{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamranr123/kamranr123.github.io/blob/master/fine_tune_multilingual_bert_on_emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4on5D3v5YVng",
        "outputId": "0083b7a2-0e65-45c1-ade0-bcfd644749b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers datasets accelerate"
      ],
      "metadata": {
        "id": "oYBBBhdaILmf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content https://github.com/nazaninsbr/Persian-Emotion-Detection/raw/refs/heads/main/dataset.csv"
      ],
      "metadata": {
        "id": "WHRf3iBLeW9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "ZljdrqNY0a2w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "# Emotion label columns (vote counts 0-5)\n",
        "label_cols = [\"Anger\", \"Fear\", \"Happiness\", \"Hatred\", \"Sadness\", \"Wonder\"]\n",
        "\n",
        "# Binarize emotions: 1 if >=3 votes (majority), else 0\n",
        "df[label_cols] = df[label_cols].apply(lambda row: [1 if x >= 3 else 0 for x in row], axis=1, result_type='expand')\n",
        "\n",
        "# Add Neutral: 1 if no emotions have majority (sum of binarized emotions == 0)\n",
        "df[\"Neutral\"] = (df[label_cols].sum(axis=1) == 0).astype(int)\n",
        "\n",
        "# Final labels\n",
        "final_labels = label_cols + [\"Neutral\"]\n",
        "df[\"labels\"] = df[final_labels].apply(lambda row: [float(x) for x in row], axis=1)\n",
        "\n",
        "# Keep only text + labels\n",
        "df = df[[\"text\", \"labels\"]]\n",
        "\n",
        "# Train/validation split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Hugging Face datasets\n",
        "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
        "dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
        "\n",
        "# Verify\n",
        "train_labels = np.array(dataset[\"train\"][\"labels\"])\n",
        "val_labels = np.array(dataset[\"validation\"][\"labels\"])\n",
        "print(\"Unique training label values:\", np.unique(train_labels))\n",
        "print(\"Unique validation label values:\", np.unique(val_labels))\n",
        "print(\"Training label frequencies:\", np.sum(train_labels, axis=0) / train_labels.shape[0])\n",
        "print(\"Validation label frequencies:\", np.sum(val_labels, axis=0) / val_labels.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQowqp_3j9Hf",
        "outputId": "941abd9e-e665-4b08-fda3-20ae0d602ff3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique training label values: [0. 1.]\n",
            "Unique validation label values: [0. 1.]\n",
            "Training label frequencies: [0.05570833 0.02308333 0.023625   0.042125   0.05891667 0.033625\n",
            " 0.796125  ]\n",
            "Validation label frequencies: [0.04916667 0.02266667 0.02083333 0.04083333 0.05933333 0.02983333\n",
            " 0.80483333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "\n",
        "# Check current label values\n",
        "train_labels = np.array(dataset[\"train\"][\"labels\"])\n",
        "val_labels = np.array(dataset[\"validation\"][\"labels\"])\n",
        "print(\"Unique training label values (before):\", np.unique(train_labels))\n",
        "print(\"Unique validation label values (before):\", np.unique(val_labels))\n",
        "\n",
        "# Binarize labels with a threshold (e.g., 0.5)\n",
        "thresholds = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.05]  # Lower threshold for Label 6\n",
        "def binarize_labels(example):\n",
        "    labels = np.array(example[\"labels\"])\n",
        "    example[\"labels\"] = (labels > np.array(thresholds)).astype(int)\n",
        "    return example\n",
        "\n",
        "dataset[\"train\"] = dataset[\"train\"].map(binarize_labels)\n",
        "dataset[\"validation\"] = dataset[\"validation\"].map(binarize_labels)\n",
        "\n",
        "# Verify binarization\n",
        "train_labels = np.array(dataset[\"train\"][\"labels\"])\n",
        "val_labels = np.array(dataset[\"validation\"][\"labels\"])\n",
        "print(\"Unique training label values (after):\", np.unique(train_labels))\n",
        "print(\"Unique validation label values (after):\", np.unique(val_labels))\n",
        "print(\"Training label frequencies:\", np.sum(train_labels, axis=0) / train_labels.shape[0])\n",
        "print(\"Validation label frequencies:\", np.sum(val_labels, axis=0) / val_labels.shape[0])"
      ],
      "metadata": {
        "id": "iCx_iLOQEeAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "aug = naw.SynonymAug(aug_p=0.3)\n",
        "def augment_data(example):\n",
        "    example[\"text\"] = aug.augment(example[\"text\"])[0]\n",
        "    return example\n",
        "dataset[\"train\"] = dataset[\"train\"].map(augment_data)"
      ],
      "metadata": {
        "id": "dUwgN3XxHiQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(dataset[\"train\"][i]['labels'])"
      ],
      "metadata": {
        "id": "8EzJekzg9gs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"google-bert/bert-base-multilingual-cased\"\n",
        "model_name = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "dataset = dataset.map(tokenize, batched=True)\n",
        "# dataset = dataset.remove_columns([\"text\"])\n"
      ],
      "metadata": {
        "id": "suYQzQhK0p_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=7,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "model.config.hidden_dropout_prob = 0.3\n",
        "model.config.attention_probs_dropout_prob = 0.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Ok0W230zzQ",
        "outputId": "f2b7c0d9-555a-447e-f56f-e75b7919082a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    thresholds = np.arange(0.1, 0.6, 0.1)\n",
        "    best_preds = np.zeros_like(labels)\n",
        "    best_thresholds = np.ones(labels.shape[1]) * 0.5\n",
        "    for i in range(labels.shape[1]):\n",
        "        best_f1 = 0\n",
        "        for t in thresholds:\n",
        "            preds_i = (probs[:, i] > t).astype(int)\n",
        "            f1_i = f1_score(labels[:, i], preds_i, average='binary')\n",
        "            if f1_i > best_f1:\n",
        "                best_f1 = f1_i\n",
        "                best_thresholds[i] = t\n",
        "                best_preds[:, i] = preds_i\n",
        "\n",
        "    f1_macro = f1_score(labels, best_preds, average='macro')\n",
        "    acc = accuracy_score(labels, best_preds)\n",
        "    hamming = hamming_loss(labels, best_preds)\n",
        "    per_label_f1 = f1_score(labels, best_preds, average=None)\n",
        "\n",
        "    print(f\"Best thresholds: {best_thresholds}\")\n",
        "    print(f\"Positive predictions: {np.sum(best_preds, axis=0)}\")\n",
        "    print(f\"Positive true labels: {np.sum(labels, axis=0)}\")\n",
        "    print(f\"Average logits: {np.mean(logits, axis=0)}\")\n",
        "    print(f\"Average probabilities: {np.mean(probs, axis=0)}\")\n",
        "\n",
        "    metrics = {\"accuracy\": acc, \"f1_macro\": f1_macro, \"hamming_loss\": hamming}\n",
        "    for i, f1_score_label in enumerate(per_label_f1):\n",
        "        metrics[f\"f1_label_{i}\"] = f1_score_label\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "7wHbVpd102tH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/bert-persian-emotions')"
      ],
      "metadata": {
        "id": "QbuClHldrUIc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, DataCollatorWithPadding\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/bert-persian-emotions\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=500,\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    optim=\"adamw_torch_fused\",\n",
        ")"
      ],
      "metadata": {
        "id": "2M9Y0vJD07rg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "\n",
        "# Focal loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1.0, gamma=3.0, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "    def forward(self, logits, targets):\n",
        "        targets = targets * (1 - self.label_smoothing) + 0.5 * self.label_smoothing\n",
        "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(logits, targets)\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\").float()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = FocalLoss(alpha=1.0, gamma=3.0)\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics  # your F1/multi-label metrics\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LkJnJTUd1-XX",
        "outputId": "ceb1fce2-b547-42e0-e873-86d1f8ca02c2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2621153558.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='61' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  61/3750 00:46 < 48:09, 1.28 it/s, Epoch 0.16/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique label values:\", np.unique(small_dataset[\"validation\"][\"labels\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_47YpJ1-ZNZ",
        "outputId": "e7994b24-a568-4a0b-e1f1-fa0a28313df1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique label values: [0.         0.07692308 0.08333333 0.08333333 0.09090909 0.1\n",
            " 0.1        0.1        0.11111111 0.11111111 0.11111111 0.125\n",
            " 0.125      0.14285714 0.14285714 0.15384615 0.16666667 0.16666667\n",
            " 0.18181818 0.2        0.2        0.2        0.22222222 0.22222222\n",
            " 0.22222222 0.23076923 0.25       0.25       0.27272727 0.28571429\n",
            " 0.28571429 0.3        0.3        0.3        0.30769231 0.33333333\n",
            " 0.33333333 0.33333333 0.36363636 0.375      0.375      0.4\n",
            " 0.42857143 0.42857143 0.44444444 0.44444444 0.44444444 0.5\n",
            " 0.5        0.57142857 0.57142857 0.6        0.66666667 0.75\n",
            " 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"من امروز خیلی خوشحالم\",      # Happy\n",
        "    \"احساس می‌کنم ناراحت و خسته‌ام\", # Sad\n",
        "    \"از تاریکی می‌ترسم\",           # Fear\n",
        "    \"قدم زدن زیر بارون شاید بهترین مسکن درد هاست...\" # Neutral\n",
        "]\n",
        "\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "outputs = model(**inputs)\n",
        "probs = torch.sigmoid(outputs.logits).detach().numpy()\n",
        "\n",
        "for text, p in zip(texts, probs):\n",
        "    labels_pred = [final_labels[i] for i, v in enumerate(p) if v > 0.5]\n",
        "    print(text, \"->\", labels_pred)\n"
      ],
      "metadata": {
        "id": "rtoVASNe-pvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# collect true labels and preds on validation set\n",
        "preds_logits = trainer.predict(dataset[\"validation\"]).predictions  # raw logits\n",
        "probs = 1 / (1 + np.exp(-preds_logits))\n",
        "preds = (probs > 0.5).astype(int)\n",
        "\n",
        "# binarize references (soft labels → 0/1)\n",
        "refs = np.stack([ex[\"labels\"] for ex in dataset[\"validation\"]])\n",
        "refs_bin = (refs >= 0.5).astype(int)\n",
        "\n",
        "# overall per-label counts\n",
        "pos_counts = refs_bin.sum(axis=0)\n",
        "neg_counts = refs_bin.shape[0] - pos_counts\n",
        "print(\"pos counts per label:\", pos_counts)\n",
        "print(\"neg counts per label:\", neg_counts)\n",
        "\n",
        "# per-label f1\n",
        "for i, name in enumerate(final_labels):\n",
        "    print(name, \"F1:\", f1_score(refs_bin[:, i], preds[:, i], zero_division=0))\n",
        "\n",
        "# full classification report\n",
        "print(classification_report(refs_bin, preds, zero_division=0))\n"
      ],
      "metadata": {
        "id": "AshUjyI7FgQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# macro F1:\n",
        "macro = f1_score(refs, preds, average=\"macro\", zero_division=0)\n",
        "micro = f1_score(refs, preds, average=\"micro\", zero_division=0)\n",
        "print(\"macro, micro:\", macro, micro)\n"
      ],
      "metadata": {
        "id": "xjBI7MErFY6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert Hugging Face dataset into numpy array of labels\n",
        "all_labels = np.stack(dataset[\"train\"][\"labels\"])  # shape: (num_samples, num_labels)\n",
        "\n",
        "# Count positives and negatives per label\n",
        "pos_counts = all_labels.sum(axis=0)\n",
        "neg_counts = all_labels.shape[0] - pos_counts\n",
        "\n",
        "print(\"pos counts per label:\", pos_counts)\n",
        "print(\"neg counts per label:\", neg_counts)\n",
        "\n",
        "# If you want mapping to label names:\n",
        "for name, pos, neg in zip(final_labels, pos_counts, neg_counts):\n",
        "    print(f\"{name:10s} | pos: {int(pos):5d} | neg: {int(neg):5d}\")\n",
        "\n",
        "val_labels = np.array(small_dataset[\"validation\"][\"labels\"])\n",
        "print(\"Validation label frequencies:\", np.sum(val_labels, axis=0) / val_labels.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U55f3uwAXOki",
        "outputId": "46a0d526-24ab-451d-b559-e46900464545"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos counts per label: [4435.79776857 3377.90284005 3411.00137803 4083.14986549 4608.76150663\n",
            " 3826.38664122  257.        ]\n",
            "neg counts per label: [19564.20223143 20622.09715995 20588.99862197 19916.85013451\n",
            " 19391.23849337 20173.61335878 23743.        ]\n",
            "Anger      | pos:  4435 | neg: 19564\n",
            "Fear       | pos:  3377 | neg: 20622\n",
            "Happiness  | pos:  3411 | neg: 20588\n",
            "Hatred     | pos:  4083 | neg: 19916\n",
            "Sadness    | pos:  4608 | neg: 19391\n",
            "Wonder     | pos:  3826 | neg: 20173\n",
            "Neutral    | pos:   257 | neg: 23743\n",
            "Validation label frequencies: [0.16867392 0.14521033 0.14398886 0.1701612  0.18877742 0.16365703\n",
            " 0.01953125]\n"
          ]
        }
      ]
    }
  ]
}