{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamranr123/kamranr123.github.io/blob/master/km_ui_sd%20v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> KM Colab</h1>"
      ],
      "metadata": {
        "id": "Ww9RtC1NhlgR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGEktzWoh9Bq"
      },
      "source": [
        "## Choose Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "XNaPfHNQh_uS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "0783e6ee905349d397579d628f96226a",
            "f818d114cf78409e82853046551fdf81",
            "eafad93b473f43ea96bf5d841a50eb16",
            "8dd983ac1f574c19bac2505c9748ad4d",
            "10105602f36c47d290ad05e561e00060",
            "480feb2f41574fcf8aecc8108f97cb7d"
          ]
        },
        "outputId": "3387d38f-8321-48c0-dd4d-864f95903785"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<h1>Model selection <a href=\"https://github.com/NUROISEA/anime-webui-colab/wiki/Selecting-a-model\"><strong>[?]</strong></a></h1>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Select(description='Choose a model:', options=('Stable Diffusion v1.5', 'Dark Sushi Mix', 'ExpMix Line', 'Cham…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0783e6ee905349d397579d628f96226a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Select(description='Choose a model version:', options=('v1-5-pruned.safetensors', 'v1-5-pruned-emaonly.safeten…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dd983ac1f574c19bac2505c9748ad4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Model: Stable Diffusion v1.5, Version: v1-5-pruned.safetensorschange\n",
            "Selected Model: FaeTastic, Version: FaeTasticV2.safetensorschange\n",
            "Selected Model: DreamShaperXL1.0, Version: DreamShaperXL1.0.safetensors"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import markdown\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "# ******************************************************************************\n",
        "!wget -q https://raw.githubusercontent.com/kamranr123/kamranr123.github.io/master/modellist.py -P /content/\n",
        "from modellist import available_model_dict\n",
        "# ******************************************************************************\n",
        "# initialize values\n",
        "model = list(available_model_dict.keys())[0]\n",
        "model_ver = available_model_dict[model][0]\n",
        "model_name = available_model_dict[model][4]\n",
        "model_link = available_model_dict[model][3] + model_name\n",
        "if 'civitai.com' in model_link:\n",
        "    model_link = available_model_dict[model][3]\n",
        "\n",
        "# Define the title and link\n",
        "title = \"Model selection\"\n",
        "link = \"https://github.com/NUROISEA/anime-webui-colab/wiki/Selecting-a-model\"\n",
        "\n",
        "# Generate the Markdown-formatted text\n",
        "markdown_text = f\"# {title} [**[?]**]({link})\"\n",
        "\n",
        "# Convert the Markdown text to HTML\n",
        "html = markdown.markdown(markdown_text)\n",
        "display(Markdown(html))\n",
        "\n",
        "# Create a list of models for the first selection listbox\n",
        "model_options = list(available_model_dict.keys())\n",
        "\n",
        "# Create the first selection listbox widget for models\n",
        "model_selection = widgets.Select(\n",
        "    options=model_options,\n",
        "    description='Choose a model:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Create the second selection listbox widget for values\n",
        "model_version_selection = widgets.Select(\n",
        "    options = available_model_dict[model_options[0]][4:],\n",
        "    description='Choose a model version:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Define a function to handle the model selection change event\n",
        "def on_model_selection_change(change):\n",
        "    global model\n",
        "    model = change['new']\n",
        "    print('change')\n",
        "    selected_values = available_model_dict[model][4:]\n",
        "    model_version_selection.options = selected_values\n",
        "\n",
        "# Attach the model selection change event handler\n",
        "model_selection.observe(on_model_selection_change, 'value')\n",
        "\n",
        "# Define a function to handle the model selection change event\n",
        "def on_model_version_selection_change(change):\n",
        "    global model_name, model_link, model_ver\n",
        "    model_name = change['new']\n",
        "    model_link = available_model_dict[model][3] + model_name\n",
        "    model_ver = available_model_dict[model][0]\n",
        "    if 'civitai.com' in model_link:\n",
        "        model_link = available_model_dict[model][3]\n",
        "    print(\"\\r\", end=\"\")\n",
        "    print(\"Selected Model: {}, Version: {}\".format(model, model_name), end=\"\")\n",
        "    # print(\"Selected Model link: {}\".format(model_link), end=\"\")\n",
        "\n",
        "# Attach the model version selection change event handler\n",
        "model_version_selection.observe(on_model_version_selection_change, 'value')\n",
        "\n",
        "# Display the selection listboxes\n",
        "display(model_selection)\n",
        "display(model_version_selection)\n",
        "print(\"Selected Model: {}, Version: {}\".format(model, model_name), end=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USPvp_jieoRL"
      },
      "source": [
        "## Download models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XfzRZ-WCddcx",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7746d7c7-cbe4-49d9-9510-1c17d4d2c6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KMUI/models/checkpoints\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "19f046|\u001b[1;32mOK\u001b[0m  |   119MiB/s|/content/KMUI/models/checkpoints/DreamShaperXL1.0.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "def gn():\n",
        "    return 'CKMyUI'.replace(\"KM\", 'omf')\n",
        "\n",
        "%cd /content\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "clear_output()\n",
        "\n",
        "base_path = '/content/KMUI/models'\n",
        "model_path = f'{base_path}/checkpoints'\n",
        "lora_path = f'{base_path}/loras'\n",
        "vae_path = f'{base_path}/vae'\n",
        "\n",
        "\n",
        "if not os.path.exists(base_path):\n",
        "    os.makedirs(base_path)\n",
        "\n",
        "def download(model_link, model_name, path=model_path):\n",
        "    if path == model_path:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "    else:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 8 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "\n",
        "%cd {model_path}\n",
        "download(model_link, model_name, model_path)\n",
        "\n",
        "def replace_word_in_file(file_path, target_word, new_word):\n",
        "    try:\n",
        "        # Open the file in read mode\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Read the file content\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Replace the target word with the new word\n",
        "        modified_content = file_content.replace(target_word, new_word)\n",
        "\n",
        "        # Open the file in write mode to overwrite its content\n",
        "        with open(file_path, 'w') as file:\n",
        "            # Write the modified content back to the file\n",
        "            file.write(modified_content)\n",
        "\n",
        "        # print(f\"Word '{target_word}' replaced with '{new_word}' in {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}: {file_path}\")\n",
        "\n",
        "def forceCopyFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.copy2(sfile, dfile)\n",
        "\n",
        "def forceMoveFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.move(sfile, dfile)\n",
        "\n",
        "def isAFlatDir(sDir):\n",
        "    for item in os.listdir(sDir):\n",
        "        sItem = os.path.join(sDir, item)\n",
        "        if os.path.isdir(sItem):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def moveTree(src, dst, target_word='Comfy', new_word='KM'):\n",
        "    _dst = dst.replace(target_word, new_word)\n",
        "    _dst = _dst.replace(target_word.lower(), new_word.lower())\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(_dst, item)\n",
        "        if os.path.isfile(s):\n",
        "            if not os.path.exists(_dst):\n",
        "                os.makedirs(_dst)\n",
        "            forceMoveFile(s,d)\n",
        "            replace_word_in_file(d, target_word, new_word)\n",
        "            replace_word_in_file(d, target_word.lower(), new_word.lower())\n",
        "        if os.path.isdir(s):\n",
        "            isRecursive = not isAFlatDir(s)\n",
        "            if isRecursive:\n",
        "                moveTree(s, d)\n",
        "            else:\n",
        "                if not os.path.exists(d):\n",
        "                    os.makedirs(d)\n",
        "                for item in os.listdir(s):\n",
        "                    srcFile = os.path.join(s, item)\n",
        "                    dstFile = os.path.join(d, item)\n",
        "                    forceMoveFile(srcFile, dstFile)\n",
        "                    replace_word_in_file(dstFile, target_word, new_word)\n",
        "                    replace_word_in_file(dstFile, target_word.lower(), new_word.lower())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUabsHbSTKF6"
      },
      "source": [
        "## LoRa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WU43pGOkO8A3"
      },
      "outputs": [],
      "source": [
        "# !pip install huggingface-hub\n",
        "# from huggingface_hub import HfApi, list_models\n",
        "# hf_api = HfApi(\n",
        "#     endpoint=\"https://huggingface.co\", # Can be a Private Hub endpoint.\n",
        "#     token=\"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\", # Token is not persisted on the machine.\n",
        "# )\n",
        "\n",
        "# def extract_lora_from_rep(repo_id, max_size=1000):\n",
        "#     ans = []\n",
        "#     list_files = hf_api.list_files_info(repo_id=repo_id)\n",
        "#     for repofile in list_files:\n",
        "#         if repofile.rfilename.endswith('safetensors') :\n",
        "#             size = float(format(repofile.size/1024/1024, \".2f\"))\n",
        "#             if size < max_size:\n",
        "#                 link = f\"https://huggingface.co/{repo_id}/resolve/main/{repofile.rfilename}\"\n",
        "#                 ans.append(link)\n",
        "#         elif repofile.rfilename.endswith('jpg') or repofile.rfilename.endswith('png'):\n",
        "#             link = f\"https://huggingface.co/{repo_id}/resolve/main/{repofile.rfilename}\"\n",
        "#             ans.append(link)\n",
        "#     return ans\n",
        "\n",
        "# def extract_lora_from_author(author, max_size=1000):\n",
        "#     ans = []\n",
        "#     all_models = hf_api.list_models(author=author)\n",
        "#     for lmodel in all_models:\n",
        "#         ans.extend(extract_lora_from_rep(lmodel.id, max_size))\n",
        "#     return ans\n",
        "\n",
        "lora_list = []\n",
        "lora_list.append(['https://civitai.com/api/download/models/122580', 'Skin-Hands.safetensors']) # Skin & Hands (male/female) from Polyhedron\n",
        "lora_list.append(['https://civitai.com/api/download/models/117151', 'LEOSAMClothingAdjuster.safetensors']) # LEOSAM's Clothing +/- Adjuster LoRA\n",
        "lora_list.append(['https://civitai.com/api/download/models/126785','WowifierXL.safetensors']) # WowifierXL LoRA\n",
        "lora_list.append(['https://civitai.com/api/download/models/155625','Caricaturized.safetensors']) # SDXL Caricaturized LoRA\n",
        "lora_list.append(['https://huggingface.co/naonovn/Lora/resolve/main/add_detail.safetensors','add_detail.safetensors']) # add_detail LoRA\n",
        "\n",
        "# 3D rendering style (SD 1.5)\n",
        "# https://civitai.com/models/73756\n",
        "# The larger the version number, the more mature and realistic the rendering style will be.\n",
        "lora_list.append(['https://civitai.com/api/download/models/107366','3DMM_V12.safetensors'])\n",
        "lora_list.append(['https://civitai.com/api/download/models/78467','3DMM_V10.safetensors'])\n",
        "lora_list.append(['https://civitai.com/api/download/models/88206','3DMM_V7.safetensors'])\n",
        "lora_list.append(['https://civitai.com/api/download/models/78559','3DMM_V5.safetensors'])\n",
        "lora_list.append(['https://civitai.com/api/download/models/78564','3DMM_V3.safetensors'])\n",
        "\n",
        "# Detail Tweaker XL\n",
        "# https://civitai.com/models/122359/detail-tweaker-xl\n",
        "lora_list.append(['https://civitai.com/api/download/models/135867','DetailTweaker-XL-V1.safetensors'])\n",
        "\n",
        "# Add More Details - Detail Enhancer / Tweaker\n",
        "# https://civitai.com/models/82098/add-more-details-detail-enhancer-tweaker-lora\n",
        "lora_list.append(['https://civitai.com/api/download/models/87153','AddMoreDetails-v1.safetensors'])\n",
        "\n",
        "# sharpen/soften effect\n",
        "# https://civitai.com/models/94543/lora-sharpensoften-effect-lora-model\n",
        "lora_list.append(['https://civitai.com/api/download/models/100851?type=Model&format=SafeTensor','sharpen-soften effect-v1.safetensors'])\n",
        "\n",
        "# S-shape body slider LoRA (SD 1.5)\n",
        "# https://civitai.com/models/135052/muggle-loras-shape-body-slider\n",
        "lora_list.append(['https://civitai.com/api/download/models/148789?type=Model&format=SafeTensor','S-shape body slider-v1.safetensors'])\n",
        "\n",
        "# Better eyes+face+skin LoRA (SD 1.5)\n",
        "# https://civitai.com/models/51430?modelVersionId=55905\n",
        "lora_list.append(['https://civitai.com/api/download/models/55905','BetterEyesFaceSkin-v1.safetensors'])\n",
        "\n",
        "# Hipoly 3D Model LoRA (SD 1.5)\n",
        "# https://civitai.com/models/70921/duchaitenniji\n",
        "lora_list.append(['https://civitai.com/api/download/models/44566','Hipoly3D-v2.safetensors'])\n",
        "\n",
        "# Samaritan 3d Cartoon SDXL\n",
        "# https://civitai.com/models/121932/samaritan-3d-cartoon-sdxl\n",
        "# the default face is grumpy/angry for some reason. But this model was trained on variety of emotions,\n",
        "# try \"smiling, laugh,sad, crying, shouting, surprised, etc\" in the prompt\n",
        "lora_list.append(['https://civitai.com/api/download/models/132727','3DMM_V3.safetensors'])\n",
        "\n",
        "# xl-water-dress\n",
        "# https://civitai.com/models/156447/xl-water-dress\n",
        "lora_list.append(['https://civitai.com/api/download/models/175608','xl-water-dress.safetensors'])\n",
        "\n",
        "# lora_list.extend(extract_lora_from_author(author='casque'))\n",
        "# lora_list.extend(extract_lora_from_rep(repo_id='naonovn/Lora'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ControlNet"
      ],
      "metadata": {
        "id": "XnlbpcS8dCdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "controllora_list_SDXL = []\n",
        "# https://huggingface.co/stabilityai/control-lora      (SDXL)\n",
        "link = 'https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors'\n",
        "controllora_list_SDXL.append([link, 'control-lora-canny-rank256.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors'\n",
        "controllora_list_SDXL.append([link, 'control-lora-depth-rank256.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors'\n",
        "controllora_list_SDXL.append([link, 'control-lora-recolor-rank256.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors'\n",
        "controllora_list_SDXL.append([link, 'control-lora-sketch-rank256.safetensors'])\n",
        "\n",
        "# ################################################################################\n",
        "controlnet_list_SDXL = []\n",
        "\n",
        "# https://huggingface.co/collections/diffusers/sdxl-controlnets-64f9c35846f3f06f5abe351f      (SDXL)\n",
        "link = 'https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors'\n",
        "controlnet_list_SDXL.append([link, 'controlnet-canny-sdxl-1.0.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors'\n",
        "controlnet_list_SDXL.append([link, 'controlnet-depth-sdxl-1.0.safetensors'])\n",
        "# download(link, 'controlnet-depth-sdxl-1.0.safetensors', f'{base_path}/controlnet')\n",
        "\n",
        "# ###############################################################################\n",
        "controlnet_list = []\n",
        "\n",
        "link = 'https://huggingface.co/nolanaatama/models/resolve/main/control_v11p_sd15_openpose_fp16.safetensors'\n",
        "controlnet_list.append([link, 'control_v11p_sd15_openpose_fp16.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/nolanaatama/models/resolve/main/control_v11p_sd15_canny_fp16.safetensors'\n",
        "controlnet_list.append([link, 'control_v11p_sd15_canny_fp16.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/nolanaatama/models/resolve/main/control_v11p_sd15_depth_fp16.safetensors'\n",
        "controlnet_list.append([link, 'control_v11p_sd15_depth_fp16.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/nolanaatama/models/resolve/main/control_v11p_sd15_softedge_fp16.safetensors'\n",
        "controlnet_list.append([link, 'control_v11p_sd15_softedge_fp16.safetensors'])\n",
        "\n",
        "link = 'https://huggingface.co/nolanaatama/models/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors'\n",
        "# controlnet_list.append([link, 'control_v11e_sd15_ip2p_fp16.safetensors'])\n",
        "\n",
        "# ###############################################################################\n",
        "T2IAdapter_list = []\n",
        "link = 'https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd15v2.pth'\n",
        "T2IAdapter_list.append([link, 't2iadapter_canny_sd15v2.pth'])\n",
        "\n",
        "link = 'https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd15v2.pth'\n",
        "T2IAdapter_list.append([link, 't2iadapter_depth_sd15v2.pth'])\n",
        "\n",
        "link = 'https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/coadapter-color-sd15v1.pth'\n",
        "controlnet_list.append([link, 'coadapter-color-sd15v1.pth'])"
      ],
      "metadata": {
        "id": "0SDUA25YdH_A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qf_1-GCqcVt"
      },
      "source": [
        "# Run KMUI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setting\n",
        "\n",
        "#@markdown # UI\n",
        "#@markdown extensions (custom node)\n",
        "OneButtonPrompt = False #@param {type:'boolean'}\n",
        "ReactorNode = True #@param {type:'boolean'}\n",
        "FaceRestore = True #@param {type:'boolean'}\n",
        "ControlnetAux = True #@param {type:'boolean'}\n",
        "DetailedKSAmpler = False #@param {type:'boolean'}\n",
        "rgthree = True #@param {type:'boolean'}\n",
        "SeargeSDXL = False #@param {type:'boolean'}\n",
        "#@markdown download\n",
        "DownloadEmbeddings = True #@param {type:'boolean'}\n",
        "DownloadLoRa = True #@param {type:'boolean'}\n",
        "DownloadVAE = False #@param {type:'boolean'}\n",
        "TaesdDecoder = True #@param {type:'boolean'}\n",
        "Upscaller_RealESRGAN_x2 = True #@param {type:'boolean'}\n",
        "Upscaller_4x_UltraSharp = False #@param {type:'boolean'}\n",
        "Clip_Vision_g = False #@param {type:'boolean'}\n",
        "#@markdown Control Net\n",
        "Control_LoRa = False #@param {type:'boolean'}\n",
        "ControlNet_V15 = False #@param {type:'boolean'}\n",
        "ControlNet_XL = False #@param {type:'boolean'}\n",
        "T2IAdapter = False #@param {type:'boolean'}"
      ],
      "metadata": {
        "id": "IzWiMDvTKPqO",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "g_dX9-EbDiXA"
      },
      "outputs": [],
      "source": [
        "#@title Download models\n",
        "if DownloadEmbeddings:\n",
        "    !wget -q 'https://huggingface.co/nolanaatama/colab/resolve/main/embeddings.zip' -P /content/KMUI/models/embeddings/\n",
        "    with zipfile.ZipFile(\"/content/KMUI/models/embeddings/embeddings.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/KMUI/models')\n",
        "    os.remove(\"/content/KMUI/models/embeddings/embeddings.zip\")\n",
        "\n",
        "if DownloadLoRa:\n",
        "    %cd {lora_path}'\n",
        "    for item in lora_list:\n",
        "      download(item[0], item[1], lora_path)\n",
        "\n",
        "if DownloadVAE:\n",
        "    download('https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt', 'vae-ft-mse-840000-ema-pruned.ckpt', vae_path)\n",
        "\n",
        "if TaesdDecoder:\n",
        "    download('https://github.com/madebyollin/taesd/raw/main/taesd_decoder.pth', 'taesd_decoder.pth', f'{base_path}/vae_approx')\n",
        "    download(\"https://github.com/madebyollin/taesd/raw/main/taesdxl_decoder.pth\", 'taesdxl_decoder.pth', f'{base_path}/vae_approx')\n",
        "\n",
        "if Upscaller_RealESRGAN_x2:\n",
        "    download(\"https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth\", 'RealESRGAN_x2.pth', f'{base_path}/upscale_models')\n",
        "\n",
        "if Upscaller_4x_UltraSharp:\n",
        "    download('https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x-UltraSharp.pth', '4x-UltraSharp.pth', f'{base_path}/upscale_models')\n",
        "\n",
        "if FaceRestore or ReactorNode:\n",
        "    download(\"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\", 'GFPGANv1.4.pth', f'{base_path}/facerestore_models')\n",
        "\n",
        "%cd f'{base_path}/controlnet'\n",
        "if Control_LoRa:\n",
        "    for item in controllora_list_SDXL:\n",
        "      download(item[0], item[1], f'{base_path}/controlnet')\n",
        "\n",
        "if ControlNet_XL:\n",
        "    for item in controlnet_list_SDXL:\n",
        "      download(item[0], item[1], f'{base_path}/controlnet')\n",
        "\n",
        "if ControlNet_V15:\n",
        "    for item in controlnet_list:\n",
        "      download(item[0], item[1], f'{base_path}/controlnet')\n",
        "\n",
        "if Control_LoRa:\n",
        "    for item in T2IAdapter_list:\n",
        "      download(item[0], item[1], f'{base_path}/controlnet')\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rld0qAZAfPg0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prepare workspace and install KMUI\n",
        "\n",
        "%cd /content\n",
        "!apt -y update -qq\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "!pip install -q mediapipe==0.9.1.0 addict yapf fvcore omegaconf\n",
        "\n",
        "!git clone https://github.com/comfyanonymous/{gn()}\n",
        "\n",
        "#Install custom nodes\n",
        "%cd /content/{gn()}/custom_nodes\n",
        "\n",
        "!git clone https://github.com/mpiquero1111/{gn()}-SaveImgPrompt SaveImgPrompt\n",
        "\n",
        "if OneButtonPrompt:\n",
        "    !git clone https://github.com/AIrjen/OneButtonPrompt\n",
        "\n",
        "if ControlnetAux:\n",
        "    !git clone https://github.com/Fannovel16/{gn()}_controlnet_aux/\n",
        "\n",
        "if ReactorNode:\n",
        "    !git clone https://github.com/Gourieff/{gn()}-reactor-node\n",
        "\n",
        "if rgthree:\n",
        "    !git clone https://github.com/rgthree/rgthree-comfy\n",
        "\n",
        "# FaceRestore\n",
        "if FaceRestore:\n",
        "    download('https://civitai.com/api/download/models/122586', 'rf.zip', f'/content/{gn()}/custom_nodes')\n",
        "    with zipfile.ZipFile(f'/content/{gn()}/custom_nodes/rf.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(f'/content/{gn()}/custom_nodes')\n",
        "    os.remove(f'/content/{gn()}/custom_nodes/rf.zip')\n",
        "\n",
        "# DetailedKSAmpler\n",
        "if DetailedKSAmpler:\n",
        "    download('https://civitai.com/api/download/models/169441', 'rf.zip', f'/content/{gn()}/custom_nodes')\n",
        "    with zipfile.ZipFile(f'/content/{gn()}/custom_nodes/rf.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(f'/content/{gn()}/custom_nodes')\n",
        "    os.remove(f'/content/{gn()}/custom_nodes/rf.zip')\n",
        "\n",
        "moveTree(f'/content/{gn()}', '/content/KMUI')\n",
        "shutil.rmtree(f'/content/{gn()}')\n",
        "\n",
        "# install requirements\n",
        "%cd /content/KMUI\n",
        "# C_omfy\n",
        "!pip install xformers -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "%cd /content/KMUI/custom_nodes\n",
        "# SaveImagePrompt\n",
        "!pip install colorama\n",
        "\n",
        "# reactor-node\n",
        "if ReactorNode:\n",
        "    os.makedirs('/content/KMUI/custom_nodes/KMUI-reactor-node/models/insightface')\n",
        "    os.makedirs('/content/KMUI/custom_nodes/KMUI-reactor-node/models/facerestore_models')\n",
        "    download(\"https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\", 'inswapper_128.onnx', f'/content/KMUI/custom_nodes/KMUI-reactor-node/models/insightface')\n",
        "    shutil.copy('/content/KMUI/models/facerestore_models/GFPGANv1.4.pth', '/content/KMUI/custom_nodes/KMUI-reactor-node/models/facerestore_models/GFPGANv1.4.pth')\n",
        "    !pip install -r KMUI-reactor-node/requirements.txt\n",
        "\n",
        "if SeargeSDXL:\n",
        "    !git clone https://github.com/SeargeDP/SeargeSDXL\n",
        "\n",
        "# controlnet_aux\n",
        "if ControlnetAux:\n",
        "    !pip install -r KMUI_controlnet_aux/requirements.txt\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tbkwsKC0SWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4da7c7-9098-42cd-edbb-feb96304adc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-06 18:31:42--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2023.8.2/cloudflared-linux-amd64 [following]\n",
            "--2023-10-06 18:31:42--  https://github.com/cloudflare/cloudflared/releases/download/2023.8.2/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/e6bb31a7-5cfa-446c-bf2a-c8eccfa0256e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231006%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231006T183142Z&X-Amz-Expires=300&X-Amz-Signature=cd9d5a7dd1d7502ea4a94f871a68070c579df55bbf21e316afaaba65ded2b13e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-06 18:31:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/e6bb31a7-5cfa-446c-bf2a-c8eccfa0256e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231006%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231006T183142Z&X-Amz-Expires=300&X-Amz-Signature=cd9d5a7dd1d7502ea4a94f871a68070c579df55bbf21e316afaaba65ded2b13e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36461990 (35M) [application/octet-stream]\n",
            "Saving to: ‘/content/cloudflared-linux-amd64’\n",
            "\n",
            "/content/cloudflare 100%[===================>]  34.77M   216MB/s    in 0.2s    \n",
            "\n",
            "2023-10-06 18:31:43 (216 MB/s) - ‘/content/cloudflared-linux-amd64’ saved [36461990/36461990]\n",
            "\n",
            "https://walks-guestbook-inch-announcement.trycloudflare.com\n",
            "/content/KMUI\n",
            "Total VRAM 15102 MB, total RAM 12983 MB\n",
            "xformers version: 0.0.22\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using xformers cross attention\n",
            "2023-10-06 18:31:58.091220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\u001b[33m[rgthree] Optimizing KMUI reursive execution. If queueing and/or re-queueing seems broken, change \"patch_recursive_execution\" to false in rgthree_config.json \u001b[0m\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "  12.3 seconds: /content/KMUI/custom_nodes/rgthree-km\n",
            "\n",
            "### Loading: Save img prompt\n",
            "Total VRAM 15102 MB, total RAM 12983 MB\u001b[0m\n",
            "\u001b[0mxformers version:\u001b[0m \u001b[0m0.0.22\u001b[0m\n",
            "\u001b[0mSet vram state to: NORMAL_VRAM\u001b[0m\n",
            "\u001b[0mDevice:\u001b[0m \u001b[0mcuda:0 Tesla T4 : native\u001b[0m\n",
            "\u001b[0mVAE dtype:\u001b[0m \u001b[0mtorch.float32\u001b[0m\n",
            "\u001b[0mTotal VRAM 15102 MB, total RAM 12983 MB\u001b[0m\n",
            "\u001b[0mxformers version:\u001b[0m \u001b[0m0.0.22\u001b[0m\n",
            "\u001b[0mSet vram state to: NORMAL_VRAM\u001b[0m\n",
            "\u001b[0mDevice:\u001b[0m \u001b[0mcuda:0 Tesla T4 : native\u001b[0m\n",
            "\u001b[0mVAE dtype:\u001b[0m \u001b[0mtorch.float32\u001b[0m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/content/KMUI/nodes.py\", line 1734, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/KMUI/custom_nodes/facerestore/__init__.py\", line 6, in <module>\n",
            "    import cv2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 181, in <module>\n",
            "    bootstrap()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 175, in bootstrap\n",
            "    if __load_extra_py_code_for_module(\"cv2\", submodule, DEBUG):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 28, in __load_extra_py_code_for_module\n",
            "    py_module = importlib.import_module(module_name)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/typing/__init__.py\", line 157, in <module>\n",
            "    Prim = typing.Union[cv2.gapi.wip.draw.Text, cv2.gapi.wip.draw.Circle, cv2.gapi.wip.draw.Image, cv2.gapi.wip.draw.Line, cv2.gapi.wip.draw.Rect, cv2.gapi.wip.draw.Mosaic, cv2.gapi.wip.draw.Poly]\n",
            "AttributeError: module 'cv2.gapi.wip.draw' has no attribute 'Text'\n",
            "\u001b[0m\n",
            "\u001b[0mCannot import /content/KMUI/custom_nodes/facerestore module for custom nodes:\u001b[0m \u001b[0mmodule 'cv2.gapi.wip.draw' has no attribute 'Text'\u001b[0m\n",
            "\u001b[0m\u001b[32m\u001b[1mrgthree's km nodes:\u001b[0m\u001b[1m Loaded 15 exciting nodes.\u001b[0m\u001b[0m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/content/KMUI/nodes.py\", line 1734, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/KMUI/custom_nodes/KMUI_controlnet_aux/__init__.py\", line 2, in <module>\n",
            "    from .utils import here, create_node_input_types\n",
            "  File \"/content/KMUI/custom_nodes/KMUI_controlnet_aux/utils.py\", line 4, in <module>\n",
            "    import cv2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 181, in <module>\n",
            "    bootstrap()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 175, in bootstrap\n",
            "    if __load_extra_py_code_for_module(\"cv2\", submodule, DEBUG):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\", line 28, in __load_extra_py_code_for_module\n",
            "    py_module = importlib.import_module(module_name)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cv2/typing/__init__.py\", line 94, in <module>\n",
            "    MatLike = typing.Union[cv2.mat_wrapper.Mat, NumPyArrayGeneric]\n",
            "AttributeError: partially initialized module 'cv2' has no attribute 'mat_wrapper' (most likely due to a circular import)\n",
            "\u001b[0m\n",
            "\u001b[0mCannot import /content/KMUI/custom_nodes/KMUI_controlnet_aux module for custom nodes:\u001b[0m \u001b[0mpartially initialized module 'cv2' has no attribute 'mat_wrapper' (most likely due to a circular import)\u001b[0m\n",
            "\u001b[0m\n",
            "Import times for custom nodes:\u001b[0m\n",
            "\u001b[0m   0.0 seconds:\u001b[0m \u001b[0m/content/KMUI/custom_nodes/SaveImgPrompt\u001b[0m\n",
            "\u001b[0m   0.0 seconds (IMPORT FAILED):\u001b[0m \u001b[0m/content/KMUI/custom_nodes/KMUI_controlnet_aux\u001b[0m\n",
            "\u001b[0m   0.0 seconds (IMPORT FAILED):\u001b[0m \u001b[0m/content/KMUI/custom_nodes/facerestore\u001b[0m\n",
            "\u001b[0m   0.0 seconds:\u001b[0m \u001b[0m/content/KMUI/custom_nodes/rgthree-km\u001b[0m\n",
            "\u001b[0m   2.2 seconds:\u001b[0m \u001b[0m/content/KMUI/custom_nodes/KMUI-reactor-node\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0mStarting server\n",
            "\u001b[0m\n",
            "\u001b[0mTo see the GUI go to: http://127.0.0.1:8188\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0mmodel_type\u001b[0m \u001b[0mEPS\u001b[0m\n",
            "\u001b[0madm\u001b[0m \u001b[0m2816\u001b[0m\n",
            "\u001b[0mmaking attention of type 'vanilla-xformers' with 512 in_channels\u001b[0m\n",
            "\u001b[0mbuilding MemoryEfficientAttnBlock with 512 in_channels...\u001b[0m\n",
            "\u001b[0mWorking with z of shape (1, 4, 32, 32) = 4096 dimensions.\u001b[0m\n",
            "\u001b[0mmaking attention of type 'vanilla-xformers' with 512 in_channels\u001b[0m\n",
            "\u001b[0mbuilding MemoryEfficientAttnBlock with 512 in_channels...\u001b[0m\n",
            "\u001b[0mmissing\u001b[0m \u001b[0m{'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\u001b[0m\n",
            "\u001b[0mleft over keys:\u001b[0m \u001b[0mdict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\u001b[0m\n",
            "\u001b[0mloaded straight to GPU\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "100% 25/25 [00:24<00:00,  1.00it/s]\u001b[0m\n",
            "18:33:55 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0042.jpeg\u001b[0m\u001b[0mPrompt executed in 92.73 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0mFailed to validate prompt for output 10:\u001b[0m\n",
            "\u001b[0m* Lora Loader Stack (rgthree) 16:\u001b[0m\n",
            "\u001b[0m  - Required input is missing: model\u001b[0m\n",
            "\u001b[0mOutput will be ignored\u001b[0m\n",
            "\u001b[0minvalid prompt:\u001b[0m \u001b[0m{'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0munload clone\u001b[0m \u001b[0m1\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0munload clone\u001b[0m \u001b[0m1\u001b[0m\n",
            "100% 25/25 [00:24<00:00,  1.03it/s]\u001b[0m\n",
            "18:35:32 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0043.jpeg\u001b[0m\u001b[0mPrompt executed in 47.91 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "100% 25/25 [00:23<00:00,  1.05it/s]\u001b[0m\n",
            "18:37:28 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0044.jpeg\u001b[0m\u001b[0mPrompt executed in 40.68 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc1.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_in.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_out.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\u001b[0m\n",
            "\u001b[0mlora key not loaded\u001b[0m \u001b[0mlora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 491520\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 491520\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 491520\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 491520\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[1280, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.proj_in.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight\u001b[0m \u001b[0mshape '[5120, 640]' is invalid for input of size 13107200\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight\u001b[0m \u001b[0mshape '[640, 2560]' is invalid for input of size 6553600\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.3.1.proj_out.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.proj_in.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight\u001b[0m \u001b[0mshape '[5120, 640]' is invalid for input of size 13107200\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight\u001b[0m \u001b[0mshape '[640, 2560]' is invalid for input of size 6553600\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.4.1.proj_out.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.proj_in.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight\u001b[0m \u001b[0mshape '[5120, 640]' is invalid for input of size 13107200\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight\u001b[0m \u001b[0mshape '[640, 2560]' is invalid for input of size 6553600\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight\u001b[0m \u001b[0mshape '[640, 2048]' is invalid for input of size 983040\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "\u001b[0mERROR\u001b[0m \u001b[0mdiffusion_model.output_blocks.5.1.proj_out.weight\u001b[0m \u001b[0mshape '[640, 640]' is invalid for input of size 1638400\u001b[0m\n",
            "100% 25/25 [00:24<00:00,  1.02it/s]\u001b[0m\n",
            "18:38:25 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0045.jpeg\u001b[0m\u001b[0mPrompt executed in 42.72 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0m2\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "\u001b[0mloading new\u001b[0m\n",
            "100% 40/40 [00:40<00:00,  1.02s/it]\u001b[0m\n",
            "18:40:05 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0046.jpeg\u001b[0m\u001b[0mPrompt executed in 60.02 seconds\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 40/40 [00:43<00:00,  1.09s/it]\u001b[0m\n",
            "18:41:02 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0047.jpeg\u001b[0m\u001b[0mPrompt executed in 57.58 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 30/30 [00:56<00:00,  1.87s/it]\u001b[0m\n",
            "18:43:38 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0048.jpeg\u001b[0m\u001b[0mPrompt executed in 68.68 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 30/30 [01:00<00:00,  2.00s/it]\u001b[0m\n",
            "18:45:09 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0049.jpeg\u001b[0m\u001b[0mPrompt executed in 71.44 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 30/30 [00:59<00:00,  1.99s/it]\u001b[0m\n",
            "18:46:28 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0050.jpeg\u001b[0m\u001b[0mPrompt executed in 73.55 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 30/30 [00:59<00:00,  2.00s/it]\u001b[0m\n",
            "18:47:53 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0051.jpeg\u001b[0m\u001b[0mPrompt executed in 74.42 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            "100% 30/30 [01:00<00:00,  2.01s/it]\u001b[0m\n",
            "18:50:12 - ReActor Node - \u001b[38;5;173mSTATUS\u001b[0m - Working: source face index [1], target face index [0]\n",
            "\u001b[0m\u001b[32m+ File(s) saved to: /content/KMUI/output/2023-10-06/km_0052.jpeg\u001b[0m\u001b[0mPrompt executed in 73.08 seconds\u001b[0m\n",
            "\u001b[0mgot prompt\u001b[0m\n",
            "\u001b[0m4\u001b[0m\n",
            "\u001b[0m3\u001b[0m\n",
            " 23% 7/30 [00:13<00:46,  2.01s/it]\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title Run\n",
        "\n",
        "import os\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared-linux-amd64 && chmod 777 /content/cloudflared-linux-amd64\n",
        "import atexit, requests, subprocess, time, re, os\n",
        "from random import randint\n",
        "from threading import Timer\n",
        "from queue import Queue\n",
        "def cloudflared(port, metrics_port, output_queue):\n",
        "    atexit.register(lambda p: p.terminate(), subprocess.Popen(['/content/cloudflared-linux-amd64', 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT))\n",
        "    attempts, tunnel_url = 0, None\n",
        "    while attempts < 10 and not tunnel_url:\n",
        "        attempts += 1\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            tunnel_url = re.search(\"(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)\", requests.get(f'http://127.0.0.1:{metrics_port}/metrics').text).group(\"url\")\n",
        "        except:\n",
        "            pass\n",
        "    if not tunnel_url:\n",
        "        raise Exception(\"Can't connect to Cloudflare Edge\")\n",
        "    output_queue.put(tunnel_url)\n",
        "output_queue, metrics_port = Queue(), randint(8100, 9000)\n",
        "thread = Timer(2, cloudflared, args=(8188, metrics_port, output_queue))\n",
        "thread.start()\n",
        "thread.join()\n",
        "tunnel_url = output_queue.get()\n",
        "os.environ['webui_url'] = tunnel_url\n",
        "print(tunnel_url)\n",
        "\n",
        "args = ''\n",
        "if TaesdDecoder:\n",
        "    args = '  --preview-method taesd'\n",
        "%cd /content/KMUI\n",
        "!python main.py {args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D-6yNrqCkO0i"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# shutil.move('/content/models', '/content/KMUI/models')\n",
        "# shutil.move('/content/KMUI/models', '/content/models')\n",
        "# shutil.move('/content/stable-diffusion-webui/models/Stable-diffusion', '/content/KMUI/models/checkpoints')\n",
        "shutil.rmtree('/content/KMUI')\n",
        "# shutil.rmtree('/content/stable-diffusion-webui')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb8G2WauywJu"
      },
      "source": [
        "# Utiities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "jfgnf3GbPcoK"
      },
      "outputs": [],
      "source": [
        "#@title Saving images\n",
        "\n",
        "#@markdown <small>The zip file will be visible at the files tab.</small>\n",
        "from datetime import datetime\n",
        "str_date = datetime.today().strftime('%Y-%m-%d-%H%M%S')\n",
        "archive_name = f\"outputs-{str_date}.zip\"\n",
        "\n",
        "print(\"Zipping...\")\n",
        "!zip -qr /content/{archive_name} /content/KMUI/output\n",
        "print(f\"\\033[92mZipped. You can now find {archive_name} at the files tab.\\033[0m\")\n",
        "\n",
        "# ----\n",
        "\n",
        "#@markdown <small>This copies the zip file to your Google Drive</small>\n",
        "copy_to_gdrive = True #@param {type:'boolean'}\n",
        "gdrive_folder = \"AI/Generated\" #@param { 'type': 'string' }\n",
        "\n",
        "if copy_to_gdrive:\n",
        "  # utility.log_usage('zip-to-gdrive')\n",
        "  from google.colab import drive\n",
        "\n",
        "  print(\"Mounting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "  if gdrive_folder == \"\":\n",
        "    gdrive_folder = \"AI/Generated\"\n",
        "\n",
        "  drive_folder = f\"/content/drive/MyDrive/{gdrive_folder}\"\n",
        "\n",
        "  !mkdir -p {drive_folder}\n",
        "  !cp /content/{archive_name} {drive_folder}\n",
        "  print(f\"\\033[92mCopied to {gdrive_folder}!\\033[0m\")\n",
        "\n",
        "  drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AyH4Jb5mNofH",
        "USPvp_jieoRL",
        "vUabsHbSTKF6",
        "Nb8G2WauywJu"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0783e6ee905349d397579d628f96226a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "Stable Diffusion v1.5",
              "Dark Sushi Mix",
              "ExpMix Line",
              "ChameleonAiMix",
              "majicMIX realistic V5",
              "OrangeMixs",
              "HenMixReal",
              "DreamlikePhotoreal",
              "NeverEndingDream2",
              "F2",
              "PerfectWorldV4B",
              "DreamShaper",
              "AnyLoRA",
              "AbsoluteReality",
              "MeinaHentai",
              "KenCanMix",
              "HenmixArt",
              "Reliberate",
              "Deliberate",
              "HenmixReal",
              "RunDiffusionFXPhotorealistic",
              "Paragon-V1.0",
              "Photon",
              "RealisticVision",
              "SDXL-V1.0 Base",
              "SDXL-V1.0 Refiner",
              "SDVN6-RealXL",
              "DynaVisionXL",
              "RealCartoon-Realistic",
              "CounterfeitXL-anime",
              "ZavyChromaXL",
              "DreamShaperXL1.0",
              "3DAnimationDiffusion",
              "FaeTastic",
              "naturalsin"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "Choose a model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 31,
            "layout": "IPY_MODEL_f818d114cf78409e82853046551fdf81",
            "rows": 5,
            "style": "IPY_MODEL_eafad93b473f43ea96bf5d841a50eb16"
          }
        },
        "f818d114cf78409e82853046551fdf81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafad93b473f43ea96bf5d841a50eb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "8dd983ac1f574c19bac2505c9748ad4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "DreamShaperXL1.0.safetensors"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "Choose a model version:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_10105602f36c47d290ad05e561e00060",
            "rows": 5,
            "style": "IPY_MODEL_480feb2f41574fcf8aecc8108f97cb7d"
          }
        },
        "10105602f36c47d290ad05e561e00060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480feb2f41574fcf8aecc8108f97cb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}