{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamranr123/kamranr123.github.io/blob/master/km_ui_sd%20v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> KM Colab</h1>"
      ],
      "metadata": {
        "id": "Ww9RtC1NhlgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "Flux_mode = False\n",
        "model_type = \"SDXL\" # @param [\"SD15\",\"SDXL\",\"Flux. 1 dev\",\"Flux. 1 Schnell\", \"SD3.5\"]\n",
        "\n",
        "Flux_mode = 'Flux' in model_type\n",
        "def gn():\n",
        "    # return 'TotoroUI' if Flux_mode else 'CKMyUI'.replace(\"KM\", 'omf')\n",
        "    return 'CKMyUI'.replace(\"KM\", 'omf')\n",
        "\n",
        "# gnn= 'TotoroUI' if Flux_mode else 'KMUI'\n",
        "gnn= 'KMUI'\n"
      ],
      "metadata": {
        "id": "D-0_qj5YQbt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initial"
      ],
      "metadata": {
        "id": "b-lSsUXClM0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, clear_output\n",
        "!pip install python-telegram-bot\n",
        "# !pip install wget\n",
        "!pip install piexif\n",
        "# ******************************************************************************\n",
        "# !pip install -q torchsde einops diffusers accelerate xformers==0.0.27.post2\n",
        "# !pip install spandrel\n",
        "!apt -y install -qq aria2\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "AYaxBtWIETRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, clear_output\n",
        "\n",
        "# import wget\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        contents = file.read()\n",
        "    return contents\n",
        "# ******************************************************************************\n",
        "class Modelpaths:\n",
        "    base_path = f'/content/{gnn}/models'\n",
        "    model = f'{base_path}/checkpoints'\n",
        "    lora = f'{base_path}/loras'\n",
        "    vae = f'{base_path}/vae'\n",
        "    upscale = f'{base_path}/upscale_models'\n",
        "    controlnet = f'{base_path}/controlnet'\n",
        "    embeddings = f'{base_path}/embeddings'\n",
        "    diffusers = f'{base_path}/diffusers'\n",
        "    unet = f'{base_path}/unet'\n",
        "    clip = f'{base_path}/clip'\n",
        "\n",
        "    def __init__(self):\n",
        "        if not os.path.exists(self.base_path):\n",
        "            os.makedirs(self.model)\n",
        "            os.makedirs(self.lora)\n",
        "            os.makedirs(self.vae)\n",
        "            os.makedirs(self.upscale)\n",
        "            os.makedirs(self.embeddings)\n",
        "            os.makedirs(self.diffusers)\n",
        "            os.makedirs(self.unet)\n",
        "            os.makedirs(self.clip)\n",
        "\n",
        "modelpaths = Modelpaths()\n",
        "\n",
        "# ******************************************************************************\n",
        "def download(model_link, model_name, path=modelpaths.model):\n",
        "    if 'civitai' in model_link:\n",
        "        if \"?\" in model_link:\n",
        "            model_link = f\"{model_link},token=2a98e142e24406e7fbb077e80b0418a6\"\n",
        "        else:\n",
        "            model_link = f\"{model_link}?token=2a98e142e24406e7fbb077e80b0418a6\"\n",
        "\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "    else:\n",
        "        if path == modelpaths.model:\n",
        "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error -c -x 16 -s 8 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "\n",
        "def download_from_civitai(model_id, versian_id):\n",
        "    url = f\"https://civitai.com/api/v1/models/{str(model_id)}\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # If the request was successful, print the JSON content\n",
        "    json_data = ''\n",
        "    if response.status_code == 200:\n",
        "        json_data = response.json()\n",
        "\n",
        "        m_type = json_data[\"type\"]\n",
        "        mpath = modelpaths.base_path\n",
        "\n",
        "        if m_type == 'Checkpoint':\n",
        "            mpath = modelpaths.model\n",
        "        elif m_type == 'TextualInversion':\n",
        "            mpath = modelpaths.embeddings\n",
        "        elif m_type == 'LORA':\n",
        "            mpath = modelpaths.lora\n",
        "        elif m_type == 'Controlnet':\n",
        "            mpath = modelpaths.controlnet\n",
        "\n",
        "        for it in json_data[\"modelVersions\"]:\n",
        "            if str(it[\"id\"]) == str(versian_id):\n",
        "                download(f'https://civitai.com/api/download/models/{it[\"id\"]}', str(it[\"files\"][0][\"name\"]), mpath)\n",
        "                return str(it[\"files\"][0][\"name\"])\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "def replace_word_in_file(file_path, target_word, new_word):\n",
        "    try:\n",
        "        # Open the file in read mode\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Read the file content\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Replace the target word with the new word\n",
        "        modified_content = file_content.replace(target_word, new_word)\n",
        "        modified_content = modified_content.replace(f'{gnn}-Impact-Subpack', 'ComfyUI-Impact-Subpack') #exeption\n",
        "\n",
        "        # Open the file in write mode to overwrite its content\n",
        "        with open(file_path, 'w') as file:\n",
        "            # Write the modified content back to the file\n",
        "            file.write(modified_content)\n",
        "\n",
        "        # print(f\"Word '{target_word}' replaced with '{new_word}' in {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}: {file_path}\")\n",
        "\n",
        "def forceCopyFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.copy2(sfile, dfile)\n",
        "\n",
        "def forceMoveFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.move(sfile, dfile)\n",
        "\n",
        "def isAFlatDir(sDir):\n",
        "    for item in os.listdir(sDir):\n",
        "        sItem = os.path.join(sDir, item)\n",
        "        if os.path.isdir(sItem):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def moveTree(src, dst, target_word='Comfy', new_word=gnn):\n",
        "    _dst = dst.replace(target_word, new_word)\n",
        "    _dst = _dst.replace(target_word.lower(), new_word.lower())\n",
        "\n",
        "    for item in os.listdir(src):\n",
        "        _item = item.replace(target_word, new_word)\n",
        "        _item = _item.replace(target_word.lower(), new_word.lower())\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(_dst, _item)\n",
        "\n",
        "        if os.path.isfile(s):\n",
        "            if not os.path.exists(_dst):\n",
        "                os.makedirs(_dst)\n",
        "            forceMoveFile(s,d)\n",
        "            replace_word_in_file(d, target_word, new_word)\n",
        "            replace_word_in_file(d, target_word.lower(), new_word.lower())\n",
        "        if os.path.isdir(s):\n",
        "            isRecursive = not isAFlatDir(s)\n",
        "            if isRecursive:\n",
        "                moveTree(s, d)\n",
        "            else:\n",
        "                if not os.path.exists(d):\n",
        "                    os.makedirs(d)\n",
        "                for item2 in os.listdir(s):\n",
        "                    _item = item2.replace(target_word, new_word)\n",
        "                    _item = _item.replace(target_word.lower(), new_word.lower())\n",
        "                    srcFile = os.path.join(s, item2)\n",
        "                    dstFile = os.path.join(d, _item)\n",
        "                    forceMoveFile(srcFile, dstFile)\n",
        "                    replace_word_in_file(dstFile, target_word, new_word)\n",
        "                    replace_word_in_file(dstFile, target_word.lower(), new_word.lower())\n",
        "\n"
      ],
      "metadata": {
        "id": "InBOxoWDlRhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Telegram Bot"
      ],
      "metadata": {
        "id": "APupapWeCXhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class TelegramTextBuilder:\n",
        "    def __init__(self):\n",
        "        self.parts = []\n",
        "\n",
        "    def _escape(self, text: str) -> str:\n",
        "        # Escape HTML special characters for Telegram HTML mode\n",
        "        escape_chars = {\n",
        "            '<': '&lt;',\n",
        "            '>': '&gt;',\n",
        "            '&': '&amp;',\n",
        "            '\"': '&quot;'\n",
        "        }\n",
        "        return ''.join(escape_chars.get(c, c) for c in text)\n",
        "\n",
        "    def plain(self, text: str):\n",
        "        self.parts.append(self._escape(text))\n",
        "        return self\n",
        "\n",
        "    def bold(self, text: str):\n",
        "        self.parts.append(f\"<b>{self._escape(text)}</b>\")\n",
        "        return self\n",
        "\n",
        "    def italic(self, text: str):\n",
        "        self.parts.append(f\"<i>{self._escape(text)}</i>\")\n",
        "        return self\n",
        "\n",
        "    def underline(self, text: str):\n",
        "        self.parts.append(f\"<u>{self._escape(text)}</u>\")\n",
        "        return self\n",
        "\n",
        "    def strikethrough(self, text: str):\n",
        "        self.parts.append(f\"<s>{self._escape(text)}</s>\")\n",
        "        return self\n",
        "\n",
        "    def spoiler(self, text: str):\n",
        "        self.parts.append(f\"<span class=\\\"tg-spoiler\\\">{self._escape(text)}</span>\")\n",
        "        return self\n",
        "\n",
        "    def code(self, text: str):\n",
        "        self.parts.append(f\"<code>{self._escape(text)}</code>\")\n",
        "        return self\n",
        "\n",
        "    def pre(self, text: str):\n",
        "        escaped = self._escape(text)\n",
        "        self.parts.append(f\"<pre>{escaped}</pre>\")\n",
        "        return self\n",
        "\n",
        "    def link(self, label: str, url: str):\n",
        "        self.parts.append(f\"<a href=\\\"{url}\\\">{self._escape(label)}</a>\")\n",
        "        return self\n",
        "\n",
        "    def mention(self, name: str, user_id: int):\n",
        "        self.parts.append(f\"<a href=\\\"tg://user?id={user_id}\\\">{self._escape(name)}</a>\")\n",
        "        return self\n",
        "\n",
        "    def quote(self, text: str, collapsible: bool = False, block: bool = False):\n",
        "        escaped = self._escape(text)\n",
        "        if collapsible:\n",
        "            # Collapse newlines into spaces for spoilers to ensure single block\n",
        "            single_line_text = ' '.join(escaped.split('\\n')).strip()\n",
        "            if block:\n",
        "                quoted_text = f\"<blockquote expandable>{self._escape(single_line_text)}</blockquote>\"\n",
        "            else:\n",
        "                quoted_text = f\"<span class=\\\"tg-spoiler\\\">{self._escape(single_line_text)}</span>\"\n",
        "        else:\n",
        "            # Non-collapsible quote\n",
        "            if block:\n",
        "                quoted_text = f\"<blockquote>{escaped}</blockquote>\"\n",
        "            else:\n",
        "                # For non-block quotes, wrap each line in <p> to mimic line-by-line quoting\n",
        "                quoted_text = ''.join(f\"<p>{line}</p>\" for line in escaped.split('\\n') if line)\n",
        "\n",
        "        self.parts.append(quoted_text)\n",
        "        return self\n",
        "\n",
        "    def new_line(self):\n",
        "        self.parts.append(\"\\n\")\n",
        "        return self\n",
        "\n",
        "    def build(self):\n",
        "        return ''.join(self.parts)"
      ],
      "metadata": {
        "id": "rhczEeSQyNYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes\n",
        "from telegram import Update, InputFile\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Store chat_ids for broadcast\n",
        "chat_ids = []\n",
        "\n",
        "# Create shutdown event globally\n",
        "shutdown_event = asyncio.Event()\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    chat_id = update.effective_chat.id\n",
        "    if chat_id not in chat_ids:\n",
        "        chat_ids.append(chat_id)\n",
        "    await update.message.reply_text(\"‚úÖ Bot started!\")\n",
        "\n",
        "async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    chat_id = update.effective_chat.id\n",
        "    if chat_id in chat_ids:\n",
        "        chat_ids.remove(chat_id)\n",
        "    await update.message.reply_text(\"‚úÖ Bot stopped!\")\n",
        "\n",
        "# Broadcast image to all registered users\n",
        "async def broadcast_image_to_telegram_bot(image, caption=None):\n",
        "    for chat_id in chat_ids:\n",
        "        try:\n",
        "            with open(image, \"rb\") as img:\n",
        "                if caption:\n",
        "                    await tb_app.bot.send_photo(chat_id=chat_id, photo=InputFile(img), caption=caption, parse_mode=\"HTML\")\n",
        "                else:\n",
        "                    await tb_app.bot.send_photo(chat_id=chat_id, photo=InputFile(img))\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to send image to {chat_id}: {e}\")\n",
        "\n",
        "# Build bot app\n",
        "# tb_app = ApplicationBuilder().token(\"8186324662:AAEaxnmaSu_mVYeC5NmZb7CPaRnBd0N8-Dk\").build()\n",
        "tb_app = ApplicationBuilder().token(\"8319818374:AAHyqXgS1ZqiVC1LZzFYWtw2vVou5kIo_cM\").build() # kamhotimbot\n",
        "tb_app.add_handler(CommandHandler(\"start\", start))\n",
        "tb_app.add_handler(CommandHandler(\"stop\", stop))\n",
        "\n",
        "# Telegram bot main async loop\n",
        "async def telegrambot_main():\n",
        "    print(\"üöÄ Starting Telegram Bot\")\n",
        "    await tb_app.initialize()\n",
        "    await tb_app.start()\n",
        "    await tb_app.updater.start_polling()\n",
        "    print(\"‚úÖ Telegram Bot is Running...\")\n",
        "\n",
        "    # Wait until shutdown_event is triggered\n",
        "    await shutdown_event.wait()\n",
        "\n",
        "    print(\"üîª Telegram Bot: Shutting down...\")\n",
        "    await tb_app.updater.stop()\n",
        "    await tb_app.stop()\n",
        "    await tb_app.shutdown()\n",
        "    print(\"‚úÖ Telegram Bot shut down cleanly.\")\n",
        "\n",
        "# Thread target to run the bot\n",
        "def run_tg_bot():\n",
        "    asyncio.run(telegrambot_main())\n",
        "\n",
        "# Start the bot in a background thread\n",
        "threading.Thread(target=run_tg_bot).start()\n"
      ],
      "metadata": {
        "id": "Jfg_eRaYJFOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model"
      ],
      "metadata": {
        "id": "oHhGb05cla8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown extensions (custom node)\n",
        "model_link = \"https://civitai.com/api/download/models/1057053\" # @param {\"type\":\"string\",\"placeholder\":\"enter link of model to download\"}\n",
        "model_name = \"seductiveorgasm.safetensors\" # @param {\"type\":\"string\",\"placeholder\":\"enter name of model\"}\n",
        "_model_type = \"LoRa\" # @param [\"Checkpoint\",\"LoRa\",\"ControlNet\", \"VAE\",\"None\"] {\"type\":\"string\"}\n",
        "\n",
        "if _model_type == \"LoRa\":\n",
        "    %cd {modelpaths.lora}\n",
        "    download(model_link, model_name, modelpaths.lora)\n",
        "elif _model_type == \"Checkpoint\":\n",
        "    %cd {modelpaths.model}\n",
        "    download(model_link, model_name, modelpaths.model)\n",
        "elif _model_type == \"ControlNet\":\n",
        "    %cd {modelpaths.controlnet}\n",
        "    download(model_link, model_name, modelpaths.controlnet)\n",
        "elif _model_type == \"VAE\":\n",
        "    %cd {modelpaths.controlnet}\n",
        "    download(model_link, model_name, modelpaths.vae)\n",
        "elif _model_type == \"None\":\n",
        "    %cd /content/\n",
        "    download(model_link, model_name, '/content')"
      ],
      "metadata": {
        "id": "kZKaq7b3eKha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaT0MBIsigWV"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JTcoxAqigWW"
      },
      "outputs": [],
      "source": [
        "# download('https://civitai.com/api/download/models/630522', 'symPonyWorld_v10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/828380', 'prefectPonyXL_v3.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/686204', 'realcartoonXL_v7.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1612720', 'waiNSFWIllustrious_v130.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/297740', 'dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors', modelpaths.model)\n",
        "\n",
        "download('https://civitai.com/api/download/models/1629649', 'fucktastic25DCheckpointPony_v20.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1111838', 'prefectiousXLNSFW_v10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/916744', 'ZavyChromaXL.V10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1150354', 'iniverseMixSFWNSFW_ponyRealGuofengV50C.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/641087', 'RealCartoon-Realistic_v17.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/798204', 'realvisxlV50_v50LightningBakedvae.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1183839', 'aniversePonyXL_v50.safetensors', modelpaths.model) #SDXL\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1183839', 'aniverse_v50Pruned.safetensors', modelpaths.model) #SD15\n",
        "\n",
        "# download('https://civitai.com/api/download/models/306531', 'hardcoreHentai13_v13Baked.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/253055', 'perfectdeliberate_v5.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/48949', 'camelliamixNSFW_v11.safetensors', modelpaths.model)\n",
        "# download('https://civitai.com/api/download/models/28569', 'klF8Anime2VAE_klF8Anime2VAE.safetensors', modelpaths.vae)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/51194', 'puffy_realisticV10.safetensors', modelpaths.model)\n",
        "\n",
        "# print(download_from_civitai(9942, 17233)) # AbyssOrangeMix3 (AOM3)\n",
        "\n",
        "# download('https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/VividOrangeMix/VividOrengeMix_Hard.safetensors?download=true', 'VividOrengeMix_Hard.safetensors', modelpaths.model)\n",
        "# download('https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt?download=true', 'orangemix.vae.pt', modelpaths.vae)\n",
        "\n",
        "if model_type == \"SD15\":\n",
        "    download('https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-8steps-lora.safetensors', 'Hyper-SD15-8steps-lora.safetensors', modelpaths.lora)\n",
        "elif model_type == \"SDXL\":\n",
        "    download('https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-8steps-lora.safetensors', 'Hyper-SDXL-8steps-lora.safetensors', modelpaths.lora)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUabsHbSTKF6"
      },
      "source": [
        "## LoRa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU43pGOkO8A3"
      },
      "outputs": [],
      "source": [
        "lora_list = []\n",
        "\n",
        "if model_type == \"SD15\":\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/122580', 'Skin-Hands.safetensors']) # Skin & Hands (male/female) from Polyhedron\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/117151', 'LEOSAMClothingAdjuster.safetensors']) # LEOSAM's Clothing +/- Adjuster LoRA\n",
        "    # lora_list.append(['https://huggingface.co/naonovn/Lora/resolve/main/add_detail.safetensors','add_detail.safetensors']) # add_detail LoRA\n",
        "\n",
        "    # 3D rendering style (SD 1.5)\n",
        "    # https://civitai.com/models/73756  Trigger Words: 3DMM\n",
        "    # The larger the version number, the more mature and realistic the rendering style will be.\n",
        "    lora_list.append(['https://civitai.com/api/download/models/107366','3DMM_V12.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78467','3DMM_V10.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/88206','3DMM_V7.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78559','3DMM_V5.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78564','3DMM_V3.safetensors'])\n",
        "\n",
        "    # Add More Details - Detail Enhancer / Tweaker\n",
        "    # https://civitai.com/models/82098/add-more-details-detail-enhancer-tweaker-lora\n",
        "    lora_list.append(['https://civitai.com/api/download/models/87153','AddMoreDetails-v1.safetensors'])\n",
        "\n",
        "    # sharpen/soften effect\n",
        "    # https://civitai.com/models/94543/lora-sharpensoften-effect-lora-model\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/100851?type=Model&format=SafeTensor','sharpen-soften effect-v1.safetensors'])\n",
        "\n",
        "    # S-shape body slider LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/135052/muggle-loras-shape-body-slider\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/148789?type=Model&format=SafeTensor','S-shape body slider-v1.safetensors'])\n",
        "\n",
        "    # Better eyes+face+skin LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/51430?modelVersionId=55905\n",
        "    lora_list.append(['https://civitai.com/api/download/models/55905','BetterEyesFaceSkin-v1.safetensors'])\n",
        "\n",
        "    # Hipoly 3D Model LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/70921/duchaitenniji\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/44566','Hipoly3D-v2.safetensors'])\n",
        "\n",
        "    # cowgirl with hands on knees\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/140297?type=Model&format=SafeTensor','cowgirl_with_hands_on_knees_v1.0.safetensors'])\n",
        "\n",
        "\n",
        "    # POV Squatting Cowgirl LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/10490','PSCowgirl.safetensors'])\n",
        "\n",
        "    # POV Missionary LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/37826','POVMissionary.safetensors'])\n",
        "\n",
        "    # POV Missionary Vaginal + Creampie LoRA LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/183382','MissionaryVaginal-v2.safetensors'])\n",
        "\n",
        "    # Upright straddle sex front view   Trigger Words:(1boy:1.1), sex, (hetero:1.3), sitting, girl on top, (straddling, upright straddle, vaginal, penis), pussy, pussy juice, leg lock, from behind, hug\n",
        "    lora_list.append(['https://civitai.com/api/download/models/191103','upright_front_above_50.safetensors'])\n",
        "\n",
        "    # Upright straddle sex - standard side view\n",
        "    lora_list.append(['https://civitai.com/api/download/models/109425','upright_straddle_20.safetensors'])\n",
        "\n",
        "    # Doggystyle (Side View)\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/34020','EkuneSideDoggy.safetensors'])\n",
        "\n",
        "    # yuzuriha (enhance related to SEX)\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/269824','yuzuriha_blush_face.safetensors'])\n",
        "\n",
        "    # colorfulhair2 LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/97974?type=Model&format=SafeTensor', 'asb-CH2.safetensors'])\n",
        "\n",
        "    # Half Color Hair LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/45686','hlfcol.safetensors'])\n",
        "\n",
        "    # color hair LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/113573?type=Model&format=SafeTensor','color-hair.safetensors'])\n",
        "elif model_type == \"SDXL\":\n",
        "    # Samaritan 3d Cartoon SDXL\n",
        "    # https://civitai.com/models/121932/samaritan-3d-cartoon-sdxl\n",
        "    # the default face is grumpy/angry for some reason. But this model was trained on variety of emotions,\n",
        "    # try \"smiling, laugh,sad, crying, shouting, surprised, etc\" in the prompt\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/132727','Samaritan-3d-Cartoon-xl.safetensors'])\n",
        "\n",
        "    # xl-water-dress\n",
        "    # https://civitai.com/models/156447/xl-water-dress\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/175608','xl-water-dress.safetensors'])\n",
        "\n",
        "    # xl_more_art-full\n",
        "    # https://civitai.com/models/124347/xlmoreart-full-xlreal-enhancer?modelVersionId=152309\n",
        "    lora_list.append(['https://civitai.com/api/download/models/152309','xl_more_art-full-v1.safetensors'])\n",
        "\n",
        "    # Penetration Depth Slider - Pony/SDXL\n",
        "    # https://civitai.com/models/485121?modelVersionId=539502\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/539502','Insertion_Slider_alpha1.safetensors'])\n",
        "\n",
        "    # NSFW POV All In One SDXL\n",
        "    # https://civitai.com/models/144203?modelVersionId=160240\n",
        "    lora_list.append(['https://civitai.com/api/download/models/160240?','NsfwPovAllInOneLoraSdxl-000009.safetensors'])\n",
        "\n",
        "    # Breast Size Slider - SDXL\n",
        "    # https://civitai.com/models/481119/breast-size-slider-sdxl\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/535064','BreastSlider_SDXL.safetensors'])\n",
        "\n",
        "    # Detail Tweaker XL\n",
        "    # https://civitai.com/models/122359/detail-tweaker-xl\n",
        "    lora_list.append(['https://civitai.com/api/download/models/135867','DetailTweaker-XL-V1.safetensors'])\n",
        "\n",
        "    lora_list.append(['https://civitai.com/api/download/models/382152','Expressive_H-000001.safetensors']) # ExpressiveH (Hentai LoRa Style)\n",
        "    lora_list.append(['https://civitai.com/api/download/models/703107','3DMM_XL_V13.safetensors']) # 3D rendering style : keywords:3DMM\n",
        "    lora_list.append(['https://civitai.com/api/download/models/128461','PerfectEyesXL.safetensors']) # Perfect Eyes XL : keywords:perfecteyes\n",
        "    lora_list.append(['https://civitai.com/api/download/models/670719','Rendered_Face_Detailer_v1.0.safetensors']) # Rendered Face Detailer SDXL : keywords:7-cgifaces\n",
        "    lora_list.append(['https://civitai.com/api/download/models/469461','Upright_front_above_2-000012.safetensors']) # Upright straddle sex front view : keywords:1boy, sex, hetero, upright straddle, straddling, girl on top\n",
        "    lora_list.append(['https://civitai.com/api/download/models/383563','detailed_notrigger.safetensors']) # detailed\n",
        "    lora_list.append(['https://civitai.com/api/download/models/259830','aesthetic.safetensors']) # Aesthetic SDXL : keywords:aesthetic\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1622964','AddMicroDetails_Illustrious_v3.safetensors']) # Add Micro Details - Concept (Illustrious / Pony) : keywords:addmicrodetails\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1640138','Urban_Fusion_IL.safetensors']) # Urban_Fusion_IL : Strength: 0.8\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1615226','CreateConcept_Illustrious_v2.safetensors']) # Create Concept - Concept (Illustrious) : Strength: 0.8 : keywords:createconcept, addmicrodetails\n",
        "    lora_list.append(['https://civitai.com/api/download/models/947620','cfg_scale_boost.safetensors']) # Control LoRA Collection : Strength: 0.4\n",
        "\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/126785','WowifierXL.safetensors']) # WowifierXL LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/155625','Caricaturized-xl.safetensors']) # SDXL Caricaturized LoRA\n",
        "\n",
        "elif model_type == \"Flux. 1 dev\":\n",
        "    lora_list.append(['https://civitai.com/api/download/models/996543','vaginalsexlora.safetensors'])\n",
        "    lora_list.append(['https://civitai.com/api/download/models/746602','NSFW_master.safetensors'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qf_1-GCqcVt"
      },
      "source": [
        "# Run KMUI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setting\n",
        "\n",
        "#@markdown # UI\n",
        "#@markdown extensions (custom node)\n",
        "ReactorNode = False #@param {type:'boolean'}\n",
        "ControlnetAux = False #@param {type:'boolean'}\n",
        "#@markdown download\n",
        "DownloadEmbeddings = False #@param {type:'boolean'}\n",
        "DownloadLoRa = True #@param {type:'boolean'}\n",
        "DownloadVAE = False #@param {type:'boolean'}\n",
        "Clip_Vision_g = False #@param {type:'boolean'}"
      ],
      "metadata": {
        "id": "IzWiMDvTKPqO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_dX9-EbDiXA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download models\n",
        "if DownloadEmbeddings:\n",
        "    !wget -q 'https://huggingface.co/nolanaatama/colab/resolve/main/embeddings.zip' -P /content/{gn()}/models/embeddings/\n",
        "    with zipfile.ZipFile(f\"/content/{gn()}/models/embeddings/embeddings.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(f'/content/{gn()}/models')\n",
        "    os.remove(f\"/content/{gn()}/models/embeddings/embeddings.zip\")\n",
        "\n",
        "if DownloadLoRa:\n",
        "    %cd {lora_path}\n",
        "    for item in lora_list:\n",
        "      download(item[0], item[1], modelpaths.lora)\n",
        "\n",
        "if DownloadVAE:\n",
        "    download('https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt', 'vae-ft-mse-840000-ema-pruned.ckpt', modelpaths.vae)\n",
        "\n",
        "# if ReactorNode:\n",
        "#     download(\"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\", 'GFPGANv1.4.pth', f'{modelpaths.base_path}/facerestore_models')\n",
        "#     download(\"https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\", 'inswapper_128.onnx', f'{modelpaths.base_path}/insightface')\n",
        "\n",
        "# clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rld0qAZAfPg0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prepare workflow\n",
        "\n",
        "%cd /content\n",
        "!apt -y update -qq\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "# !pip install -q mediapipe==0.9.1.0 addict yapf fvcore omegaconf\n",
        "\n",
        "!git clone https://github.com/comfyanonymous/{gn()}\n",
        "!git clone -b totoro4 https://github.com/camenduru/{gn()} /content/TotoroUI\n",
        "if not os.path.exists('/content/TotoroUI/custom_nodes'):\n",
        "    os.makedirs('/content/TotoroUI/custom_nodes')\n",
        "\n",
        "%cd /content/TotoroUI/custom_nodes\n",
        "!git clone https://github.com/city96/ComfyUi-GGUF ComfyUi_GGUF\n",
        "moveTree(f'/content/TotoroUI/custom_nodes/ComfyUi_GGUF', f'/content/TotoroUI/custom_nodes/totoro_GGUF', target_word='Comfy', new_word='totoro')\n",
        "\n",
        "%cd /content/{gn()}/custom_nodes\n",
        "!git clone https://github.com/city96/{gn()}-GGUF {gn()[:-2]}_GGUF\n",
        "\n",
        "if ControlnetAux:\n",
        "    !git clone https://github.com/Fannovel16{gn()}_controlnet_aux/\n",
        "\n",
        "if ReactorNode:\n",
        "    !git clone https://github.com/Gourieff/{gn()}-reactor-node {gn()[:-2]}_reactor_node\n",
        "\n",
        "moveTree(f'/content/{gn()}', f'/content/{gnn}')\n",
        "shutil.rmtree(f'/content/{gn()}')\n",
        "\n",
        "# install requirements\n",
        "%cd /content/{gnn}\n",
        "# C_omfy\n",
        "!pip install torch torchsde torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu128\n",
        "!pip install -r requirements.txt #--extra-index-url https://download.pytorch.org/whl/cu122\n",
        "!pip install tokenizers==0.21\n",
        "!pip install av\n",
        "# !pip install torchsde\n",
        "# !pip install spandrel\n",
        "\n",
        "%cd /content/{gnn}/custom_nodes\n",
        "\n",
        "!pip install -r {gnn}_GGUF/requirements.txt\n",
        "\n",
        "# reactor-node\n",
        "if ReactorNode:\n",
        "    !pip install -r {gnn}_reactor_node/requirements.txt\n",
        "    !python {gnn}_reactor_node/install.py\n",
        "\n",
        "\n",
        "# controlnet_aux\n",
        "if ControlnetAux:\n",
        "    !pip install -r {gnn}_controlnet_aux/requirements.txt\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb8G2WauywJu"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-6yNrqCkO0i"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# shutil.move('/content/KMUI-1/output', '/content/KMUI')\n",
        "# shutil.move('/content/KMUI/models', '/content/models')\n",
        "# shutil.move('/content/KMUI/models', '/content/TotoroUI/models')\n",
        "# shutil.rmtree('/content/KMUI-1')\n",
        "shutil.rmtree('/content/drive/MyDrive/AI/KHidden.mail_Generated/2025-05-18')\n",
        "# shutil.rmtree('/content/drive')\n",
        "os.mkdir('/content/drive/MyDrive/AI/KHidden.mail_Generated/2025-05-18')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  from google.colab import drive\n",
        "\n",
        "  print(\"Mounting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "#   drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "4koCPO-rFglK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfgnf3GbPcoK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Saving images\n",
        "\n",
        "#@markdown <small>The zip file will be visible at the files tab.</small>\n",
        "from datetime import datetime\n",
        "str_date = datetime.today().strftime('%Y-%m-%d-%H%M%S')\n",
        "archive_name = f\"outputs-{str_date}.zip\"\n",
        "\n",
        "print(\"Zipping...\")\n",
        "!zip -qr /content/{archive_name} /content/drive/MyDrive/AI/KHidden.mail_Generated/2025-01-01\n",
        "print(f\"\\033[92mZipped. You can now find {archive_name} at the files tab.\\033[0m\")\n",
        "\n",
        "# ----\n",
        "\n",
        "#@markdown <small>This copies the zip file to your Google Drive</small>\n",
        "copy_to_gdrive = False #@param {type:'boolean'}\n",
        "gdrive_folder = \"AI/Generated\" #@param { 'type': 'string' }\n",
        "\n",
        "if copy_to_gdrive:\n",
        "  # utility.log_usage('zip-to-gdrive')\n",
        "  from google.colab import drive\n",
        "\n",
        "  print(\"Mounting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "  if gdrive_folder == \"\":\n",
        "    gdrive_folder = \"AI/Generated\"\n",
        "\n",
        "  drive_folder = f\"/content/drive/MyDrive/{gdrive_folder}\"\n",
        "\n",
        "  !mkdir -p {drive_folder}\n",
        "  !cp /content/{archive_name} {drive_folder}\n",
        "  print(f\"\\033[92mCopied to {gdrive_folder}!\\033[0m\")\n",
        "\n",
        "  drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ai Model for generate prompt\n",
        "Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF"
      ],
      "metadata": {
        "id": "u6v6g3pXAjMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi\n",
        "# !pip install crewai\n",
        "# !pip install numpy==1.24.4\n",
        "!pip install llama-cpp-python==v0.2.90 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "# !pip install llama-cpp-python==v0.3.0 --upgrade --force-reinstall --no-cache-dir --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "\n",
        "# from huggingface_hub import login\n",
        "# login(token='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')  # Replace with your actual token\n",
        "\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/prompt_style_positive.txt?download=true', 'prompt_style_positive.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/prompt_style.txt?download=true', 'prompt_style.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/lora.txt?download=true', 'lora.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/lora_prompt.txt?download=true', 'lora_prompt.txt', '/content')\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Hnx8jVY6ChsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "class PromptGenerator:\n",
        "    chat_history = []\n",
        "\n",
        "    class Item:\n",
        "        prompt: str\n",
        "        temperature: float = 1.2\n",
        "        max_new_tokens: int = 1024\n",
        "        seed : int = 43\n",
        "\n",
        "    def __init__(self, n_ctx, lora_list, basemodel):\n",
        "        self.system_prompt = read_file('/content/prompt_style_positive.txt')\n",
        "        self.system_lora_prompt = read_file('/content/lora_prompt.txt')\n",
        "        self.lora_list = self._get_lora_list(lora_list, basemodel) if basemodel else []\n",
        "        self.len_chat_history = 0\n",
        "        self.chat_history = []\n",
        "\n",
        "        # model_id = \"failspy/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF\"\n",
        "        # filename=\"*-v3_q6.gguf\"\n",
        "        model_id = \"mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF\"\n",
        "        # filename=\"*Q6_K.gguf\"\n",
        "        filename=\"*Q8_0.gguf\"\n",
        "        model_id = \"mlabonne/Hermes-3-Llama-3.1-8B-lorablated-GGUF\"\n",
        "        self.model = Llama.from_pretrained(repo_id=model_id, filename=filename, n_gpu_layers=-1, n_ctx=n_ctx, verbose=False)\n",
        "\n",
        "    def _get_lora_list(self, l_list, basemodel):\n",
        "        lora_list = []\n",
        "        for it in l_list:\n",
        "            if it[\"baseModel\"] == basemodel:\n",
        "                item = {\n",
        "                    \"id\": it[\"id\"],\n",
        "                    \"name\": it[\"name\"],\n",
        "                    \"tags\": it[\"tags\"],\n",
        "                    \"weights\": it[\"weights\"]\n",
        "                }\n",
        "                try:\n",
        "                    item[\"trainedWords\"] = it[\"trainedWords\"]\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                lora_list.append(item)\n",
        "        return json.dumps(lora_list)\n",
        "\n",
        "\n",
        "    def list_json_extractor_from_text(self, text):\n",
        "        text = text.replace(\" '\", ' \"').replace(\"' \", '\" ').replace(\"{'\", '{\"').replace(\"'}\", '\"}').replace(\"':\", '\":')\n",
        "        text = text.replace(\"',\", '\",')\n",
        "        start_index = text.find('[')\n",
        "        end_index = text.rfind(']')\n",
        "        if end_index == -1:  # If no closing '}' is found\n",
        "            text += '\"]'  # Add missing closing brace\n",
        "            end_index = len(text)   # Set end_index to the new last character\n",
        "\n",
        "        # Step 3: Extract the JSON part from the start index to the end index\n",
        "        json_string = text[start_index:end_index + 1].strip()\n",
        "\n",
        "        try:\n",
        "            # Parse the JSON string\n",
        "            return json.loads(json_string)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"error in json_extractor_from_text: {e}, try another way\")\n",
        "            pattern = re.compile(r'\\{\"id\":\\s*(\\d+),\\s*\"weights\":\\s*([0-9.]+)\\}')\n",
        "            matches = pattern.findall(json_string)\n",
        "\n",
        "            # Convert matches to list of dictionaries\n",
        "            valid_items = [{\"id\": int(match[0]), \"weights\": float(match[1])} for match in matches]\n",
        "            return valid_items if len(valid_items) > 0 else None\n",
        "\n",
        "    def truncate_list_and_append(self, new_string):\n",
        "        \"\"\"Truncate strings in the list such that their total length does not exceed 4096 characters,\n",
        "        and append `new_string` to the list while removing the first element if necessary.\n",
        "        \"\"\"\n",
        "        ln = len(''.join(new_string))\n",
        "        max_sum = 1024 * 4\n",
        "        if len(self.chat_history) == 0:\n",
        "            self.len_chat_history = ln\n",
        "            self.chat_history.append(new_string)\n",
        "            return\n",
        "        if ln > max_sum:\n",
        "            self.len_chat_history = ln\n",
        "            self.chat_history.clear()\n",
        "            self.chat_history.append(new_string)\n",
        "            return\n",
        "\n",
        "        while len(self.chat_history) > 0 and ln + self.len_chat_history > max_sum:\n",
        "            self.len_chat_history -= len(''.join(self.chat_history.pop(1)))\n",
        "            print('removing from chat_history!')\n",
        "        self.chat_history.append(new_string)\n",
        "        self.len_chat_history += ln\n",
        "\n",
        "    def free_memory(self):\n",
        "        self.model.reset()\n",
        "        self.model.set_cache(None)\n",
        "        del self.model\n",
        "        self.model = None\n",
        "\n",
        "    def format_prompt(self, item: Item, system_prompt, chat_history):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "        ]\n",
        "        for it in chat_history:\n",
        "            messages.append({\"role\" : \"user\", \"content\": it[0]})\n",
        "            messages.append({\"role\" : \"assistant\", \"content\": it[1]})\n",
        "        messages.append({\"role\" : \"user\", \"content\": item.prompt})\n",
        "        return messages\n",
        "\n",
        "    def generate_prompt(self, prompt, seed=4, use_system_prompt=True):\n",
        "        item = PromptGenerator.Item()\n",
        "        item.seed=seed\n",
        "        item.prompt = prompt\n",
        "\n",
        "        formatted_prompt = self.format_prompt(item, self.system_prompt if use_system_prompt else 'You are prompt creator', self.chat_history)\n",
        "        output = self.model.create_chat_completion(messages=formatted_prompt, seed=item.seed, temperature=item.temperature,\n",
        "                                              max_tokens=item.max_new_tokens)\n",
        "\n",
        "\n",
        "        answer = output['choices'][0]['message']['content']\n",
        "        if answer:\n",
        "            self.truncate_list_and_append([str(item.prompt), str(answer)])\n",
        "        return answer, output\n",
        "\n",
        "    def generate_lora_list(self, prompt, seed=4):\n",
        "        if len(self.lora_list) ==0:\n",
        "            print('no base model provided !!!')\n",
        "            return None\n",
        "\n",
        "        item = PromptGenerator.Item()\n",
        "        item.seed=seed\n",
        "        item.prompt = prompt\n",
        "\n",
        "        chat_history = [\n",
        "            ['Please provide me a list of loras', str(self.lora_list)],\n",
        "            ['Please go ahead and give me the prompt in the specified JSON format.', str(json.dumps(prompt))],\n",
        "        ]\n",
        "        formatted_prompt = self.format_prompt(item, self.system_lora_prompt, chat_history)\n",
        "        output = self.model.create_chat_completion(messages=formatted_prompt, seed=item.seed, temperature=item.temperature,\n",
        "                                              max_tokens=item.max_new_tokens)\n",
        "\n",
        "\n",
        "        out = output['choices'][0]['message']['content']\n",
        "        answer = self.list_json_extractor_from_text(str(out))\n",
        "        return answer, out\n",
        "\n",
        "    def clear_history(self):\n",
        "        self.chat_history.clear()\n",
        "\n",
        "TEST_AI = True\n",
        "if TEST_AI:\n",
        "    try:\n",
        "        if promptGenerator:\n",
        "            promptGenerator.free_memory()\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    # lora_list = json.loads(read_file('/content/lora.txt'))\n",
        "    # promptGenerator = PromptGenerator(lora_list, basemodel='SDXL 1.0')\n",
        "\n",
        "    print('Start loading Prompt Generator Ai')\n",
        "    t1 = time.time()\n",
        "\n",
        "    base_model = None\n",
        "    if model_type == \"SDXL\":\n",
        "        base_model = 'SDXL 1.0'\n",
        "    elif model_type == \"SD15\":\n",
        "        base_model = 'SD 1.5'\n",
        "\n",
        "    n_ctx = 4 * 1024\n",
        "    promptGenerator = PromptGenerator(n_ctx=n_ctx, lora_list=None, basemodel=None)\n",
        "    print(f'Prompt Generator Ai loaded in {str(round(time.time() - t1, 1))} second.')"
      ],
      "metadata": {
        "id": "_oSVT4RRAtxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mass Prompt Generator"
      ],
      "metadata": {
        "id": "StghNPhX1mbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### definition class"
      ],
      "metadata": {
        "id": "0lUh9isl1yEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Callable, Tuple\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class AIPromptGenerator:\n",
        "    def __init__(self, generate_prompt_fn: Callable):\n",
        "        \"\"\"\n",
        "        Initialize the prompt generator with a function to access local AI.\n",
        "\n",
        "        Args:\n",
        "            generate_prompt_fn: Function that takes (prompt, seed) and returns AI-generated prompt\n",
        "        \"\"\"\n",
        "        self.generate_prompt_fn = generate_prompt_fn\n",
        "        # Expanded keyword sets with weights\n",
        "        self.keyword_sets = {\n",
        "            'color': [\n",
        "                (\"red\", 0.1), (\"black\", 0.1), (\"purple\", 0.1), (\"yellow\", 0.1), (\"pink\", 0.1),\n",
        "                (\"green\", 0.1), (\"blue\", 0.1), (\"silver\", 0.1), (\"gold\", 0.1), (\"gray\", 0.1),\n",
        "                (\"white\", 0.1), (\"brown\", 0.1), (\"orange\", 0.1), (\"violet\", 0.1)\n",
        "            ],\n",
        "            'hair_style': [\n",
        "                (\"ponytail\", 0.1), (\"messy\", 0.1), (\"bob cut\", 0.1), (\"braid ponytail\", 0.1),\n",
        "                (\"long\", 0.1), (\"short\", 0.1), (\"wavy\", 0.1), (\"straight\", 0.1), (\"curly\", 0.1),\n",
        "                (\"spiky\", 0.1), (\"bun\", 0.1), (\"twin tails\", 0.1), (\"princess curls\", 0.1)\n",
        "            ],\n",
        "            'erotic': [\n",
        "                (\"seductive pose\", 0.2), (\"provocative\", 0.15), (\"alluring\", 0.15), (\"suggestive\", 0.15),\n",
        "                (\"cleavage\", 0.2), (\"erotic\", 0.16), (\"spread legs\", 0.15), (\"open legs\", 0.15)\n",
        "            ],\n",
        "            'nipples': [\n",
        "                (\"visible nipples\", 0.2), (\"puffy nipples\", 0.2), (\"covered nipples\", 0.2),\n",
        "                (\"hard nipples\", 0.2), (\"nipple slip\", 0.15)\n",
        "            ],\n",
        "            'sexual': [\n",
        "                (\"nude\", 0.2), (\"half nude\", 0.2), (\"bare breasts\", 0.15), (\"exposed\", 0.15),\n",
        "                (\"genitals visible\", 0.2), (\"cum\", 0.15), (\"topless\", 0.2)\n",
        "            ],\n",
        "            'sensual': [\n",
        "                (\"pleasure\", 0.2), (\"ecstasy\", 0.15), (\"arousal\", 0.15), (\"desire\", 0.2),\n",
        "                (\"lust\", 0.2), (\"moaning\", 0.2), (\"heavy breathing\", 0.2), (\"bliss\", 0.2)\n",
        "            ],\n",
        "            'sex_position': [\n",
        "                (\"missionary position\", 0.15), (\"cowgirl position\", 0.15), (\"doggy style position\", 0.15), (\"spooning  position\", 0.15),\n",
        "                (\"reverse cowgirl\", 0.15), (\"lotus position\", 0.15), (\"standing position\", 0.15), (\"69 position\", 0.1),\n",
        "                (\"against wall position\", 0.15), (\"Pretzel Dip position\", 0.15), (\"Scissoring position\", 0.15), (\"Anvil position\", 0.15),\n",
        "                (\"Flatiron position\", 0.15), (\"Corkscrew position\", 0.15), (\"Leapfrog position\", 0.15), (\"Magic Mountain position\", 0.15),\n",
        "            ],\n",
        "            'action': [\n",
        "                (\"kissing\", 0.15), (\"fondling\", 0.15), (\"licking\", 0.15), (\"stroking\", 0.15),\n",
        "                (\"grinding\", 0.15), (\"embracing\", 0.15), (\"thrusting\", 0.15), (\"biting\", 0.15),\n",
        "                (\"touching self\", 0.15), (\"fucking\", 0.2), (\"inserting\", 0.2),\n",
        "            ],\n",
        "            'pose': [\n",
        "                # Standing Poses\n",
        "                (\"standing straight\", 0.07), (\"relaxed standing\", 0.07), (\"arms crossed\", 0.07),\n",
        "                (\"hands in pockets\", 0.07), (\"leaning against a wall\", 0.07), (\"hands on hips\", 0.07),\n",
        "                (\"hands above head\", 0.07), (\"bending forward\", 0.07), (\"standing on one leg\", 0.07),\n",
        "                # Sitting Poses\n",
        "                (\"sitting on a chair\", 0.07), (\"sitting cross-legged\", 0.06), (\"sitting on knees\", 0.06),\n",
        "                (\"slouched on a chair\", 0.07), (\"sitting on the edge of a chair\", 0.07),\n",
        "                (\"sitting with knees to the side\", 0.07), (\"sitting with legs stretched\", 0.07),\n",
        "                (\"sitting with legs crossed\", 0.07),\n",
        "                # Lying Poses\n",
        "                (\"lying on the back\", 0.07), (\"lying on the stomach\", 0.07), (\"lying on the side\", 0.07),\n",
        "                (\"curled up\", 0.07), (\"reclining\", 0.07),\n",
        "                # Action/Movement Poses\n",
        "                (\"walking\", 0.07), (\"running\", 0.07), (\"jumping\", 0.07), (\"pulling something\", 0.07),\n",
        "                (\"pushing something\", 0.07), (\"climbing\", 0.07), (\"falling\", 0.07), (\"dancing\", 0.07),\n",
        "                # Hand & Body Gestures\n",
        "                (\"arms raised\", 0.07), (\"hands on face\", 0.07), (\"on all fours\", 0.07), (\"hugging knees\", 0.07),\n",
        "                (\"pointing\", 0.07), (\"hands clasped together\", 0.07), (\"waving\", 0.07),\n",
        "                # Emotional/Expressive Poses\n",
        "                (\"bent over with hands on knees\", 0.07), (\"kneeling on the ground\", 0.07),\n",
        "                (\"leaning to the side\", 0.07), (\"balancing\", 0.07), (\"fighting stance\", 0.07)\n",
        "            ],\n",
        "            'body': [\n",
        "                (\"curvy\", 0.15), (\"voluptuous\", 0.15), (\"athletic\", 0.15), (\"petite\", 0.1),\n",
        "                (\"slim\", 0.15), (\"hourglass figure\", 0.1), (\"chubby\", 0.1)\n",
        "            ],\n",
        "            'dress': [\n",
        "                (\"lingerie\", 0.1), (\"bikini\", 0.1), (\"maid outfit\", 0.1), (\"school uniform\", 0.1),\n",
        "                (\"kimono\", 0.1), (\"stockings\", 0.1), (\"leotard\", 0.1), (\"transparent clothes\", 0.1),\n",
        "                (\"naked\", 0.1), (\"half naked\", 0.1), (\"ripped clothes\", 0.1), (\"panties\", 0.1)\n",
        "            ],\n",
        "            'camera': [\n",
        "                (\"front view\", 0.2), (\"side view\", 0.2), (\"POV\", 0.2), (\"close-up\", 0.2),\n",
        "                (\"medium shot\", 0.2), (\"wide shot\", 0.2), (\"aerial view\", 0.2)\n",
        "            ],\n",
        "            'age': [\n",
        "                (\"young woman\", 0.3), (\"teen\", 0.2), (\"20s\", 0.2), (\"30s\", 0.2), (\"young adult\", 0.1)\n",
        "            ],\n",
        "            'race': [\n",
        "                (\"human\", 0.5), (\"elf\", 0.15), (\"demon\", 0.1), (\"angel\", 0.1), (\"catgirl\", 0.1),\n",
        "                (\"bunny girl\", 0.1), (\"mermaid\", 0.1), (\"vampire\", 0.1)\n",
        "            ],\n",
        "            'lighting': [\n",
        "                (\"soft light\", 0.2), (\"moonlight\", 0.2), (\"sunlight\", 0.2), (\"candlelight\", 0.15),\n",
        "                (\"neon lights\", 0.15), (\"dim lighting\", 0.1), (\"backlight\", 0.1)\n",
        "            ],\n",
        "            'expression': [\n",
        "                (\"seductive\", 0.2), (\"confident\", 0.2), (\"shy\", 0.15), (\"lust\", 0.15),\n",
        "                (\"desire\", 0.15), (\"submissive\", 0.15), (\"embarrassed\", 0.15)\n",
        "            ],\n",
        "            'accessories': [\n",
        "                (\"choker\", 0.2), (\"high heels\", 0.2), (\"stockings\", 0.15), (\"gloves\", 0.2),\n",
        "                (\"ribbon\", 0.15), (\"piercings\", 0.1), (\"collar\", 0.05), (\"leash\", 0.2)\n",
        "            ],\n",
        "            'environment': [\n",
        "                (\"bedroom\", 0.2), (\"beach\", 0.2), (\"forest\", 0.2), (\"shower\", 0.2),\n",
        "                (\"castle\", 0.2), (\"school\", 0.2), (\"dungeon\", 0.2), (\"pool\", 0.2),\n",
        "                (\"hospital\", 0.2), (\"office\", 0.2)\n",
        "            ],\n",
        "            'mood': [\n",
        "                (\"romantic\", 0.2), (\"mysterious\", 0.2), (\"intimate\", 0.2), (\"playful\", 0.15),\n",
        "                (\"dark\", 0.1), (\"dreamy\", 0.2), (\"passionate\", 0.2)\n",
        "            ],\n",
        "            'texture': [\n",
        "                (\"silky\", 0.2), (\"velvet\", 0.2), (\"lace\", 0.15), (\"satin\", 0.15),\n",
        "                (\"leather\", 0.15), (\"sheer\", 0.15), (\"soft\", 0.2)\n",
        "            ],\n",
        "            'background_details': [\n",
        "                (\"candles\", 0.15), (\"flowers\", 0.15), (\"mirrors\", 0.15), (\"curtains\", 0.15),\n",
        "                (\"fog\", 0.15), (\"stars\", 0.1), (\"petals\", 0.15), (\"vines\", 0.05)\n",
        "            ]\n",
        "\n",
        "            'art_style': [\n",
        "                (\"anime\", 0.2), (\"realistic\", 0.2), (\"fantasy art\", 0.2), (\"cyberpunk\", 0.2),\n",
        "                (\"3D render\", 0.2),(\"surreal\", 0.2)\n",
        "            ],\n",
        "            'time_of_day': [\n",
        "                (\"daytime\", 0.25), (\"night\", 0.25), (\"sunset\", 0.2), (\"dawn\", 0.2),\n",
        "                (\"twilight\", 0.2), (\"midnight\", 0.2)\n",
        "            ],\n",
        "            'weather': [\n",
        "                (\"clear sky\", 0.3), (\"rainy\", 0.2), (\"foggy\", 0.15), (\"stormy\", 0.15),\n",
        "                (\"snowy\", 0.2), (\"cloudy\", 0.2), (\"windy\", 0.2)\n",
        "            ],\n",
        "            'emotion': [\n",
        "                (\"joyful\", 0.2), (\"melancholic\", 0.2), (\"confident\", 0.2), (\"vulnerable\", 0.2),\n",
        "                (\"introspective\", 0.2), (\"playful\", 0.2), (\"mysterious\", 0.2), (\"angry\", 0.1),\n",
        "                (\"serene\", 0.2), (\"anxious\", 0.15)\n",
        "            ],\n",
        "            'props': [\n",
        "                (\"book\", 0.15), (\"mirror\", 0.15), (\"sword\", 0.1), (\"flowers\", 0.1),\n",
        "                (\"wine glass\", 0.1), (\"candle\", 0.1), (\"umbrella\", 0.1), (\"fan\", 0.1),\n",
        "                (\"jewelry box\", 0.1), (\"musical instrument\", 0.1)\n",
        "            ],\n",
        "            'facial_features': [\n",
        "                (\"freckles\", 0.2), (\"sharp cheekbones\", 0.2), (\"soft lips\", 0.2), (\"piercing eyes\", 0.2),\n",
        "                (\"long eyelashes\", 0.2), (\"scar\", 0.2), (\"tattoo on face\", 0.2), (\"blushing cheeks\", 0.2)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Expanded incompatible keyword pairs\n",
        "        self.incompatible_pairs = [\n",
        "            (['naked', 'half naked', 'nude', 'topless', 'bare breasts'],\n",
        "             ['lingerie', 'bikini', 'maid outfit', 'school uniform', 'kimono', 'leotard']),\n",
        "            (['slim', 'athletic', 'petite'], ['chubby', 'voluptuous']),\n",
        "            (['shy', 'embarrassed'], ['confident', 'dominant']),\n",
        "            (['naked', 'nude'], ['accessories', 'stockings', 'high heels', 'gloves']),\n",
        "            (['missionary', 'cowgirl', 'doggy style', 'reverse cowgirl', 'spooning', 'lotus position', '69'],\n",
        "             ['standing straight', 'relaxed standing', 'arms crossed', 'hands in pockets', 'leaning against a wall',\n",
        "              'hands on hips', 'hands above head', 'standing on one leg', 'walking', 'running', 'jumping']),\n",
        "            (['pleasure', 'ecstasy', 'bliss'], ['pain']),\n",
        "            (['teen'], ['mature', 'middle-aged']),\n",
        "            (['sitting on a chair', 'sitting cross-legged', 'sitting on knees', 'slouched on a chair',\n",
        "              'sitting on the edge of a chair', 'sitting with knees to the side', 'sitting with legs stretched',\n",
        "              'sitting with legs crossed'],\n",
        "             ['lying on the back', 'lying on the stomach', 'lying on the side', 'curled up', 'reclining']),\n",
        "            (['lying on the back', 'lying on the stomach', 'lying on the side', 'curled up', 'reclining'],\n",
        "             ['walking', 'running', 'jumping', 'climbing', 'fighting stance'])\n",
        "            (['night', 'midnight'], ['sunlight', 'daytime']),\n",
        "            (['daytime', 'sunset', 'dawn'], ['moonlight', 'neon lights']),\n",
        "            (['rainy', 'stormy', 'snowy', 'foggy'], ['bedroom', 'hospital', 'office']),\n",
        "            (['joyful', 'playful', 'serene'], ['melancholic', 'angry', 'anxious']),\n",
        "            (['sword', 'musical instrument'], ['naked', 'half naked', 'nude']),\n",
        "            (['book', 'wine glass', 'fan'], ['running', 'jumping', 'fighting stance'])\n",
        "        ]\n",
        "\n",
        "        self.main_keywords = \"masterpiece, best quality, ultra detailed, 8k, intricate, highly detailed, cinematic, vibrant\"\n",
        "        self.max_prompt_length = 150  # StableDiffusion token limit\n",
        "\n",
        "    def add_keyword_set(self, category: str, keywords: List[Tuple[str, float]]) -> None:\n",
        "        \"\"\"\n",
        "        Add or extend a keyword set with weighted probabilities.\n",
        "\n",
        "        Args:\n",
        "            category: The keyword category\n",
        "            keywords: List of (keyword, weight) tuples\n",
        "        \"\"\"\n",
        "        total_weight = sum(weight for _, weight in keywords)\n",
        "        if abs(total_weight - 1.0) > 0.01:\n",
        "            logging.warning(f\"Keyword weights for {category} do not sum to 1.0, normalizing...\")\n",
        "            keywords = [(kw, w/total_weight) for kw, w in keywords]\n",
        "\n",
        "        if category in self.keyword_sets:\n",
        "            self.keyword_sets[category].extend(keywords)\n",
        "        else:\n",
        "            self.keyword_sets[category] = keywords\n",
        "        logging.info(f\"Added/updated keyword set for category: {category}\")\n",
        "\n",
        "    def get_random_keyword(self, category: str, exclude: List[str] = None) -> str:\n",
        "        \"\"\"\n",
        "        Select a random keyword from a category based on weights.\n",
        "\n",
        "        Args:\n",
        "            category: The keyword category\n",
        "            exclude: List of keywords to exclude\n",
        "\n",
        "        Returns:\n",
        "            Selected keyword or empty string if invalid\n",
        "        \"\"\"\n",
        "        if category not in self.keyword_sets:\n",
        "            logging.warning(f\"Category {category} not found\")\n",
        "            return \"\"\n",
        "\n",
        "        keywords = self.keyword_sets[category]\n",
        "        if exclude:\n",
        "            keywords = [(kw, w) for kw, w in keywords if kw not in exclude]\n",
        "        if not keywords:\n",
        "            logging.warning(f\"No valid keywords in {category} after exclusions\")\n",
        "            return \"\"\n",
        "\n",
        "        keywords, weights = zip(*keywords)\n",
        "        return random.choices(keywords, weights=weights, k=1)[0]\n",
        "\n",
        "    def check_compatibility(self, selected_keywords: Dict[str, str]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Ensure selected keywords are compatible.\n",
        "\n",
        "        Args:\n",
        "            selected_keywords: Dictionary of category:keyword pairs\n",
        "\n",
        "        Returns:\n",
        "            Updated dictionary with compatible keywords\n",
        "        \"\"\"\n",
        "        for group1, group2 in self.incompatible_pairs:\n",
        "            for cat, kw in list(selected_keywords.items()):\n",
        "                if kw in group1:\n",
        "                    for cat2, kw2 in list(selected_keywords.items()):\n",
        "                        if kw2 in group2:\n",
        "                            selected_keywords[cat2] = self.get_random_keyword(cat2, exclude=group2)\n",
        "                            logging.info(f\"Replaced incompatible keyword {kw2} in {cat2} with {selected_keywords[cat2]}\")\n",
        "                elif kw in group2:\n",
        "                    for cat2, kw2 in list(selected_keywords.items()):\n",
        "                        if kw2 in group1:\n",
        "                            selected_keywords[cat2] = self.get_random_keyword(cat2, exclude=group1)\n",
        "                            logging.info(f\"Replaced incompatible keyword {kw2} in {cat2} with {selected_keywords[cat2]}\")\n",
        "        return selected_keywords\n",
        "\n",
        "    def generate_keyword_combination(self) -> str:\n",
        "        selected_keywords = {}\n",
        "\n",
        "        # Updated core categories\n",
        "        core_categories = ['color', 'hair_style', 'body', 'dress', 'environment',\n",
        "                          'camera', 'expression', 'lighting', 'age', 'race', 'mood',\n",
        "                          'pose', 'art_style', 'time_of_day', 'emotion']\n",
        "\n",
        "        for category in core_categories:\n",
        "            selected_keywords[category] = self.get_random_keyword(category)\n",
        "\n",
        "        # Context-aware adjustments\n",
        "        # Weather for outdoor environments\n",
        "        if selected_keywords['environment'] in ['beach', 'forest', 'pool', 'desert', 'mountain']:\n",
        "            if random.random() > 0.4:\n",
        "                selected_keywords['weather'] = self.get_random_keyword('weather')\n",
        "\n",
        "        # Props based on pose and environment\n",
        "        if selected_keywords['pose'] in ['sitting on a chair', 'sitting cross-legged', 'lying on the back', 'reclining']:\n",
        "            if random.random() > 0.5:\n",
        "                selected_keywords['props'] = self.get_random_keyword('props', exclude=['sword', 'umbrella'])\n",
        "        elif selected_keywords['pose'] in ['standing straight', 'hands on hips', 'fighting stance']:\n",
        "            if random.random() > 0.3:\n",
        "                selected_keywords['props'] = self.get_random_keyword('props', exclude=['book', 'wine glass'])\n",
        "\n",
        "        # Facial features for close-up or medium shots\n",
        "        if selected_keywords['camera'] in ['close-up', 'medium shot']:\n",
        "            if random.random() > 0.5:\n",
        "                selected_keywords['facial_features'] = self.get_random_keyword('facial_features')\n",
        "\n",
        "        # Existing conditional logic for dress, erotic, etc.\n",
        "        if selected_keywords['dress'] not in ['naked', 'half naked', 'nude', 'topless']:\n",
        "            if random.random() > 0.4:\n",
        "                selected_keywords['accessories'] = self.get_random_keyword('accessories')\n",
        "            if random.random() > 0.3:\n",
        "                selected_keywords['texture'] = self.get_random_keyword('texture')\n",
        "        else:\n",
        "            if random.random() > 0.6:\n",
        "                selected_keywords['nipples'] = self.get_random_keyword('nipples')\n",
        "            if random.random() > 0.5:\n",
        "                selected_keywords['sexual'] = self.get_random_keyword('sexual')\n",
        "\n",
        "        if random.random() > 0.3:\n",
        "            selected_keywords['erotic'] = self.get_random_keyword('erotic')\n",
        "        if random.random() > 0.4 and 'sexual' in selected_keywords:\n",
        "            selected_keywords['sensual'] = self.get_random_keyword('sensual')\n",
        "        if random.random() > 0.5 and 'sexual' in selected_keywords:\n",
        "            selected_keywords['sex_position'] = self.get_random_keyword('sex_position')\n",
        "        if random.random() > 0.5 and 'erotic' in selected_keywords:\n",
        "            selected_keywords['action'] = self.get_random_keyword('action')\n",
        "\n",
        "        if random.random() > 0.3:\n",
        "            selected_keywords['background_details'] = self.get_random_keyword('background_details')\n",
        "\n",
        "        # Ensure compatibility\n",
        "        selected_keywords = self.check_compatibility(selected_keywords)\n",
        "\n",
        "        # Build prompt\n",
        "        prompt_parts = [self.main_keywords, selected_keywords['art_style']]\n",
        "\n",
        "        # Character or generic description\n",
        "        if random.random() > 0.6:\n",
        "            character = self.get_random_keyword('character')\n",
        "            if character:\n",
        "                prompt_parts.append(f\"{character}, {selected_keywords['age']}, {selected_keywords['race']}\")\n",
        "            else:\n",
        "                hair_color = self.get_random_keyword('color')\n",
        "                eye_color = self.get_random_keyword('color')\n",
        "                prompt_parts.append(f\"{selected_keywords['age']} {selected_keywords['race']} girl, \"\n",
        "                                  f\"{hair_color} hair, {eye_color} eyes, {selected_keywords['hair_style']}, \"\n",
        "                                  f\"{selected_keywords.get('facial_features', '')}\")\n",
        "        else:\n",
        "            hair_color = self.get_random_keyword('color')\n",
        "            eye_color = self.get_random_keyword('color')\n",
        "            prompt_parts.append(f\"{selected_keywords['age']} {selected_keywords['race']} girl, \"\n",
        "                              f\"{hair_color} hair, {eye_color} eyes, {selected_keywords['hair_style']}, \"\n",
        "                              f\"{selected_keywords.get('facial_features', '')}\")\n",
        "\n",
        "        # Add core elements\n",
        "        prompt_parts.extend([\n",
        "            f\"{selected_keywords['body']}, {selected_keywords['dress']}, {selected_keywords['pose']}\",\n",
        "            f\"{selected_keywords['environment']}, {selected_keywords['camera']}, {selected_keywords.get('weather', '')}\",\n",
        "            f\"{selected_keywords['expression']}, {selected_keywords['emotion']}, {selected_keywords['lighting']}, \"\n",
        "            f\"{selected_keywords['mood']}, {selected_keywords['time_of_day']}\"\n",
        "        ])\n",
        "\n",
        "        # Add optional elements\n",
        "        for category in ['erotic', 'nipples', 'sexual', 'sensual', 'sex_position', 'action',\n",
        "                        'accessories', 'texture', 'background_details', 'props']:\n",
        "            if category in selected_keywords:\n",
        "                prompt_parts.append(selected_keywords[category])\n",
        "\n",
        "        prompt = \", \".join(filter(None, prompt_parts)).replace('  ', ' ').strip()\n",
        "\n",
        "        # Ensure prompt is within StableDiffusion length limits\n",
        "        words = prompt.split()\n",
        "        if len(words) > self.max_prompt_length:\n",
        "            prompt = \" \".join(words[:self.max_prompt_length])\n",
        "\n",
        "        logging.info(f\"Generated prompt: {prompt}\")\n",
        "        return prompt\n",
        "\n",
        "    def clean_ai_output(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean AI-generated output to extract just the prompt.\n",
        "\n",
        "        Args:\n",
        "            text: Raw AI output\n",
        "\n",
        "        Returns:\n",
        "            Cleaned prompt text\n",
        "        \"\"\"\n",
        "        # Remove common prefixes and suffixes with regex\n",
        "        text = re.sub(r'^(here is your prompt:|generated prompt:|prompt:|here you go:|here\\'s the prompt:)\\s*', '', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'(i hope|let me know|enjoy|please note).*$', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Remove quotes, markdown, and extra whitespace\n",
        "        text = text.strip('\"\\'` \\n').replace('\\n', ' ')\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Limit to max words\n",
        "        words = text.split()\n",
        "        if len(words) > self.max_prompt_length:\n",
        "            text = ' '.join(words[:self.max_prompt_length])\n",
        "\n",
        "        return text\n",
        "\n",
        "    def generate_prompts(\n",
        "            self,\n",
        "            base_prompt: str = 'Generate highly detailed NSFW prompt for StableDiffusion image generation',\n",
        "            num_prompts: int = 10,\n",
        "            save_path: Optional[str] = None,\n",
        "            batch_size: int = 10\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate multiple prompts using the AI.\n",
        "\n",
        "        Args:\n",
        "            base_prompt: Base instruction for AI\n",
        "            num_prompts: Number of prompts to generate\n",
        "            save_path: Directory to save prompts\n",
        "            batch_size: Number of prompts to generate between saves\n",
        "\n",
        "        Returns:\n",
        "            List of generated prompts\n",
        "        \"\"\"\n",
        "        logging.info(f'Starting to generate {num_prompts} prompts...')\n",
        "        start_time = time.time()\n",
        "        prompts = []\n",
        "\n",
        "        general_prompt = \"\"\"\n",
        "        {base}. Follow these rules:\n",
        "        1. Use only provided keywords\n",
        "        2. Output only the prompt, no extra commentary\n",
        "        3. Select one option randomly from lists separated by '|'\n",
        "        4. Keep prompt to one line, max {max_words} words\n",
        "        5. Ensure coherence and compatibility with StableDiffusion\n",
        "        Keywords: {keywords}\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        while len(prompts) < num_prompts:\n",
        "            try:\n",
        "                keywords = self.generate_keyword_combination()\n",
        "                full_prompt = general_prompt.format(\n",
        "                    base=base_prompt,\n",
        "                    keywords=keywords,\n",
        "                    max_words=self.max_prompt_length\n",
        "                )\n",
        "\n",
        "                ai_seed = random.randint(0, 2**32 - 1)\n",
        "                raw_output = self.generate_prompt_fn(prompt=full_prompt, seed=ai_seed)\n",
        "\n",
        "                if raw_output:\n",
        "                    clean_prompt = self.clean_ai_output(raw_output)\n",
        "                    if clean_prompt and len(clean_prompt.split()) <= self.max_prompt_length:\n",
        "                        prompts.append(clean_prompt)\n",
        "                        logging.info(f\"Generated prompt {len(prompts)}/{num_prompts}: {clean_prompt}\")\n",
        "\n",
        "                        if save_path and len(prompts) % batch_size == 0:\n",
        "                            self.save_prompts(base_prompt, prompts, save_path, timestamp)\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error generating prompt: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if save_path:\n",
        "            self.save_prompts(base_prompt, prompts, save_path, timestamp)\n",
        "\n",
        "        elapsed = round(time.time() - start_time, 1)\n",
        "        logging.info(f'Finished generating {len(prompts)} prompts in {elapsed} seconds.')\n",
        "        return prompts\n",
        "\n",
        "    def generate_raw_prompts(\n",
        "            self,\n",
        "            base_prompt: str = 'Generate highly detailed NSFW prompt for StableDiffusion image generation'\n",
        "    ) -> str:\n",
        "        general_prompt = \"\"\"\n",
        "        {base}, {keywords}\n",
        "        \"\"\"\n",
        "        keywords = self.generate_keyword_combination()\n",
        "        prompt = general_prompt.format(\n",
        "            base=base_prompt,\n",
        "            keywords=keywords,\n",
        "            max_words=self.max_prompt_length\n",
        "        )\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def save_prompts(self, base_prompt: str, prompts: List[str], directory: str, timestamp) -> None:\n",
        "        \"\"\"\n",
        "        Save prompts to a JSON file.\n",
        "\n",
        "        Args:\n",
        "            base_prompt: Base prompt used\n",
        "            prompts: List of generated prompts\n",
        "            directory: Directory to save the file\n",
        "        \"\"\"\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        filename = os.path.join(directory, f\"prompts_{timestamp}.json\")\n",
        "\n",
        "        data = {\n",
        "            \"metadata\": {\n",
        "                \"generated_at\": timestamp,\n",
        "                \"num_prompts\": len(prompts),\n",
        "                \"base_prompt\": base_prompt,\n",
        "                \"keyword_categories\": list(self.keyword_sets.keys())\n",
        "            },\n",
        "            \"prompts\": prompts\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(filename, 'w') as f:\n",
        "                json.dump(data, f, indent=2)\n",
        "            logging.info(f\"Saved {len(prompts)} prompts to {filename}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving prompts: {str(e)}\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     generator = AIPromptGenerator(generate_prompt)\n",
        "#     base_prompt = 'Generate prompt for girl with high-quality erotic themes, optimized for StableDiffusion'\n",
        "#     prompts = generator.generate_prompts(base_prompt=base_prompt, num_prompts=3, save_path=\"./prompts\")\n",
        "#     for pt in prompts:\n",
        "#         print(pt)"
      ],
      "metadata": {
        "id": "0Bwk6sBK1rbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator"
      ],
      "metadata": {
        "id": "0UDR4sOW14v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(prompt, seed=1267):\n",
        "    promptGenerator.clear_history()\n",
        "    prompt, out = promptGenerator.generate_prompt(prompt=prompt, seed=seed, use_system_prompt=False)\n",
        "    return prompt\n",
        "\n",
        "generator = AIPromptGenerator(generate_prompt)\n",
        "\n",
        "# base_prompt = 'Generate prompt for girl that getting fucked in sexual positions, highest possible erotic themes, sensual pleasure coursing through their bodies'\n",
        "base_prompt = 'Generate prompt for beauty girl with high-quality sensual themes and sexual positions, optimized for StableDiffusion'\n",
        "prompts = generator.generate_prompts(base_prompt=base_prompt, num_prompts=200, save_path=\"./prompts\")\n",
        "# for pt in prompts:\n",
        "#     print(pt)"
      ],
      "metadata": {
        "id": "9sMxJrIB1wYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator.save_prompts(base_prompt, prompts, '/content/drive/MyDrive/AI'))"
      ],
      "metadata": {
        "id": "-PUPmdduNBwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_prompt(prompt='suggest me image prompt with explitic sexual content, including sex , ... . not mild themes, highest possible erotic themes ', seed=1267))"
      ],
      "metadata": {
        "id": "NcnnfG0-TQQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nodes"
      ],
      "metadata": {
        "id": "imVQcYXHvVeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models as Enum"
      ],
      "metadata": {
        "id": "p50s1XPcng-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "# https://huggingface.co/stabilityai/control-lora\n",
        "class Controlnet(Enum):\n",
        "    pass\n",
        "\n",
        "class ControlnetLoRa_SDXL(Controlnet):\n",
        "    Canny = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors', 'control-lora-canny-rank256.safetensors']\n",
        "    Depth = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors', 'control-lora-depth-rank256.safetensors']\n",
        "    Recolor = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors', 'control-lora-recolor-rank256.safetensors']\n",
        "    Sketch = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors', 'control-lora-sketch-rank256.safetensors']\n",
        "    OpenPoseXL2 = ['https://huggingface.co/thibaud/controlnet-openpose-sdxl-1.0/resolve/main/control-lora-openposeXL2-rank256.safetensors', 'control-lora-openposeXL2-rank256.safetensors']\n",
        "\n",
        "class ControlnetModel_SD15(Controlnet):\n",
        "    Canny = ['https://huggingface.co/lllyasviel/control_v11p_sd15_canny/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_canny.fp16.safetensors']\n",
        "    Depth = ['https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11f1p_sd15_depth.fp16.safetensors']\n",
        "    SoftEdge = ['https://huggingface.co/lllyasviel/control_v11p_sd15_softedge/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_softedge.fp16.safetensors']\n",
        "    Inpaint = ['https://huggingface.co/lllyasviel/control_v11p_sd15_inpaint/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_inpaint.fp16.safetensors']\n",
        "    OpenPose = ['https://huggingface.co/lllyasviel/control_v11p_sd15_openpose/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_openpose.fp16.safetensors']\n",
        "    Scribble = ['https://huggingface.co/lllyasviel/control_v11p_sd15_scribble/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_scribble.fp16.safetensors']\n",
        "    LineArt  = ['https://huggingface.co/lllyasviel/control_v11p_sd15_lineart/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_lineart.fp16.safetensors']\n",
        "\n",
        "class ControlnetModel_XL(Controlnet):\n",
        "    Canny = ['https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'controlnet-canny-sdxl-1.0.fp16.safetensors']\n",
        "    Depth = ['https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'controlnet-depth-sdxl-1.0.fp16.safetensors']\n",
        "\n",
        "class HyperLoRa(Enum):\n",
        "    HyperSD_15_1_step = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-1step-lora.safetensors', 'Hyper-SD15-1step-lora.safetensors']\n",
        "    HyperSD_15_2_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-2steps-lora.safetensors', 'Hyper-SD15-2steps-lora.safetensors']\n",
        "    HyperSD_15_4_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-4steps-lora.safetensors', 'Hyper-SD15-4steps-lora.safetensors']\n",
        "    HyperSD_15_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-8steps-lora.safetensors', 'Hyper-SD15-8steps-lora.safetensors']\n",
        "    HyperSD_XL_1_step = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-1step-lora.safetensors', 'Hyper-SDXL-1step-lora.safetensors']\n",
        "    HyperSD_XL_2_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-2steps-lora.safetensors', 'Hyper-SDXL-2steps-lora.safetensors']\n",
        "    HyperSD_XL_4_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-4steps-lora.safetensors', 'Hyper-SDXL-4steps-lora.safetensors']\n",
        "    HyperSD_XL_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-8steps-lora.safetensors', 'Hyper-SDXL-8steps-lora.safetensors']\n",
        "    Hyper_Flux_DEV_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-FLUX.1-dev-8steps-lora.safetensors', 'Hyper-FLUX.1-dev-8steps-lora.safetensors']\n",
        "    Hyper_Flux_DEV_16_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-FLUX.1-dev-16steps-lora.safetensors', 'Hyper-FLUX.1-dev-16steps-lora.safetensors']\n",
        "\n",
        "class UpscalerModel(Enum):\n",
        "    RealESRGAN_x2 = ['https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth', 'RealESRGAN_x2.pth']\n",
        "    UltraSharp_4x = ['https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x-UltraSharp.pth', '4x-UltraSharp.pth']\n",
        "\n",
        "class Scheduler(Enum):\n",
        "    SIMPLE = 'simple'\n",
        "    NORMAL = 'normal'\n",
        "    KARRAS = 'karras'\n",
        "    EXPONENTIAL = 'exponential'\n",
        "    SGM_UNIFORM = 'sgm_uniform'\n",
        "\n",
        "\n",
        "class Sampler(Enum):\n",
        "    DDIM = 'ddim'\n",
        "    Euler = 'euler'\n",
        "    Euler_a = 'euler_ancestral'\n",
        "    DDPM = 'ddpm'\n",
        "    DPM_PP_2M = 'dpmpp_2m'\n",
        "    DPM_PP_2M_SDE = 'dpmpp_2m_sde'\n",
        "    DPM_PP_SDE = 'dpmpp_sde'\n",
        "    DPM2 = 'dpm_2'\n",
        "    DPM2_a = 'dpm_2_ancestral'\n",
        "    Heun = 'heun'\n",
        "    LMS = 'lms'\n",
        "    DEIS = 'deis'\n",
        "    UniPC = 'uni_pc'\n",
        "    LCM = 'lcm'\n"
      ],
      "metadata": {
        "id": "lh8oeyhWnruO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes to method"
      ],
      "metadata": {
        "id": "u6xXtx6glPfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# %cd /content/TotoroUI\n",
        "# from TotoroUI.nodes import NODE_CLASS_MAPPINGS as T_NODE_CLASS_MAPPINGS\n",
        "# from TotoroUI.totoro import model_management as T_model_management\n",
        "# from TotoroUI.totoro_extras import nodes_custom_sampler as T_nodes_custom_sampler\n",
        "# from TotoroUI.totoro_extras import nodes_custom_sampler as T_nodes_custom_sampler\n",
        "# from TotoroUI.custom_nodes.totoro_GGUF.nodes import NODE_CLASS_MAPPINGS as T_NODE_CLASS_MAPPINGS_GGUF\n",
        "\n",
        "%cd /content/KMUI\n",
        "import nodes\n",
        "from KMUI.nodes import NODE_CLASS_MAPPINGS\n",
        "from KMUI.kmui_extras import nodes_custom_sampler\n",
        "from KMUI.kmui import model_management\n",
        "from KMUI.custom_nodes.KMUI_GGUF.nodes import NODE_CLASS_MAPPINGS as NODE_CLASS_MAPPINGS_GGUF\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "def scale_by_model(pixels, upscale_model:UpscalerModel, scale:float=1, upscale_method=\"nearest-exact\"): # return upscaled pixels\n",
        "    from KMUI.kmui_extras import nodes_upscale_model\n",
        "    # upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n",
        "    if not os.path.exists(modelpaths.upscale + '/' + upscale_model.value[1]):\n",
        "        download(upscale_model.value[0], upscale_model.value[1], modelpaths.upscale)\n",
        "        if not os.path.exists(modelpaths.upscale + '/' + upscale_model.value[1]):\n",
        "            raise Exception(f'download {upscale_model.value[1]} failed!')\n",
        "\n",
        "    UpscaleModelLoader = nodes_upscale_model.NODE_CLASS_MAPPINGS[\"UpscaleModelLoader\"]()\n",
        "    ImageUpscaleWithModel = nodes_upscale_model.NODE_CLASS_MAPPINGS[\"ImageUpscaleWithModel\"]()\n",
        "    ImageScaleBy = NODE_CLASS_MAPPINGS[\"ImageScaleBy\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        model = UpscaleModelLoader.load_model(model_name=upscale_model.value[1])[0]\n",
        "        image = pixels\n",
        "        if model:\n",
        "            image = ImageUpscaleWithModel.upscale(model, pixels)[0]\n",
        "\n",
        "        if scale != 1:\n",
        "            image = ImageScaleBy.upscale(image, upscale_method, scale)[0]\n",
        "\n",
        "        return image\n",
        "\n",
        "def apply_controlnet(conditioning, control_net, image, strength): # cn = [(lora name, strength), ...]\n",
        "    ControlNetApply = NODE_CLASS_MAPPINGS[\"ControlNetApply\"]()\n",
        "    with torch.inference_mode():\n",
        "        cond = ControlNetApply.apply_controlnet(conditioning, control_net, image, strength)[0]\n",
        "    return cond\n",
        "\n",
        "def apply_lora(unet, lora=[], clip=None, apply_to_clip=True): # lora = [(lora name, strength), ...]\n",
        "    LoraLoaderModelOnly = NODE_CLASS_MAPPINGS[\"LoraLoaderModelOnly\"]()\n",
        "    LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        if apply_to_clip:\n",
        "            final_model = (unet, clip)\n",
        "            for it in lora:\n",
        "                final_model = LoraLoader.load_lora(model=final_model[0], clip=final_model[1], lora_name=it[0], strength_model=it[1], strength_clip=it[1])\n",
        "        else:\n",
        "            final_model = unet\n",
        "            for it in lora:\n",
        "                final_model = LoraLoaderModelOnly.load_lora_model_only(final_model, it[0], it[1])[0]\n",
        "            final_model = (final_model, clip)\n",
        "        return final_model\n",
        "\n",
        "def apply_hyper_lora(unet, clip, lora:HyperLoRa):\n",
        "    if not os.path.exists(modelpaths.lora + '/' + lora.value[1]):\n",
        "        download(lora.value[0], lora.value[1], modelpaths.lora)\n",
        "        if not os.path.exists(modelpaths.lora + '/' + lora.value[1]):\n",
        "            raise Exception(f'download {lora.value[1]} failed!')\n",
        "\n",
        "    return apply_lora(unet=unet, lora=[[lora.value[1], 1.0],], clip=clip)\n",
        "    # LoraLoaderModelOnly = NODE_CLASS_MAPPINGS[\"LoraLoaderModelOnly\"]()\n",
        "    # final_model = unet\n",
        "    # with torch.inference_mode():\n",
        "    #     return LoraLoaderModelOnly.load_lora_model_only(final_model, lora.value[1], 1.0)[0]\n",
        "\n",
        "def load_vae(file_name=None):\n",
        "    if file_name is None:\n",
        "        for item in os.listdir(modelpaths.vae):\n",
        "            if item.endswith('safetensors') or item.endswith('pt'):\n",
        "                file_name = item\n",
        "                break\n",
        "        if not file_name:\n",
        "            raise Exception(\"no model found.\")\n",
        "        else:\n",
        "            print(f\"VAE {file_name} loaded.\")\n",
        "\n",
        "    VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "    with torch.inference_mode():\n",
        "        vae = VAELoader.load_vae(file_name)[0]\n",
        "    return vae, file_name\n",
        "\n",
        "def load_checkpoint(ckpt_name: str=None):\n",
        "    if Flux_mode:\n",
        "        schnell = 'schnell' in model_type.lower()\n",
        "        dn = False\n",
        "        if schnell:\n",
        "            # https://huggingface.co/city96/FLUX.1-schnell-gguf/tree/main\n",
        "            name = 'flux1-schnell-Q6_K.gguf'\n",
        "            name = 'flux1-schnell-Q5_K_S.gguf'\n",
        "            if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "                dn = True\n",
        "                download(f'https://huggingface.co/city96/FLUX.1-schnell-gguf/resolve/main/{name}',name , modelpaths.unet)\n",
        "        else:\n",
        "            # https://huggingface.co/city96/FLUX.1-dev-gguf/tree/main\n",
        "            # name = 'flux1-dev-Q6_K.gguf'\n",
        "            name = 'flux1-dev-Q5_K_S.gguf'\n",
        "            if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "                dn = True\n",
        "                download(f'https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/{name}',name , modelpaths.unet)\n",
        "                download(f'https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha/resolve/main/diffusion_pytorch_model.safetensors','FLUX.1-Turbo-Alpha.safetensors' , modelpaths.lora)\n",
        "        if dn:\n",
        "            download('https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft', 'ae.sft', modelpaths.vae)\n",
        "            download('https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors', 'clip_l.safetensors', modelpaths.clip)\n",
        "            download('https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q5_K_M.gguf', 't5-v1_1-xxl-encoder-Q6_K.gguf', modelpaths.clip)\n",
        "\n",
        "\n",
        "        DualCLIPLoaderGGUF = NODE_CLASS_MAPPINGS_GGUF[\"DualCLIPLoaderGGUF\"]()\n",
        "        UnetLoaderGGUF = NODE_CLASS_MAPPINGS_GGUF[\"UnetLoaderGGUF\"]()\n",
        "        VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            clip = DualCLIPLoaderGGUF.load_clip(\"t5-v1_1-xxl-encoder-Q6_K.gguf\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "            unet = UnetLoaderGGUF.load_unet(name)[0]\n",
        "            if not schnell:\n",
        "                unet, clip = apply_lora(unet=unet, lora=[['FLUX.1-Turbo-Alpha.safetensors', 1.0]], clip=clip)\n",
        "            vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "            return unet, clip, vae, name\n",
        "    elif model_type==\"SD3.5\":\n",
        "        name = 'sd3.5_large_fp8_scaled.safetensors'\n",
        "        if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "            download(f'https://huggingface.co/Comfy-Org/stable-diffusion-3.5-fp8/resolve/main/{name}',name , modelpaths.model)\n",
        "\n",
        "        CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "        with torch.inference_mode():\n",
        "            checkpoint_loader_simple = CheckpointLoaderSimple.load_checkpoint(ckpt_name) # it return (model_patcher, clip, vae, clipvision)\n",
        "            clip = checkpoint_loader_simple[1]\n",
        "            unet = checkpoint_loader_simple[0]\n",
        "            vae = checkpoint_loader_simple[2]\n",
        "            return unet, clip, vae, ckpt_name\n",
        "    else:\n",
        "        if ckpt_name is None:\n",
        "            for item in os.listdir(modelpaths.model):\n",
        "                if item.endswith('safetensors'):\n",
        "                    ckpt_name = item\n",
        "                    break\n",
        "            if not ckpt_name:\n",
        "                raise Exception(\"no model found.\")\n",
        "            else:\n",
        "                print(f\"model {ckpt_name} loaded.\")\n",
        "        CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "        with torch.inference_mode():\n",
        "            checkpoint_loader_simple = CheckpointLoaderSimple.load_checkpoint(ckpt_name) # it return (model_patcher, clip, vae, clipvision)\n",
        "            clip = checkpoint_loader_simple[1]\n",
        "            unet = checkpoint_loader_simple[0]\n",
        "            vae = checkpoint_loader_simple[2]\n",
        "            return unet, clip, vae, ckpt_name\n",
        "\n",
        "def encode_prompt(clip, prompt):\n",
        "    with torch.inference_mode():\n",
        "        cond, pooled = clip.encode_from_tokens(clip.tokenize(prompt), return_pooled=True)\n",
        "        return [[cond, {\"pooled_output\": pooled}]]\n",
        "\n",
        "def load_controlnet(control_net):\n",
        "    if not os.path.exists(modelpaths.controlnet + '/' + control_net.value[1]):\n",
        "        download(control_net.value[0], control_net.value[1], modelpaths.controlnet)\n",
        "        if not os.path.exists(modelpaths.controlnet + '/' + control_net.value[1]):\n",
        "            raise Exception(f'download {control_net.value[1]} failed!')\n",
        "\n",
        "    CNLoader = NODE_CLASS_MAPPINGS[\"ControlNetLoader\"]()\n",
        "    with torch.inference_mode():\n",
        "        cn = CNLoader.load_vae(control_net.value[1])[0]\n",
        "    return cn\n",
        "\n",
        "def create_empty_latent(width, height, batch_size=1):\n",
        "    EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16), batch_size=batch_size)[0]\n",
        "\n",
        "def ksampler(model, positive, negative, latent, seed=0, steps=20, cfg=1.0,\n",
        "             sampler: Sampler=Sampler.Euler, scheduler: Scheduler=Scheduler.NORMAL,\n",
        "             denoise=1.0,start_step=None, last_step=None, add_noise=True, force_full_denoise=False):\n",
        "    RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "    BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "    CFGGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"CFGGuider\"]()\n",
        "    KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "    BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "    SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "\n",
        "    disable_noise = not add_noise\n",
        "    if Flux_mode:\n",
        "        if 'schnell' in model_type.lower():\n",
        "            sampler = Sampler.Euler\n",
        "            scheduler = Scheduler.SIMPLE\n",
        "            steps = 4\n",
        "            cfg = 0.9\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                noise = RandomNoise.get_noise(seed)[0]\n",
        "                guider = BasicGuider.get_guider(model, positive)[0]\n",
        "                guider.set_cfg(cfg)\n",
        "\n",
        "                sampler = KSamplerSelect.get_sampler(sampler.value)[0]\n",
        "                sigmas = BasicScheduler.get_sigmas(model, scheduler.value, steps, denoise)[0]\n",
        "                sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent)\n",
        "                model_management.soft_empty_cache(True)\n",
        "                return sample\n",
        "        else:\n",
        "            sampler = Sampler.Euler\n",
        "            scheduler = Scheduler.SIMPLE\n",
        "            steps = 8\n",
        "            cfg = 1.0\n",
        "\n",
        "            return nodes.common_ksampler(model=model, seed=seed, steps=steps, cfg=cfg, sampler_name=sampler.value,\n",
        "                                        scheduler=scheduler.value, positive=positive, negative=negative,\n",
        "                                        latent=latent, denoise=denoise, start_step=start_step, last_step=last_step,\n",
        "                                         disable_noise=disable_noise, force_full_denoise=force_full_denoise)[0]\n",
        "    else:\n",
        "        with torch.inference_mode():\n",
        "            # noise = RandomNoise.get_noise(seed)[0]\n",
        "            # guider = CFGGuider.get_guider(model, positive, negative, cfg)[0]\n",
        "            # sampler = KSamplerSelect.get_sampler(sampler.value)[0]\n",
        "            # sigmas = BasicScheduler.get_sigmas(model, scheduler.value, steps, denoise)[0]\n",
        "            # sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent)\n",
        "            # model_management.soft_empty_cache()\n",
        "            # return sample\n",
        "            return nodes.common_ksampler(model=model, seed=seed, steps=steps, cfg=cfg, sampler_name=sampler.value,\n",
        "                                        scheduler=scheduler.value, positive=positive, negative=negative,\n",
        "                                        latent=latent, denoise=denoise,start_step=start_step, last_step=last_step,\n",
        "                                         disable_noise=disable_noise,force_full_denoise=force_full_denoise)[0]\n",
        "\n",
        "def vae_decode(vae, latent): # return image (float[0-1])\n",
        "    VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return VAEDecode.decode(vae, latent)[0].detach()\n",
        "\n",
        "def vae_encode(vae, pixels): # pixels (float[0-1])\n",
        "    VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return VAEEncode.encode(vae, pixels)[0]\n",
        "\n",
        "def load_image(image_path): # RETURN_TYPES = (\"IMAGE\", \"MASK\")\n",
        "    LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "    return LoadImage.load_image(image_path)[0]\n",
        "\n",
        "def get_printable_image(image, index=0): # image in float format\n",
        "    return Image.fromarray(np.array(image*255, dtype=np.uint8)[index])\n",
        "\n",
        "def saveJPEG(image, index=0, path='/content/KMUI/output', name='image', quality=94, exif=None): # image in float format\n",
        "    img = Image.fromarray(np.array(image*255, dtype=np.uint8)[index])\n",
        "    if exif:\n",
        "        img.convert('RGB').save(f'{path}/{name}.jpg', optimize=True, quality=quality, exif=exif)\n",
        "    else:\n",
        "        img.convert('RGB').save(f'{path}/{name}.jpg', optimize=True, quality=quality)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "PrC4_OZuEHNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## custom nodes"
      ],
      "metadata": {
        "id": "9DuIoxttIxBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceRestorModel(Enum):\n",
        "    GFPGANv14 = 'GFPGANv1.4.pth'\n",
        "    codeformer = 'codeformer-v0.1.0.pth'\n",
        "    GPEN_BFR_512 = 'GPEN-BFR-512.onnx'\n",
        "    GPEN_BFR_1024 = 'GPEN-BFR-1024.onnx'\n",
        "    GPEN_BFR_2048 = 'GPEN-BFR-2048.onnx'\n",
        "\n",
        "class ReActorFaceSwap:\n",
        "    facedetection_model = [\"retinaface_resnet50\", \"retinaface_mobile0.25\", \"YOLOv5l\", \"YOLOv5n\"]\n",
        "    fr_urls = \"https://huggingface.co/datasets/Gourieff/ReActor/resolve/main/models/facerestore_models/\"\n",
        "    reactor = None\n",
        "    swap_model = 'inswapper_128.onnx'\n",
        "    face_restore_model = FaceRestorModel.GFPGANv14\n",
        "\n",
        "    def __init__(self, face_restore_model=FaceRestorModel.GFPGANv14):\n",
        "        try:\n",
        "            %cd /content/KMUI/custom_nodes/KMUI_reactor_node\n",
        "            from KMUI_reactor_node.nodes import NODE_CLASS_MAPPINGS as RA_NODE_CLASS_MAPPINGS\n",
        "        except Exception as e:\n",
        "            %cd /content/KMUI/custom_nodes\n",
        "            from KMUI_reactor_node.nodes import NODE_CLASS_MAPPINGS as RA_NODE_CLASS_MAPPINGS\n",
        "\n",
        "        self.face_restore_model=face_restore_model\n",
        "        if not os.path.exists(f'{modelpaths.base_path}/facerestore_models'):\n",
        "            os.makedirs(f'{modelpaths.base_path}/facerestore_models')\n",
        "\n",
        "        if not os.path.exists(f'{modelpaths.base_path}/facerestore_models/{self.face_restore_model.value}'):\n",
        "            download(self.fr_urls + self.face_restore_model.value, self.face_restore_model.value, f'{modelpaths.base_path}/facerestore_models')\n",
        "\n",
        "        self.reactor = RA_NODE_CLASS_MAPPINGS[\"ReActorFaceSwap\"]()\n",
        "\n",
        "    def swap(self, input_image, source_image, input_faces_index='0', source_faces_index='0'):\n",
        "        result ,face_model_to_provide = self.reactor.execute(enabled=True, input_image=input_image, swap_model=self.swap_model, detect_gender_source='no',\n",
        "                             detect_gender_input='no', source_faces_index=source_faces_index, input_faces_index=input_faces_index,\n",
        "                             console_log_level=1, face_restore_model=self.face_restore_model.value, face_restore_visibility=1,\n",
        "                             codeformer_weight=1, facedetection=self.facedetection_model[0], source_image=source_image,\n",
        "                             face_model=None, faces_order=None, face_boost=None)\n",
        "        return result\n",
        "\n",
        "# reActorFaceSwap = None\n",
        "# if ReactorNode:\n",
        "#     reActorFaceSwap = ReActorFaceSwap()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lhjEW5-RIwHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference data"
      ],
      "metadata": {
        "id": "F3pLYafjlXZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_prompt = '''\n",
        "A masterfully crafted, ultra-detailed, 8K masterpiece, beauty girl with captivating eyes,\n",
        "curvy, bent, seductive body shape, one hand grab breast, scream of orgasm, vibrand intense color, RED, GREEN, Yellow, purple, black, white, gold,\n",
        "her voluptuous figure alluring in the soft moonlight. Carefully rendered in high resolution,\n",
        "every curl of her luscious tresses, her bare skin aglow in the deep shadows of this erotic scene,\n",
        "'''\n",
        "# positive_prompt = '''\n",
        "# highly detailed realistic (full_body:1.3) photo of girl with vibrant red hair styled in an intricate braid that falls over her shoulder.\n",
        "# her bare skin aglow in the deep shadows of this erotic scene, She has large, expressive golden-brown eyes with delicate eyeliner and a touch of red eyeshadow.\n",
        "# Her lips are full and painted a bold red, slightly parted to reveal a hint of sharp. She wears elegant,\n",
        "# dangling earrings featuring heart-shaped red gemstones framed in gold, paired with a matching red cord necklace. Her skin is smooth and luminous,\n",
        "# with a soft blush on her cheeks. She is dressed in a flowing white garment with gentle folds, illuminated by a warm, ethereal light against a dark,\n",
        "# starry background with tiny sparkling particles. The overall style should be realistic with a fantasy aesthetic, emphasizing rich colors and fine details.\n",
        "# '''\n",
        "\n",
        "# positive_prompt = '''\n",
        "# Create a highly detailed realistic (full body) photo of girl with vibrant red hair styled in an intricate braid.\n",
        "# Her hair is glossy and voluminous, with soft strands framing her face, catching the light with a subtle glow.\n",
        "# her bare white skin aglow in the deep shadows of this erotic scene, She has large, expressive golden-brown eyes with delicate eyeliner and a touch of red eyeshadow,\n",
        "# giving her a striking and elegant look. Her lips are full and painted a bold red, slightly parted to reveal a hint of sharp.\n",
        "# her bare skin aglow in the deep shadows of this erotic scene, curvy, bent, seductive body shape,\n",
        "# She wears elegant, dangling earrings featuring heart-shaped red gemstones framed in gold, paired with a matching red cord necklace.\n",
        "# Her skin is smooth and luminous, with a soft blush on her cheeks. She is illuminated by a warm,\n",
        "# ethereal light against a dark, starry background with tiny sparkling particles. The overall style should be a fantasy aesthetic, emphasizing rich colors and fine details.\n",
        "# '''\n",
        "\n",
        "negative_prompt = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "lora_prompt = ''\n",
        "width = 640 # int(832)\n",
        "height = 1144 # int(1216)\n",
        "seed = 0\n",
        "steps = 25\n",
        "cfg = 5\n",
        "sampler = Sampler.DPM_PP_2M\n",
        "scheduler = Scheduler.KARRAS\n",
        "# print(positive_prompt)\n",
        "# print(negative_prompt)\n",
        "empty_latent = create_empty_latent(width,height)\n",
        "if seed ==0:\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "print(f'seed={seed}')"
      ],
      "metadata": {
        "id": "LopCusy3SNzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "GbPYUikl_Udj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet, clip, vae, chp_name = load_checkpoint()\n",
        "# vae, vae_name = load_vae()"
      ],
      "metadata": {
        "id": "sCYSnmdx_ZJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet2, clip2 = apply_hyper_lora(unet=unet, clip=clip, lora=HyperLoRa.HyperSD_XL_8_steps)"
      ],
      "metadata": {
        "id": "9RlwQR67chuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple text to image"
      ],
      "metadata": {
        "id": "NS8f_7E5lseA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed = random.randint(0, 18446744073709551615)\n",
        "# unet2 = apply_hyper_lora(unet, clip, HyperLoRa.HyperSD_XL_8_steps)\n",
        "default_lora_list=[\n",
        "    ['AddMoreDetails-v1.safetensors', 1.5],\n",
        "    ['upright_front_above_50.safetensors', 0.75],\n",
        "    ['seductiveorgasm.safetensors', 0.85],\n",
        "    # ['BetterEyesFaceSkin-v1.safetensors', 1],\n",
        "    # ['3DMM_V12.safetensors', 1],\n",
        "]\n",
        "lora_prompt = ', (1boy:1.1), sex, (hetero:1.3), (upright straddle), pussy juice, leg lock, from behind, seductiveorgasm'\n",
        "\n",
        "# default_lora_list=[\n",
        "#     ['Expressive_H-000001.safetensors', 0.8],\n",
        "#     ['PerfectEyesXL.safetensors', 0.9],\n",
        "#     ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "#     ['Urban_Fusion_IL.safetensors', 0.3],\n",
        "#     ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "#     ['cfg_scale_boost.safetensors', 0.3],\n",
        "#     # ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "# ]\n",
        "\n",
        "# lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "unet3, clip3 = apply_lora(unet=unet, lora=default_lora_list, clip=clip, apply_to_clip=True)\n"
      ],
      "metadata": {
        "id": "TgGY5TgwQYqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "for i in range(100):\n",
        "    generator = AIPromptGenerator(generate_prompt_fn=None)\n",
        "\n",
        "    positive_prompt = f'''\n",
        "    A masterfully crafted, ultra-detailed, 8K masterpiece, (1boy:1.1), sex, (hetero:1.3), (upright straddle), leg lock, from behind, beauty girl with captivating eyes,\n",
        "    {generator.get_random_keyword('expression')}, {generator.get_random_keyword('body')}, {generator.get_random_keyword('sensual')}, {generator.get_random_keyword('erotic')},\n",
        "    {generator.get_random_keyword('pose')}, {generator.get_random_keyword('lighting')}, {generator.get_random_keyword('nipples')}, {generator.get_random_keyword('sexual')},\n",
        "    in {generator.get_random_keyword('environment')}, scream of orgasm, one hand grab breast,vibrand intense {generator.get_random_keyword('color')} hair,\n",
        "    {generator.get_random_keyword('hair_style')} hair style, her voluptuous figure alluring in the soft moonlight. Carefully rendered in high resolution,\n",
        "    wear {generator.get_random_keyword('accessories')},  every curl of her luscious tresses, her bare skin aglow in the deep shadows of this erotic scene,\n",
        "    {generator.get_random_keyword('age')}, {generator.get_random_keyword('camera')}, seductiveorgasm\n",
        "    '''\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "    # seed = 1366\n",
        "    latent = ksampler(model=unet3, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                    positive=encode_prompt(clip3, positive_prompt),\n",
        "                    negative=encode_prompt(clip3, negative_prompt),\n",
        "                    latent=empty_latent)\n",
        "\n",
        "    image = vae_decode(vae, latent)\n",
        "\n",
        "    print(f'seed={seed}, time: {str(time.time()-t1)} sec')\n",
        "\n",
        "    img = get_printable_image(image)\n",
        "    # clear_output()\n",
        "    saveJPEG(image)\n",
        "    caption = (\n",
        "        TelegramTextBuilder()\n",
        "        .plain(f\"seed={seed}, cfg={cfg}, step={steps}, w={width}, h={height}\")\n",
        "        .new_line()\n",
        "        .quote(positive_prompt, True, True)\n",
        "        .new_line()\n",
        "        .build()\n",
        "    )\n",
        "    await broadcast_image_to_telegram_bot('/content/KMUI/output/image.jpg', caption=caption)\n",
        "    # img"
      ],
      "metadata": {
        "id": "qBGb7iU970Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "source_image = load_image('/content/negin.jpg')\n",
        "swapped_img = ReActorFaceSwap().swap(input_image=image, source_image=source_image)\n",
        "print(f'time: {str(time.time()-t1)} sec')\n",
        "swp_img = get_printable_image(swapped_img)\n",
        "swp_img"
      ],
      "metadata": {
        "id": "-cm6tLb_ShMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple text to image Flux.1"
      ],
      "metadata": {
        "id": "VbVrHjyy1QOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['vaginalsexlora.safetensors', '0.8'],\n",
        "]\n",
        "unet3, clip3 = apply_lora(unet=unet2, lora=default_lora_list, clip=clip2)"
      ],
      "metadata": {
        "id": "OO0d3yVMVO5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "prompt = '''\n",
        "A strikingly beautiful girl with a detailed, angelic soft face lies on a luxurious, red satin bed, her expression a mix of passion and vulnerability. The room is dimly lit, with soft, golden light casting warm shadows across her smooth skin. The composition focuses on the interplay of light and shadow, emphasizing the curves and contours of their bodies, creating a visually captivating and sensual image.'''\n",
        "\n",
        "# prompt = 'tangled embrace, beautiful faces locked in deep intense gaze, nipples hard and straining, nipples pert and erect, aching need written all over their nice faces, hands roaming and caressing, stroking every curve, tongue darting out to lick and taste, fingers teasing and toying with sensitive nipples, making them even harder, driving them both wild with desire, rubbing together in the slick heat, pelvic grinding, pumping faster and faster, slamming together in deep penetrating thrusts, desperate for more of that incredible pleasure, breathless screams torn from throat, body tensing and quivering on the brink, falling off the edge into oblivion'\n",
        "t1 = time.time()\n",
        "seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "width = int(512 * 1.5)\n",
        "height = int(768 * 1.5)\n",
        "empty_latent = create_empty_latent(width, height)\n",
        "\n",
        "latent = ksampler(model=unet, seed=seed, positive=encode_prompt(clip, prompt), negative=encode_prompt(clip, \"bad quality\"), latent=empty_latent)\n",
        "image = vae_decode(vae, latent)\n",
        "print(f'seed={seed}, time: {str(time.time()-t1)} sec')\n",
        "img = get_printable_image(image)\n",
        "img\n",
        "\n",
        "saveJPEG(image, name=f'lunar-{str(datetime.now().strftime(\"%H%M%S\"))}')\n"
      ],
      "metadata": {
        "id": "xcFxnUUm1Q9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "source_image = load_image('/content/negar.jpg')\n",
        "swapped_img = ReActorFaceSwap().swap(input_image=image, source_image=source_image)\n",
        "print(f'time: {str(time.time()-t1)} sec')\n",
        "swp_img = get_printable_image(swapped_img)\n",
        "swp_img"
      ],
      "metadata": {
        "id": "gVle9H8T0-Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_management.unload_all_models()"
      ],
      "metadata": {
        "id": "obVI5mIEpuY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "yAYDIF9exOYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple image to image"
      ],
      "metadata": {
        "id": "qYRTxq85lwyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if seed == 0:\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "print(f'seed={seed}')\n",
        "\n",
        "pixels = load_image('example.png')\n",
        "latent = vae_encode(vae, pixels)\n",
        "latent = ksampler(unet, seed, steps, cfg, sampler, scheduler,\n",
        "                  encode_prompt(clip, positive_prompt), encode_prompt(clip, negative_prompt),\n",
        "                  latent, denoise=0.8)\n",
        "image = vae_decode(vae, latent)\n",
        "img = get_printable_image(image)\n",
        "img"
      ],
      "metadata": {
        "id": "eHbGqwBVcrkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UpScale Image"
      ],
      "metadata": {
        "id": "OaYV1yCpKOlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_nX = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=1)\n",
        "latent = vae_encode(vae, image_nX)\n",
        "latent = ksampler(unet2, seed, steps, cfg, sampler, scheduler,\n",
        "                  encode_prompt(clip, positive_prompt), encode_prompt(clip, negative_prompt),\n",
        "                  latent, denoise=0.4)\n",
        "image_nX = vae_decode(vae, latent)\n",
        "img = get_printable_image(image_nX)\n",
        "img"
      ],
      "metadata": {
        "id": "o7GfOEAUGeyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Batch Image Generator"
      ],
      "metadata": {
        "id": "QKxVHBIfvfyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import piexif\n",
        "from datetime import datetime\n",
        "import time\n",
        "import json\n",
        "import gc\n",
        "import PIL.Image\n",
        "import random\n",
        "\n",
        "class BatchImageGeneratorWithAI:\n",
        "\n",
        "    def __init__(self, path='/content/output', image_perfix='km_'):\n",
        "        self.out_path = os.path.join(path, datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "        if not os.path.exists(self.out_path):\n",
        "            os.makedirs(self.out_path)\n",
        "\n",
        "        self.file_perfix=image_perfix\n",
        "        self.base_model=None\n",
        "        self.model = None\n",
        "        self.base_clip=None\n",
        "        self.promptGenerator = None\n",
        "        try:\n",
        "            self.lora_list = json.loads(read_file('/content/lora.txt'))\n",
        "        except Exception as e:\n",
        "            self.lora_list = []\n",
        "\n",
        "        self.disable_lora = False\n",
        "        self.default_lora_list = []\n",
        "        self.pre_prompt = ''\n",
        "\n",
        "    def add_vae(self, vae_file_name=None):\n",
        "        self.vae, name = load_vae(vae_file_name)\n",
        "\n",
        "    def apply_lora(self, lora_list=[]):\n",
        "        flist = []\n",
        "        flist.extend(self.default_lora_list)\n",
        "        flist.extend(lora_list)\n",
        "\n",
        "        if self.base_model:\n",
        "            self.model, self.clip = apply_lora(self.base_model, lora=flist, clip=self.base_clip, apply_to_clip=True)\n",
        "        else:\n",
        "            raise Expection('load model firt!')\n",
        "\n",
        "    def add_to_positive_prompt(self, pre_prompt=''):\n",
        "        self.pre_prompt=pre_prompt\n",
        "\n",
        "    def remove_lora(self):\n",
        "        self.default_lora_list = []\n",
        "        self.model = self.base_model\n",
        "\n",
        "    def load_image_generator_model(self, ckpt_name=None, hyper_lora:HyperLoRa=None):\n",
        "        print('Start loading Image Generator Ai')\n",
        "        t1 = time.time()\n",
        "        self.unet, self.base_clip, self.vae, self.model_name = load_checkpoint(ckpt_name)\n",
        "        self.clip = self.base_clip\n",
        "        if hyper_lora:\n",
        "            self.base_model = apply_hyper_lora(self.unet, hyper_lora)\n",
        "            self.model = self.base_model\n",
        "        else:\n",
        "            self.base_model = self.unet\n",
        "            self.model = self.base_model\n",
        "        print(f'Model {ckpt_name} loaded at {str(round(time.time() - t1, 1))} second.')\n",
        "\n",
        "    def generate_prompt_with_ai(self, general_prompt, following_prompt, keywords, number, path_to_save=None):\n",
        "        def get_lora_detailds(id):\n",
        "            for lora in self.lora_list:\n",
        "                if id == lora[\"id\"]:\n",
        "                    return lora\n",
        "\n",
        "        if self.promptGenerator is None:\n",
        "            print('Start loading Prompt Generator Ai')\n",
        "            t1 = time.time()\n",
        "\n",
        "            base_model = None\n",
        "            if model_type == \"SDXL\":\n",
        "                base_model = 'SDXL 1.0'\n",
        "            elif model_type == \"SD15\":\n",
        "                base_model = 'SD 1.5'\n",
        "\n",
        "            n_ctx = 4 * 1024 if self.disable_lora else 4*1024\n",
        "            try:\n",
        "                if promptGenerator:\n",
        "                    self.promptGenerator = promptGenerator\n",
        "            except Exception as e:\n",
        "                self.promptGenerator = PromptGenerator(n_ctx=n_ctx, lora_list=self.lora_list, basemodel=base_model)\n",
        "\n",
        "            print(f'Prompt Generator Ai loaded in {str(round(time.time() - t1, 1))} second.')\n",
        "        else:\n",
        "            self.promptGenerator.clear_history()\n",
        "\n",
        "        print('Start generating prompts ...')\n",
        "        t1 = time.time()\n",
        "        prompt_list = []\n",
        "\n",
        "        prompt_list_file_name = f'prompt_list {str(datetime.now().strftime(\"%H%M%S\"))}.txt'\n",
        "        while len(prompt_list) < number:\n",
        "            print()\n",
        "            print()\n",
        "            print(f\"++++  Start {len(prompt_list)} ---------------------------------------\")\n",
        "            print()\n",
        "            ai_seed=random.randint(0, 1844674124)\n",
        "            # ai_prompt, out = self.promptGenerator.generate_prompt(prompt=general_prompt if len(prompt_list) == 0 else following_prompt, seed=ai_seed)\n",
        "            self.promptGenerator.clear_history()\n",
        "            kws = keywords()\n",
        "            main_prompt = general_prompt.replace(\"RP_Keywords\", kws)\n",
        "            ai_prompt, out = self.promptGenerator.generate_prompt(prompt=main_prompt, seed=ai_seed, use_system_prompt=False)\n",
        "            if ai_prompt:\n",
        "                try:\n",
        "                    if len(ai_prompt) > 1000:\n",
        "                        ai_prompt = ai_prompt[:1000]\n",
        "                    ai_prompt = ai_prompt.split('\\n')\n",
        "                    if len(ai_prompt) > 1:\n",
        "                        if 'The prompt' in ai_prompt[0] or 'Here' in ai_prompt[0]:\n",
        "                            ai_prompt = ai_prompt[1] if len(ai_prompt[1]) > 10 else (ai_prompt[2] if len(ai_prompt[2]) > 10 else '')\n",
        "                        else:\n",
        "                            ai_prompt = ai_prompt[0]\n",
        "                    else:\n",
        "                        ai_prompt = ai_prompt[0]\n",
        "\n",
        "                    positive_prompt = ai_prompt\n",
        "                    print(f\"positive_prompt: {positive_prompt}\")\n",
        "\n",
        "                    if self.disable_lora:\n",
        "                         prompt_list.append((positive_prompt, '', None))\n",
        "                    else:\n",
        "                        def is_duplicate(item, llist):\n",
        "                            for it in llist:\n",
        "                                if it[\"id\"] == item[\"id\"]:\n",
        "                                    return True\n",
        "                            return False\n",
        "\n",
        "                        try:\n",
        "                            lora_prompt, out = self.promptGenerator.generate_lora_list(str(json.dumps(ai_prompt)), seed=ai_seed)\n",
        "                            llora = []\n",
        "                            pp = positive_prompt\n",
        "                            for it in lora_prompt:\n",
        "                                if is_duplicate(it, llora):\n",
        "                                    continue\n",
        "\n",
        "                                lora = get_lora_detailds(it[\"id\"])\n",
        "                                if lora:\n",
        "                                    pp = positive_prompt\n",
        "                                    if \"trainedWords\" in lora:\n",
        "                                        pp += f', {lora[\"trainedWords\"][0]}'\n",
        "\n",
        "                                    if \"weights\" in it:\n",
        "                                        lora[\"weights\"] = it[\"weights\"]\n",
        "                                        print(f\"    |- lora loaded: {lora['name']}\")\n",
        "                                        llora.append(lora)\n",
        "\n",
        "                            prompt_list.append((pp, '', llora))\n",
        "                        except Exception as e:\n",
        "                            print(f\"bad lora prompt: {out}\")\n",
        "                            prompt_list.append((positive_prompt, '', None))\n",
        "\n",
        "                except Exception as er:\n",
        "                    print(f\"bad prompt: {out['choices'][0]['message']['content']}\")\n",
        "\n",
        "            if path_to_save:\n",
        "                data = {\n",
        "                    \"general_prompt\": main_prompt,\n",
        "                    \"following_prompt\": following_prompt,\n",
        "                    \"prompt_list\": prompt_list\n",
        "                }\n",
        "                file_name = os.path.join(path_to_save, prompt_list_file_name)\n",
        "                with open(file_name, 'w') as file:\n",
        "                    file.write(json.dumps(data, indent=4))\n",
        "                    file.close()\n",
        "\n",
        "        if path_to_save:\n",
        "            print(f\"Prompts printed to {file_name}\")\n",
        "        print(f'Prompt Generated at {str(round(time.time() - t1, 1))} second.')\n",
        "        return prompt_list\n",
        "\n",
        "    def load_prompts(self, file_name):\n",
        "        with open(file_name, 'r') as file:\n",
        "            contents = file.read()\n",
        "            file.close()\n",
        "        return json.loads(contents)['prompt_list']\n",
        "\n",
        "    def free_memory(self):\n",
        "        if self.promptGenerator:\n",
        "            self.promptGenerator.free_memory()\n",
        "            self.promptGenerator = None\n",
        "\n",
        "        if self.base_model:\n",
        "            self.base_model=None\n",
        "            self.model = None\n",
        "            self.clip = None\n",
        "            self.vae = None\n",
        "            model_management.soft_empty_cache(force=True)\n",
        "            model_management.unload_all_models()\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    def set_default_lora(self, default_lora_list=[]):\n",
        "        self.default_lora_list=default_lora_list\n",
        "\n",
        "    async def text_to_image(self, prompt_list, batch=6, upscale=None, width=512, height=768, steps=10, cfg=0.9, negative_prompt='', p_seed=None,\n",
        "                      sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM, denoise=0.35, save_log=False, split_sampler=False, lora_prompt=''):\n",
        "        print()\n",
        "        t1 = time.time()\n",
        "        empty_latent = create_empty_latent(width, height)\n",
        "        if self.disable_lora and len(self.default_lora_list) > 0:\n",
        "            self.apply_lora()\n",
        "\n",
        "        for i in range(len(prompt_list)):\n",
        "            positive_prompt = self.pre_prompt + prompt_list[i][0] + lora_prompt\n",
        "            llora = prompt_list[i][2]\n",
        "            list_of_lora_name = []\n",
        "            if not self.disable_lora:\n",
        "                if llora:\n",
        "                    for it in llora:\n",
        "                        try:\n",
        "                            it[\"filename\"] = it[\"filename\"].replace(\" \", \"_\").replace(\" \", \"_\")\n",
        "                            if not os.path.exists(os.path.join(modelpaths.lora, str(it[\"filename\"]))):\n",
        "                                # download lora\n",
        "                                download(f'https://civitai.com/api/download/models/{it[\"id\"]}', str(it[\"filename\"]), modelpaths.lora)\n",
        "                            if os.path.exists(os.path.join(modelpaths.lora, str(it[\"filename\"]))):\n",
        "                                list_of_lora_name.append([str(it[\"filename\"]), float(it[\"weights\"])])\n",
        "                        except Exception as e:\n",
        "                            print(f\"bad lora prompt: {e}\")\n",
        "                    self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "            # generate\n",
        "            for j in range(batch):\n",
        "                print(f'Start batch: {i}, image number: {j}')\n",
        "\n",
        "                seed = p_seed if p_seed is not None else random.randint(0, 18446744073709551615)\n",
        "                # seed = 125\n",
        "                if not split_sampler:\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                        positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                        latent=empty_latent)\n",
        "                else:\n",
        "                    stp = steps//3\n",
        "\n",
        "                    start_step = 0\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt),negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=empty_latent, start_step=start_step, last_step=last_step, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                    start_step = last_step\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=latent, start_step=start_step, last_step=last_step, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                    start_step = last_step\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=latent, start_step=start_step, last_step=steps, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                image = vae_decode(self.vae, latent)\n",
        "\n",
        "                # upscale\n",
        "                if upscale:\n",
        "                    # self.default_lora_list.append(['Hyper-SD15-8steps-lora.safetensors', 1.0])\n",
        "                    # self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "                    upscale = float(upscale)\n",
        "                    if upscale > 0.2 and upscale <= 4:\n",
        "                        if upscale <= 2:\n",
        "                            image = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=upscale * 0.5)\n",
        "                        elif upscale > 2:\n",
        "                            image = scale_by_model(image, UpscalerModel.UltraSharp_4x, scale=upscale * 0.25)\n",
        "                        latent = vae_encode(self.vae, image)\n",
        "                        latent = ksampler(model=self.model, seed=seed, steps=8, cfg=0.95, sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM,\n",
        "                                        positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                        latent=latent, denoise=denoise)\n",
        "                        image = vae_decode(self.vae, latent)\n",
        "\n",
        "                    # self.default_lora_list.pop()\n",
        "                    # self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "                await self.save_image(self.file_perfix, image, positive_prompt, negative_prompt, width, height,\n",
        "                                seed, steps, cfg, sampler, scheduler, upscale, denoise, list_of_lora_name, save_log=save_log)\n",
        "\n",
        "        if self.disable_lora and len(self.default_lora_list) > 0:\n",
        "            self.remove_lora()\n",
        "\n",
        "        print(f\"finish generating {len(prompt_list) * batch} images in {str(time.time() - t1)} second.\")\n",
        "\n",
        "    async def image_upscale(self, img_file, prompts, upscale=None, seed=0, steps=8, cfg=0.85,\n",
        "                      sampler=Sampler.DDIM, scheduler=Scheduler.NORMAL, denoise=0.4, save_log=False):\n",
        "\n",
        "        if type(img_file) == str:\n",
        "            image = load_image(img_file)\n",
        "            file_name = os.path.splitext(os.path.basename(img_file))[0]\n",
        "        else:\n",
        "            raise Exception('this methos is only for image files.')\n",
        "\n",
        "        if upscale:\n",
        "            print()\n",
        "            t1 = time.time()\n",
        "            print(f'Start upscale image: {file_name} to {upscale}')\n",
        "\n",
        "            upscale = float(upscale)\n",
        "            if seed < 1:\n",
        "                seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "            if upscale > 0.2 and upscale <= 4:\n",
        "                if upscale <= 2:\n",
        "                    image = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=upscale * 0.5)\n",
        "                elif upscale > 2:\n",
        "                    image = scale_by_model(image, UpscalerModel.UltraSharp_4x, scale=upscale * 0.25)\n",
        "                latent = vae_encode(self.vae, image)\n",
        "                latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                positive=encode_prompt(self.clip, self.pre_prompt + prompts[0]), negative=encode_prompt(self.clip, prompts[1]),\n",
        "                                latent=latent, denoise=denoise)\n",
        "                image = vae_decode(self.vae, latent)\n",
        "            await self.save_image(file_name, image, self.pre_prompt + prompts[0], prompts[1], image.shape[2], image.shape[1],\n",
        "                                seed, steps, cfg, sampler, scheduler, upscale, denoise, lora_list=[], save_log=save_log)\n",
        "            print(f\"Finish generating images in {str(time.time() - t1)} second.\")\n",
        "\n",
        "    async def save_image(self, file_name, image, p_prompt, n_prompt, width=512, height=768, seed=0, steps=10, cfg=0.95,\n",
        "                         sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM, upscale=None, denoise=0.4, lora_list=[],\n",
        "                         save_log=False, broadcast_image=True):\n",
        "\n",
        "        flist = []\n",
        "        flist.extend(self.default_lora_list)\n",
        "        flist.extend(lora_list)\n",
        "\n",
        "        zeroth_ifd = {\n",
        "            \"positive_prompt\": p_prompt,\n",
        "            \"negative_prompt\": n_prompt,\n",
        "            \"width\": str(width),\n",
        "            \"height\": str(height),\n",
        "            \"seed\": str(seed),\n",
        "            \"steps\": str(steps),\n",
        "            \"cfg\": str(cfg),\n",
        "            \"sampler\": str(sampler.value),\n",
        "            \"scheduler\": str(scheduler.value),\n",
        "            \"upscale\": str(upscale),\n",
        "            \"denoise\": str(denoise),\n",
        "            \"model_name\": str(self.model_name),\n",
        "            \"lora\": flist,\n",
        "        }\n",
        "\n",
        "        metadata_string = json.dumps(zeroth_ifd)\n",
        "        exif_dict = {\n",
        "            '0th': {\n",
        "                piexif.ImageIFD.ImageDescription: metadata_string,  # Store the serialized dictionary\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Convert the EXIF dictionary to bytes\n",
        "        exif_bytes = piexif.dump(exif_dict)\n",
        "        if file_name and len(file_name) and self.file_perfix in file_name:\n",
        "            name =  file_name + str(datetime.now().strftime(\"%H%M%S\"))\n",
        "        else:\n",
        "            name =  self.file_perfix + '_' + str(datetime.now().strftime(\"%H%M%S\"))\n",
        "\n",
        "        if save_log:\n",
        "            file_name = os.path.join(self.out_path, f\"{name}.log\")\n",
        "            with open(file_name, 'w') as file:\n",
        "                file.write(json.dumps(zeroth_ifd))\n",
        "                file.close()\n",
        "\n",
        "        saveJPEG(image=image, path=self.out_path, name=f'{name}', quality=90, exif=exif_bytes)\n",
        "\n",
        "        if broadcast_image:\n",
        "            caption = (\n",
        "                TelegramTextBuilder()\n",
        "                .plain(f\"seed={seed}, cfg={cfg}, step={steps}, w={width}, h={height}\")\n",
        "                .new_line()\n",
        "                .quote(p_prompt, True, True)\n",
        "                .new_line()\n",
        "                .build()\n",
        "            )\n",
        "            await broadcast_image_to_telegram_bot(f'{self.out_path}/{name}.jpg', caption=caption)\n",
        "\n",
        "def get_prompts_in_all_categories(categorized_prompts_file, required_categories):\n",
        "    \"\"\"\n",
        "    Find prompts that exist in ALL of the specified category lists.\n",
        "\n",
        "    Args:\n",
        "        categorized_prompts_file (str): Path to categorized prompts JSON\n",
        "        required_categories (list): Categories the prompt must appear in\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of matching prompts, output file path)\n",
        "    \"\"\"\n",
        "    with open(categorized_prompts_file, 'r', encoding='utf-8') as f:\n",
        "        categorized_prompts = json.load(f)\n",
        "\n",
        "    # Verify all required categories exist\n",
        "    missing_categories = [cat for cat in required_categories if cat not in categorized_prompts]\n",
        "    if missing_categories:\n",
        "        raise ValueError(f\"Categories not found: {missing_categories}\")\n",
        "\n",
        "    # Get sets of prompts for each required category\n",
        "    prompt_sets = [set(categorized_prompts[cat]) for cat in required_categories]\n",
        "\n",
        "    # Find intersection (prompts present in all sets)\n",
        "    common_prompts = set(prompt_sets[0])\n",
        "    for prompt_set in prompt_sets[1:]:\n",
        "        common_prompts.intersection_update(prompt_set)\n",
        "\n",
        "    matching_prompts = list(common_prompts)\n",
        "\n",
        "    return matching_prompts"
      ],
      "metadata": {
        "id": "ePf2bUCHvfSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/result')\n",
        "# gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True"
      ],
      "metadata": {
        "id": "rzwEBzv-Z-gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen.free_memory()"
      ],
      "metadata": {
        "id": "XQAG1gv2g-2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen.load_image_generator_model(ckpt_name='aniverse_v50Pruned.safetensors', hyper_lora=None)\n",
        "# gen.load_image_generator_model(ckpt_name=None, hyper_lora=None)\n",
        "# gen.add_vae()"
      ],
      "metadata": {
        "id": "ruWM7mcR1et4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 182046.txt')\n",
        "required = [\"pose\", \"action\", \"sex_position\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    # ['Upright_front_above_2-000012.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    # ['xl_more_art-full-v1.safetensors', 0.8],\n",
        "    # ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    # ['Rendered_Face_Detailer_v1.0.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    # ['skin_texture_style_v4.safetensors', 1],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    # ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_list=[\n",
        "    ['POVMissionary.safetensors', 0.8],\n",
        "    # ['MissionaryVaginal-v2.safetensors', 0.7],\n",
        "    # ['upright_front_above_50.safetensors', 0.7],\n",
        "    # ['upright_straddle_20.safetensors', 0.7],\n",
        "    # ['EkuneSideDoggy.safetensors', 0.7],\n",
        "]\n",
        "lora_prompt = ''\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, 3DMM' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='score_9, score_8_up, score_7_up, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "# gen.text_to_image(prompt_list=prompt_list[2:4], batch=1, upscale=None, width=832, height=1216, steps=8, p_seed=145, cfg=0.98,\n",
        "#                   negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)\n",
        "gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=20, cfg=6, denoise=0.2, p_seed=145, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)\n",
        "\n",
        "# for item in lora_list:\n",
        "#     nlist = default_lora_list.copy()\n",
        "#     nlist.append(item)\n",
        "#     gen.set_default_lora(default_lora_list=nlist)\n",
        "#     # gen.text_to_image(prompt_list=prompt_list[0:10], batch=1, upscale=None, width=640, height=960)\n",
        "#     gen.text_to_image(prompt_list=prompt_list[0:1], batch=1, upscale=1.4, steps=25, cfg=7, sampler=Sampler.DPM_PP_2M_SDE,\n",
        "#                       scheduler=Scheduler.KARRAS)"
      ],
      "metadata": {
        "id": "kXAVthHzo70t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"pose\", \"sex_position\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "print(len(prompts))"
      ],
      "metadata": {
        "id": "YMXxtCb53BCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['xl_more_art-full-v1.safetensors', 0.9],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 2.5],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.6],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "lora_prompt = ', 3DMM, perfecteyes'\n",
        "# gen.remove_lora()\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.apply_lora()\n",
        "\n",
        "for item in os.listdir(gen.out_path)[:4]:\n",
        "    if item.endswith(\".log\"):\n",
        "        sItem = os.path.join(gen.out_path, item)\n",
        "        data = json.loads(read_file(sItem))\n",
        "        gen.image_upscale(img_file=sItem.replace(\".log\", \".jpg\"), prompts=[data['positive_prompt']+lora_prompt, data['negative_prompt']],\n",
        "                          cfg=1, upscale=1.6, seed=int(data['seed']), steps=8, denoise=0.35)\n",
        "        # os.remove(sItem)\n",
        "        # os.remove(sItem.replace(\".log\", \".jpg\"))\n",
        "gen.remove_lora()"
      ],
      "metadata": {
        "id": "BJJbt7jeiTBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 1 (Fucktastic 2.5D Checkpoint)"
      ],
      "metadata": {
        "id": "nk0ahcge7L7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='fucktastic25DCheckpointPony_10.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "BuHSOYIA7qFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['xl_more_art-full-v1.safetensors', 0.8],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['Rendered_Face_Detailer_v1.0.safetensors', 0.9],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', perfecteyes, Expressiveh, 7-cgifaces'\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[2:4], batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "NbH_RtFG7r_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[2:4], batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "9S-R0tgs9-F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slow"
      ],
      "metadata": {
        "id": "xtaIVWuxBIqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "]\n",
        "\n",
        "lora_prompt = ''\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[2:4], batch=1, upscale=None, width=768, height=1152, steps=24, cfg=7, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.SIMPLE, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "-7JQdCBtAYj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 2 (waiNSFWIllustrious_v100)"
      ],
      "metadata": {
        "id": "f27WiESiDLoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='waiNSFWIllustrious_v100.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "XAU96zr2DLoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 182046.txt')\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.9],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', perfecteyes, Expressiveh, , aesthetic'\n",
        "pre_prompt='3D, CG Girl, detailed eyes, highly detailed body, '\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[5:], batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "tD0GVMQEDLoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slow"
      ],
      "metadata": {
        "id": "VuCiuU27DLoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 182046.txt')\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "]\n",
        "\n",
        "lora_prompt = ', perfecteyes, Expressiveh, aesthetic'\n",
        "pre_prompt='3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[:2], batch=1, upscale=None, width=768, height=1152, steps=20, cfg=7, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_SDE, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "efdgIO6pDLoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 3 (prefectPonyXL_v3)"
      ],
      "metadata": {
        "id": "EGZv4mdi-PdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='prefectPonyXL_v3.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "b3ro5DOT-PdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.7],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.6],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[:2], batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "OeYx6zlx-PdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 4 (realcartoonXL_v7)"
      ],
      "metadata": {
        "id": "2gOEbnAFCZgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='realcartoonXL_v7.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "VYAbOniyCZgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.3],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.3],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[:2], batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "WzMsY9OtCZgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 5 (aniversePonyXL_v50)"
      ],
      "metadata": {
        "id": "iGaE319xH6AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='aniversePonyXL_v50.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "8RStVU8NH6AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "# prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "\n",
        "with open('/content/prompts/prompts_20250825_133110.json', 'r', encoding='utf-8') as f:\n",
        "        prompts = json.load(f)['prompts']\n",
        "\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.4],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.3],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=21, cfg=6, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "B8KOO2yUH6AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 6 (iniverseMixSFWNSFW_ponyRealGuofengV50C) # realistic photo"
      ],
      "metadata": {
        "id": "pKdi1__RPckq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='iniverseMixSFWNSFW_ponyRealGuofengV50C.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "_7qpOW-iPcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"dress\", \"sensual\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='3D, CG model, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "4M0_CKzbPcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 7 (fucktastic25DCheckpointPony_v20)"
      ],
      "metadata": {
        "id": "wl0ZDMQbe8WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='fucktastic25DCheckpointPony_v20.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "DuGsNFl9e8WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required = [\"expression\", \"action\", \"sensual\"]\n",
        "\n",
        "# prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "\n",
        "with open('/content/drive/MyDrive/AI/prompts_20250825_171021.json', 'r', encoding='utf-8') as f:\n",
        "        prompts = json.load(f)['prompts']\n",
        "\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, 3DMM' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='score_9, score_8_up, score_7_up, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=20, cfg=6, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "XX7KkUnKe8WS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AyH4Jb5mNofH",
        "USPvp_jieoRL",
        "vUabsHbSTKF6",
        "Nb8G2WauywJu"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}