{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamranr123/kamranr123.github.io/blob/master/km_ui_sd%20v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> KM Colab</h1>"
      ],
      "metadata": {
        "id": "Ww9RtC1NhlgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "Flux_mode = False\n",
        "model_type = \"SDXL\" # @param [\"SD15\",\"SDXL\",\"Flux. 1 dev\",\"Flux. 1 Schnell\", \"SD3.5\"]\n",
        "\n",
        "Flux_mode = 'Flux' in model_type\n",
        "def gn():\n",
        "    # return 'TotoroUI' if Flux_mode else 'CKMyUI'.replace(\"KM\", 'omf')\n",
        "    return 'CKMyUI'.replace(\"KM\", 'omf')\n",
        "\n",
        "# gnn= 'TotoroUI' if Flux_mode else 'KMUI'\n",
        "gnn= 'KMUI'\n"
      ],
      "metadata": {
        "id": "D-0_qj5YQbt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initial"
      ],
      "metadata": {
        "id": "b-lSsUXClM0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, clear_output\n",
        "!pip install python-telegram-bot\n",
        "# !pip install wget\n",
        "!pip install piexif\n",
        "# ******************************************************************************\n",
        "# !pip install -q torchsde einops diffusers accelerate xformers==0.0.27.post2\n",
        "# !pip install spandrel\n",
        "!apt -y install -qq aria2\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "AYaxBtWIETRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, clear_output\n",
        "\n",
        "# import wget\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        contents = file.read()\n",
        "    return contents\n",
        "# ******************************************************************************\n",
        "class Modelpaths:\n",
        "    base_path = f'/content/{gnn}/models'\n",
        "    model = f'{base_path}/checkpoints'\n",
        "    lora = f'{base_path}/loras'\n",
        "    vae = f'{base_path}/vae'\n",
        "    upscale = f'{base_path}/upscale_models'\n",
        "    controlnet = f'{base_path}/controlnet'\n",
        "    embeddings = f'{base_path}/embeddings'\n",
        "    diffusers = f'{base_path}/diffusers'\n",
        "    unet = f'{base_path}/unet'\n",
        "    clip = f'{base_path}/clip'\n",
        "\n",
        "    def __init__(self):\n",
        "        if not os.path.exists(self.base_path):\n",
        "            os.makedirs(self.model)\n",
        "            os.makedirs(self.lora)\n",
        "            os.makedirs(self.vae)\n",
        "            os.makedirs(self.upscale)\n",
        "            os.makedirs(self.embeddings)\n",
        "            os.makedirs(self.diffusers)\n",
        "            os.makedirs(self.unet)\n",
        "            os.makedirs(self.clip)\n",
        "\n",
        "modelpaths = Modelpaths()\n",
        "\n",
        "# ******************************************************************************\n",
        "def download(model_link, model_name, path=modelpaths.model):\n",
        "    if 'civitai' in model_link:\n",
        "        if \"?\" in model_link:\n",
        "            model_link = f\"{model_link},token=2a98e142e24406e7fbb077e80b0418a6\"\n",
        "        else:\n",
        "            model_link = f\"{model_link}?token=2a98e142e24406e7fbb077e80b0418a6\"\n",
        "\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "    else:\n",
        "        if path == modelpaths.model:\n",
        "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error -c -x 16 -s 8 -k 1M {model_link} --dir={path} --out={model_name}\n",
        "\n",
        "def download_from_civitai(model_id, versian_id):\n",
        "    url = f\"https://civitai.com/api/v1/models/{str(model_id)}\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # If the request was successful, print the JSON content\n",
        "    json_data = ''\n",
        "    if response.status_code == 200:\n",
        "        json_data = response.json()\n",
        "\n",
        "        m_type = json_data[\"type\"]\n",
        "        mpath = modelpaths.base_path\n",
        "\n",
        "        if m_type == 'Checkpoint':\n",
        "            mpath = modelpaths.model\n",
        "        elif m_type == 'TextualInversion':\n",
        "            mpath = modelpaths.embeddings\n",
        "        elif m_type == 'LORA':\n",
        "            mpath = modelpaths.lora\n",
        "        elif m_type == 'Controlnet':\n",
        "            mpath = modelpaths.controlnet\n",
        "\n",
        "        for it in json_data[\"modelVersions\"]:\n",
        "            if str(it[\"id\"]) == str(versian_id):\n",
        "                download(f'https://civitai.com/api/download/models/{it[\"id\"]}', str(it[\"files\"][0][\"name\"]), mpath)\n",
        "                return str(it[\"files\"][0][\"name\"])\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "def replace_word_in_file(file_path, target_word, new_word):\n",
        "    try:\n",
        "        # Open the file in read mode\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Read the file content\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Replace the target word with the new word\n",
        "        modified_content = file_content.replace(target_word, new_word)\n",
        "        modified_content = modified_content.replace(f'{gnn}-Impact-Subpack', 'ComfyUI-Impact-Subpack') #exeption\n",
        "\n",
        "        # Open the file in write mode to overwrite its content\n",
        "        with open(file_path, 'w') as file:\n",
        "            # Write the modified content back to the file\n",
        "            file.write(modified_content)\n",
        "\n",
        "        # print(f\"Word '{target_word}' replaced with '{new_word}' in {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}: {file_path}\")\n",
        "\n",
        "def forceCopyFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.copy2(sfile, dfile)\n",
        "\n",
        "def forceMoveFile (sfile, dfile):\n",
        "    if os.path.isfile(sfile):\n",
        "        shutil.move(sfile, dfile)\n",
        "\n",
        "def isAFlatDir(sDir):\n",
        "    for item in os.listdir(sDir):\n",
        "        sItem = os.path.join(sDir, item)\n",
        "        if os.path.isdir(sItem):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def moveTree(src, dst, target_word='Comfy', new_word=gnn):\n",
        "    _dst = dst.replace(target_word, new_word)\n",
        "    _dst = _dst.replace(target_word.lower(), new_word.lower())\n",
        "\n",
        "    for item in os.listdir(src):\n",
        "        _item = item.replace(target_word, new_word)\n",
        "        _item = _item.replace(target_word.lower(), new_word.lower())\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(_dst, _item)\n",
        "\n",
        "        if os.path.isfile(s):\n",
        "            if not os.path.exists(_dst):\n",
        "                os.makedirs(_dst)\n",
        "            forceMoveFile(s,d)\n",
        "            replace_word_in_file(d, target_word, new_word)\n",
        "            replace_word_in_file(d, target_word.lower(), new_word.lower())\n",
        "        if os.path.isdir(s):\n",
        "            isRecursive = not isAFlatDir(s)\n",
        "            if isRecursive:\n",
        "                moveTree(s, d)\n",
        "            else:\n",
        "                if not os.path.exists(d):\n",
        "                    os.makedirs(d)\n",
        "                for item2 in os.listdir(s):\n",
        "                    _item = item2.replace(target_word, new_word)\n",
        "                    _item = _item.replace(target_word.lower(), new_word.lower())\n",
        "                    srcFile = os.path.join(s, item2)\n",
        "                    dstFile = os.path.join(d, _item)\n",
        "                    forceMoveFile(srcFile, dstFile)\n",
        "                    replace_word_in_file(dstFile, target_word, new_word)\n",
        "                    replace_word_in_file(dstFile, target_word.lower(), new_word.lower())\n",
        "\n"
      ],
      "metadata": {
        "id": "InBOxoWDlRhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Telegram Bot"
      ],
      "metadata": {
        "id": "APupapWeCXhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class TelegramTextBuilder:\n",
        "    def __init__(self):\n",
        "        self.parts = []\n",
        "\n",
        "    def _escape(self, text: str) -> str:\n",
        "        # Escape HTML special characters for Telegram HTML mode\n",
        "        escape_chars = {\n",
        "            '<': '&lt;',\n",
        "            '>': '&gt;',\n",
        "            '&': '&amp;',\n",
        "            '\"': '&quot;'\n",
        "        }\n",
        "        return ''.join(escape_chars.get(c, c) for c in text)\n",
        "\n",
        "    def plain(self, text: str):\n",
        "        self.parts.append(self._escape(text))\n",
        "        return self\n",
        "\n",
        "    def bold(self, text: str):\n",
        "        self.parts.append(f\"<b>{self._escape(text)}</b>\")\n",
        "        return self\n",
        "\n",
        "    def italic(self, text: str):\n",
        "        self.parts.append(f\"<i>{self._escape(text)}</i>\")\n",
        "        return self\n",
        "\n",
        "    def underline(self, text: str):\n",
        "        self.parts.append(f\"<u>{self._escape(text)}</u>\")\n",
        "        return self\n",
        "\n",
        "    def strikethrough(self, text: str):\n",
        "        self.parts.append(f\"<s>{self._escape(text)}</s>\")\n",
        "        return self\n",
        "\n",
        "    def spoiler(self, text: str):\n",
        "        self.parts.append(f\"<span class=\\\"tg-spoiler\\\">{self._escape(text)}</span>\")\n",
        "        return self\n",
        "\n",
        "    def code(self, text: str):\n",
        "        self.parts.append(f\"<code>{self._escape(text)}</code>\")\n",
        "        return self\n",
        "\n",
        "    def pre(self, text: str):\n",
        "        escaped = self._escape(text)\n",
        "        self.parts.append(f\"<pre>{escaped}</pre>\")\n",
        "        return self\n",
        "\n",
        "    def link(self, label: str, url: str):\n",
        "        self.parts.append(f\"<a href=\\\"{url}\\\">{self._escape(label)}</a>\")\n",
        "        return self\n",
        "\n",
        "    def mention(self, name: str, user_id: int):\n",
        "        self.parts.append(f\"<a href=\\\"tg://user?id={user_id}\\\">{self._escape(name)}</a>\")\n",
        "        return self\n",
        "\n",
        "    def quote(self, text: str, collapsible: bool = False, block: bool = False):\n",
        "        escaped = self._escape(text)\n",
        "        if collapsible:\n",
        "            # Collapse newlines into spaces for spoilers to ensure single block\n",
        "            single_line_text = ' '.join(escaped.split('\\n')).strip()\n",
        "            if block:\n",
        "                quoted_text = f\"<blockquote expandable>{self._escape(single_line_text)}</blockquote>\"\n",
        "            else:\n",
        "                quoted_text = f\"<span class=\\\"tg-spoiler\\\">{self._escape(single_line_text)}</span>\"\n",
        "        else:\n",
        "            # Non-collapsible quote\n",
        "            if block:\n",
        "                quoted_text = f\"<blockquote>{escaped}</blockquote>\"\n",
        "            else:\n",
        "                # For non-block quotes, wrap each line in <p> to mimic line-by-line quoting\n",
        "                quoted_text = ''.join(f\"<p>{line}</p>\" for line in escaped.split('\\n') if line)\n",
        "\n",
        "        self.parts.append(quoted_text)\n",
        "        return self\n",
        "\n",
        "    def new_line(self):\n",
        "        self.parts.append(\"\\n\")\n",
        "        return self\n",
        "\n",
        "    def build(self):\n",
        "        return ''.join(self.parts)"
      ],
      "metadata": {
        "id": "rhczEeSQyNYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes\n",
        "from telegram import Update, InputFile\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Store chat_ids for broadcast\n",
        "chat_ids = []\n",
        "\n",
        "# Create shutdown event globally\n",
        "shutdown_event = asyncio.Event()\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    chat_id = update.effective_chat.id\n",
        "    if chat_id not in chat_ids:\n",
        "        chat_ids.append(chat_id)\n",
        "    await update.message.reply_text(\"✅ Bot started!\")\n",
        "\n",
        "async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    chat_id = update.effective_chat.id\n",
        "    if chat_id in chat_ids:\n",
        "        chat_ids.remove(chat_id)\n",
        "    await update.message.reply_text(\"✅ Bot stopped!\")\n",
        "\n",
        "# Broadcast image to all registered users\n",
        "async def broadcast_image_to_telegram_bot(image, caption=None):\n",
        "    for chat_id in chat_ids:\n",
        "        try:\n",
        "            with open(image, \"rb\") as img:\n",
        "                if caption:\n",
        "                    await tb_app.bot.send_photo(chat_id=chat_id, photo=InputFile(img), caption=caption, parse_mode=\"HTML\")\n",
        "                else:\n",
        "                    await tb_app.bot.send_photo(chat_id=chat_id, photo=InputFile(img))\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to send image to {chat_id}: {e}\")\n",
        "\n",
        "# Build bot app\n",
        "# tb_app = ApplicationBuilder().token(\"8186324662:AAEaxnmaSu_mVYeC5NmZb7CPaRnBd0N8-Dk\").build()\n",
        "# tb_app = ApplicationBuilder().token(\"8319818374:AAHyqXgS1ZqiVC1LZzFYWtw2vVou5kIo_cM\").build() # kamhotimbot\n",
        "# tb_app = ApplicationBuilder().token(\"8320463552:AAHT7_6Yo-ON-BcdknjmaCnNykEwDfYBOEg\").build() # sec_imbot\n",
        "# tb_app = ApplicationBuilder().token(\"8298123735:AAEIf9z1S8v9Ok1eRQF34g6VTrFUuVlDyrU\").build() # third_imbot\n",
        "tb_app = ApplicationBuilder().token(\"8117461892:AAH1-6KRrCAivSvrmzR6n17XzgYLIHrQtBY\").build() # 4st_imbot\n",
        "tb_app.add_handler(CommandHandler(\"start\", start))\n",
        "tb_app.add_handler(CommandHandler(\"stop\", stop))\n",
        "\n",
        "# Telegram bot main async loop\n",
        "async def telegrambot_main():\n",
        "    print(\"🚀 Starting Telegram Bot\")\n",
        "    await tb_app.initialize()\n",
        "    await tb_app.start()\n",
        "    await tb_app.updater.start_polling()\n",
        "    print(\"✅ Telegram Bot is Running...\")\n",
        "\n",
        "    # Wait until shutdown_event is triggered\n",
        "    await shutdown_event.wait()\n",
        "\n",
        "    print(\"🔻 Telegram Bot: Shutting down...\")\n",
        "    await tb_app.updater.stop()\n",
        "    await tb_app.stop()\n",
        "    await tb_app.shutdown()\n",
        "    print(\"✅ Telegram Bot shut down cleanly.\")\n",
        "\n",
        "# Thread target to run the bot\n",
        "def run_tg_bot():\n",
        "    asyncio.run(telegrambot_main())\n",
        "\n",
        "# Start the bot in a background thread\n",
        "threading.Thread(target=run_tg_bot).start()\n"
      ],
      "metadata": {
        "id": "Jfg_eRaYJFOK",
        "outputId": "3194c511-970e-48d9-911d-1adebebd55e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Telegram Bot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model"
      ],
      "metadata": {
        "id": "oHhGb05cla8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown extensions (custom node)\n",
        "model_link = \"https://civitai.com/api/download/models/918028?typ\" # @param {\"type\":\"string\",\"placeholder\":\"enter link of model to download\"}\n",
        "model_name = \"Dramatic_Lighting_Slider.safetensors\" # @param {\"type\":\"string\",\"placeholder\":\"enter name of model\"}\n",
        "_model_type = \"LoRa\" # @param [\"Checkpoint\",\"LoRa\",\"ControlNet\", \"VAE\",\"None\"] {\"type\":\"string\"}\n",
        "\n",
        "if _model_type == \"LoRa\":\n",
        "    %cd {modelpaths.lora}\n",
        "    download(model_link, model_name, modelpaths.lora)\n",
        "elif _model_type == \"Checkpoint\":\n",
        "    %cd {modelpaths.model}\n",
        "    download(model_link, model_name, modelpaths.model)\n",
        "elif _model_type == \"ControlNet\":\n",
        "    %cd {modelpaths.controlnet}\n",
        "    download(model_link, model_name, modelpaths.controlnet)\n",
        "elif _model_type == \"VAE\":\n",
        "    %cd {modelpaths.controlnet}\n",
        "    download(model_link, model_name, modelpaths.vae)\n",
        "elif _model_type == \"None\":\n",
        "    %cd /content/\n",
        "    download(model_link, model_name, '/content')"
      ],
      "metadata": {
        "id": "kZKaq7b3eKha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaT0MBIsigWV"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JTcoxAqigWW",
        "outputId": "236251cd-c372-43cc-b243-9a1709791a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "05d272|\u001b[1;32mOK\u001b[0m  |   162MiB/s|/content/KMUI/models/checkpoints/waiNSFWIllustrious_v150.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3b275c|\u001b[1;32mOK\u001b[0m  |    88MiB/s|/content/KMUI/models/loras/Hyper-SDXL-8steps-lora.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "# download('https://civitai.com/api/download/models/630522', 'symPonyWorld_v10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/828380', 'prefectPonyXL_v3.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/686204', 'realcartoonXL_v7.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/297740', 'dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1629649', 'fucktastic25DCheckpointPony_v20.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1111838', 'prefectiousXLNSFW_v10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/916744', 'ZavyChromaXL.V10.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1150354', 'iniverseMixSFWNSFW_ponyRealGuofengV50C.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/641087', 'RealCartoon-Realistic_v17.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/798204', 'realvisxlV50_v50LightningBakedvae.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1183839', 'aniversePonyXL_v50.safetensors', modelpaths.model) #SDXL\n",
        "\n",
        "# download('https://civitai.com/api/download/models/1183839', 'aniverse_v50Pruned.safetensors', modelpaths.model) #SD15\n",
        "\n",
        "# download('https://civitai.com/api/download/models/306531', 'hardcoreHentai13_v13Baked.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/253055', 'perfectdeliberate_v5.safetensors', modelpaths.model)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/2001227', 'perfectdeliberate_il.safetensors', modelpaths.model) #SDXL\n",
        "\n",
        "# download('https://civitai.com/api/download/models/2081643', 'prefectIllustriousXL_v3.safetensors', modelpaths.model) #SDXL\n",
        "\n",
        "download('https://civitai.com/api/download/models/2167369', 'waiNSFWIllustrious_v150.safetensors', modelpaths.model) #SDXL\n",
        "\n",
        "# download('https://civitai.com/api/download/models/48949', 'camelliamixNSFW_v11.safetensors', modelpaths.model)\n",
        "# download('https://civitai.com/api/download/models/28569', 'klF8Anime2VAE_klF8Anime2VAE.safetensors', modelpaths.vae)\n",
        "\n",
        "# download('https://civitai.com/api/download/models/51194', 'puffy_realisticV10.safetensors', modelpaths.model)\n",
        "\n",
        "# print(download_from_civitai(9942, 17233)) # AbyssOrangeMix3 (AOM3)\n",
        "\n",
        "# download('https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/VividOrangeMix/VividOrengeMix_Hard.safetensors?download=true', 'VividOrengeMix_Hard.safetensors', modelpaths.model)\n",
        "# download('https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt?download=true', 'orangemix.vae.pt', modelpaths.vae)\n",
        "\n",
        "if model_type == \"SD15\":\n",
        "    download('https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-8steps-lora.safetensors', 'Hyper-SD15-8steps-lora.safetensors', modelpaths.lora)\n",
        "elif model_type == \"SDXL\":\n",
        "    download('https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-8steps-lora.safetensors', 'Hyper-SDXL-8steps-lora.safetensors', modelpaths.lora)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUabsHbSTKF6"
      },
      "source": [
        "## LoRa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU43pGOkO8A3"
      },
      "outputs": [],
      "source": [
        "lora_list = []\n",
        "\n",
        "if model_type == \"SD15\":\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/122580', 'Skin-Hands.safetensors']) # Skin & Hands (male/female) from Polyhedron\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/117151', 'LEOSAMClothingAdjuster.safetensors']) # LEOSAM's Clothing +/- Adjuster LoRA\n",
        "    # lora_list.append(['https://huggingface.co/naonovn/Lora/resolve/main/add_detail.safetensors','add_detail.safetensors']) # add_detail LoRA\n",
        "\n",
        "    # 3D rendering style (SD 1.5)\n",
        "    # https://civitai.com/models/73756  Trigger Words: 3DMM\n",
        "    # The larger the version number, the more mature and realistic the rendering style will be.\n",
        "    lora_list.append(['https://civitai.com/api/download/models/107366','3DMM_V12.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78467','3DMM_V10.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/88206','3DMM_V7.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78559','3DMM_V5.safetensors'])\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/78564','3DMM_V3.safetensors'])\n",
        "\n",
        "    # Add More Details - Detail Enhancer / Tweaker\n",
        "    # https://civitai.com/models/82098/add-more-details-detail-enhancer-tweaker-lora\n",
        "    lora_list.append(['https://civitai.com/api/download/models/87153','AddMoreDetails-v1.safetensors'])\n",
        "\n",
        "    # sharpen/soften effect\n",
        "    # https://civitai.com/models/94543/lora-sharpensoften-effect-lora-model\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/100851?type=Model&format=SafeTensor','sharpen-soften effect-v1.safetensors'])\n",
        "\n",
        "    # S-shape body slider LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/135052/muggle-loras-shape-body-slider\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/148789?type=Model&format=SafeTensor','S-shape body slider-v1.safetensors'])\n",
        "\n",
        "    # Better eyes+face+skin LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/51430?modelVersionId=55905\n",
        "    lora_list.append(['https://civitai.com/api/download/models/55905','BetterEyesFaceSkin-v1.safetensors'])\n",
        "\n",
        "    # Hipoly 3D Model LoRA (SD 1.5)\n",
        "    # https://civitai.com/models/70921/duchaitenniji\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/44566','Hipoly3D-v2.safetensors'])\n",
        "\n",
        "    # cowgirl with hands on knees\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/140297?type=Model&format=SafeTensor','cowgirl_with_hands_on_knees_v1.0.safetensors'])\n",
        "\n",
        "\n",
        "    # POV Squatting Cowgirl LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/10490','PSCowgirl.safetensors'])\n",
        "\n",
        "    # POV Missionary LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/37826','POVMissionary.safetensors'])\n",
        "\n",
        "    # POV Missionary Vaginal + Creampie LoRA LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/183382','MissionaryVaginal-v2.safetensors'])\n",
        "\n",
        "    # Upright straddle sex front view   Trigger Words:(1boy:1.1), sex, (hetero:1.3), sitting, girl on top, (straddling, upright straddle, vaginal, penis), pussy, pussy juice, leg lock, from behind, hug\n",
        "    lora_list.append(['https://civitai.com/api/download/models/191103','upright_front_above_50.safetensors'])\n",
        "\n",
        "    # Upright straddle sex - standard side view\n",
        "    lora_list.append(['https://civitai.com/api/download/models/109425','upright_straddle_20.safetensors'])\n",
        "\n",
        "    # Doggystyle (Side View)\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/34020','EkuneSideDoggy.safetensors'])\n",
        "\n",
        "    # yuzuriha (enhance related to SEX)\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/269824','yuzuriha_blush_face.safetensors'])\n",
        "\n",
        "    # colorfulhair2 LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/97974?type=Model&format=SafeTensor', 'asb-CH2.safetensors'])\n",
        "\n",
        "    # Half Color Hair LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/45686','hlfcol.safetensors'])\n",
        "\n",
        "    # color hair LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/113573?type=Model&format=SafeTensor','color-hair.safetensors'])\n",
        "elif model_type == \"SDXL\":\n",
        "    # Samaritan 3d Cartoon SDXL\n",
        "    # https://civitai.com/models/121932/samaritan-3d-cartoon-sdxl\n",
        "    # the default face is grumpy/angry for some reason. But this model was trained on variety of emotions,\n",
        "    # try \"smiling, laugh,sad, crying, shouting, surprised, etc\" in the prompt\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/132727','Samaritan-3d-Cartoon-xl.safetensors'])\n",
        "\n",
        "    # xl-water-dress\n",
        "    # https://civitai.com/models/156447/xl-water-dress\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/175608','xl-water-dress.safetensors'])\n",
        "\n",
        "    # xl_more_art-full\n",
        "    # https://civitai.com/models/124347/xlmoreart-full-xlreal-enhancer?modelVersionId=152309\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/152309','xl_more_art-full-v1.safetensors'])\n",
        "\n",
        "    # Penetration Depth Slider - Pony/SDXL\n",
        "    # https://civitai.com/models/485121?modelVersionId=539502\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/539502','Insertion_Slider_alpha1.safetensors'])\n",
        "\n",
        "    # NSFW POV All In One SDXL\n",
        "    # https://civitai.com/models/144203?modelVersionId=160240\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/160240?','NsfwPovAllInOneLoraSdxl-000009.safetensors'])\n",
        "\n",
        "    # Breast Size Slider - SDXL\n",
        "    # https://civitai.com/models/481119/breast-size-slider-sdxl\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/535064','BreastSlider_SDXL.safetensors'])\n",
        "\n",
        "    # Detail Tweaker XL\n",
        "    # https://civitai.com/models/122359/detail-tweaker-xl\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/135867','DetailTweaker-XL-V1.safetensors'])\n",
        "\n",
        "    lora_list.append(['https://civitai.com/api/download/models/382152','Expressive_H-000001.safetensors']) # ExpressiveH (Hentai LoRa Style)\n",
        "    lora_list.append(['https://civitai.com/api/download/models/703107','3DMM_XL_V13.safetensors']) # 3D rendering style : keywords:3DMM\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/128461','PerfectEyesXL.safetensors']) # Perfect Eyes XL : keywords:perfecteyes\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/670719','Rendered_Face_Detailer_v1.0.safetensors']) # Rendered Face Detailer SDXL : keywords:7-cgifaces\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/469461','Upright_front_above_2-000012.safetensors']) # Upright straddle sex front view : keywords:1boy, sex, hetero, upright straddle, straddling, girl on top\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/383563','detailed_notrigger.safetensors']) # detailed\n",
        "    lora_list.append(['https://civitai.com/api/download/models/259830','aesthetic.safetensors']) # Aesthetic SDXL : keywords:aesthetic\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1622964','AddMicroDetails_Illustrious_v3.safetensors']) # Add Micro Details - Concept (Illustrious / Pony) : keywords:addmicrodetails\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1640138','Urban_Fusion_IL.safetensors']) # Urban_Fusion_IL : Strength: 0.8\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1615226','CreateConcept_Illustrious_v2.safetensors']) # Create Concept - Concept (Illustrious) : Strength: 0.8 : keywords:createconcept,\n",
        "    lora_list.append(['https://civitai.com/api/download/models/947620','cfg_scale_boost.safetensors']) # Control LoRA Collection : Strength: 0.4\n",
        "    lora_list.append(['https://civitai.com/api/download/models/1268294','Dramatic_Lighting_Slider.safetensors']) # Dramatic Lighting Slider - Illustrious : Strength: 3.5\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/126785','WowifierXL.safetensors']) # WowifierXL LoRA\n",
        "    # lora_list.append(['https://civitai.com/api/download/models/155625','Caricaturized-xl.safetensors']) # SDXL Caricaturized LoRA\n",
        "\n",
        "    # https://civitai.com/models/1625070/face-enhancer-illustrious\n",
        "    lora_list.append(['https://civitai.com/api/download/models/155625','Face_Enhancer_Illustrious.safetensors']) # SDXL Face Enhancer Illustrious:\n",
        "\n",
        "    # https://civitai.com/models/1890241/female-dominant-assertive-female-female-takes-initiative?modelVersionId=2139556\n",
        "    lora_list.append(['https://civitai.com/api/download/models/2139556','female-dominant_V1.safetensors']) # female-dominant | Illustrious: keywords: female-dominant_V1\n",
        "\n",
        "    # https://civitai.com/models/1731594/eye-enhancer\n",
        "    lora_list.append(['https://civitai.com/api/download/models/128461','Eye_Enhancer.safetensors']) # Eye Enhancer : keywords:detailed eyes,anime eyes,high detail eyes,multicolored iris,detailed iris,\n",
        "\n",
        "elif model_type == \"Flux. 1 dev\":\n",
        "    lora_list.append(['https://civitai.com/api/download/models/996543','vaginalsexlora.safetensors'])\n",
        "    lora_list.append(['https://civitai.com/api/download/models/746602','NSFW_master.safetensors'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qf_1-GCqcVt"
      },
      "source": [
        "# Run KMUI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setting\n",
        "\n",
        "#@markdown # UI\n",
        "#@markdown extensions (custom node)\n",
        "ReactorNode = False #@param {type:'boolean'}\n",
        "ControlnetAux = False #@param {type:'boolean'}\n",
        "#@markdown download\n",
        "DownloadEmbeddings = False #@param {type:'boolean'}\n",
        "DownloadLoRa = True #@param {type:'boolean'}\n",
        "DownloadVAE = False #@param {type:'boolean'}\n",
        "Clip_Vision_g = False #@param {type:'boolean'}"
      ],
      "metadata": {
        "id": "IzWiMDvTKPqO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_dX9-EbDiXA",
        "cellView": "form",
        "outputId": "fd733d1d-1a99-4f87-a2e4-50f1ddb92bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '{lora_path}'\n",
            "/content/KMUI\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "61b78b|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/Expressive_H-000001.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "b9a1e7|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/3DMM_XL_V13.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "c114a2|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/aesthetic.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "7c7d5f|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/AddMicroDetails_Illustrious_v3.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "f7d321|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/Urban_Fusion_IL.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2a2cab|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/CreateConcept_Illustrious_v2.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "b6cfb0|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/cfg_scale_boost.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "ba2f54|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/Dramatic_Lighting_Slider.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "84ef59|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/Face_Enhancer_Illustrious.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "d06025|\u001b[1;32mOK\u001b[0m  |   181MiB/s|/content/KMUI/models/loras/female-dominant_V1.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "41840c|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/KMUI/models/loras/Eye_Enhancer.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "#@title Download models\n",
        "if DownloadEmbeddings:\n",
        "    !wget -q 'https://huggingface.co/nolanaatama/colab/resolve/main/embeddings.zip' -P /content/{gn()}/models/embeddings/\n",
        "    with zipfile.ZipFile(f\"/content/{gn()}/models/embeddings/embeddings.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(f'/content/{gn()}/models')\n",
        "    os.remove(f\"/content/{gn()}/models/embeddings/embeddings.zip\")\n",
        "\n",
        "if DownloadLoRa:\n",
        "    %cd {lora_path}\n",
        "    for item in lora_list:\n",
        "      download(item[0], item[1], modelpaths.lora)\n",
        "\n",
        "if DownloadVAE:\n",
        "    download('https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt', 'vae-ft-mse-840000-ema-pruned.ckpt', modelpaths.vae)\n",
        "\n",
        "# if ReactorNode:\n",
        "#     download(\"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\", 'GFPGANv1.4.pth', f'{modelpaths.base_path}/facerestore_models')\n",
        "#     download(\"https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\", 'inswapper_128.onnx', f'{modelpaths.base_path}/insightface')\n",
        "\n",
        "# clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rld0qAZAfPg0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prepare workflow\n",
        "\n",
        "%cd /content\n",
        "!apt -y update -qq\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "# !pip install -q mediapipe==0.9.1.0 addict yapf fvcore omegaconf\n",
        "\n",
        "!git clone https://github.com/comfyanonymous/{gn()}\n",
        "!git clone -b totoro4 https://github.com/camenduru/{gn()} /content/TotoroUI\n",
        "if not os.path.exists('/content/TotoroUI/custom_nodes'):\n",
        "    os.makedirs('/content/TotoroUI/custom_nodes')\n",
        "\n",
        "%cd /content/TotoroUI/custom_nodes\n",
        "!git clone https://github.com/city96/ComfyUi-GGUF ComfyUi_GGUF\n",
        "moveTree(f'/content/TotoroUI/custom_nodes/ComfyUi_GGUF', f'/content/TotoroUI/custom_nodes/totoro_GGUF', target_word='Comfy', new_word='totoro')\n",
        "\n",
        "%cd /content/{gn()}/custom_nodes\n",
        "!git clone https://github.com/city96/{gn()}-GGUF {gn()[:-2]}_GGUF\n",
        "\n",
        "if ControlnetAux:\n",
        "    !git clone https://github.com/Fannovel16{gn()}_controlnet_aux/\n",
        "\n",
        "if ReactorNode:\n",
        "    !git clone https://github.com/Gourieff/{gn()}-reactor-node {gn()[:-2]}_reactor_node\n",
        "\n",
        "moveTree(f'/content/{gn()}', f'/content/{gnn}')\n",
        "shutil.rmtree(f'/content/{gn()}')\n",
        "\n",
        "# install requirements\n",
        "%cd /content/{gnn}\n",
        "# C_omfy\n",
        "!pip install torch torchsde torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu128\n",
        "!pip install -r requirements.txt #--extra-index-url https://download.pytorch.org/whl/cu122\n",
        "!pip install tokenizers==0.21\n",
        "!pip install av\n",
        "# !pip install torchsde\n",
        "# !pip install spandrel\n",
        "\n",
        "%cd /content/{gnn}/custom_nodes\n",
        "\n",
        "!pip install -r {gnn}_GGUF/requirements.txt\n",
        "\n",
        "# reactor-node\n",
        "if ReactorNode:\n",
        "    !pip install -r {gnn}_reactor_node/requirements.txt\n",
        "    !python {gnn}_reactor_node/install.py\n",
        "\n",
        "\n",
        "# controlnet_aux\n",
        "if ControlnetAux:\n",
        "    !pip install -r {gnn}_controlnet_aux/requirements.txt\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb8G2WauywJu"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-6yNrqCkO0i"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# shutil.move('/content/KMUI-1/output', '/content/KMUI')\n",
        "# shutil.move('/content/KMUI/models', '/content/models')\n",
        "# shutil.move('/content/KMUI/models', '/content/TotoroUI/models')\n",
        "# shutil.rmtree('/content/KMUI-1')\n",
        "shutil.rmtree('/content/drive/MyDrive/AI/KHidden.mail_Generated/2025-05-18')\n",
        "# shutil.rmtree('/content/drive')\n",
        "os.mkdir('/content/drive/MyDrive/AI/KHidden.mail_Generated/2025-05-18')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  from google.colab import drive\n",
        "\n",
        "  print(\"Mounting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "#   drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "4koCPO-rFglK",
        "outputId": "cb7186f9-b6d2-4292-da52-026a91f63ac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting to Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ai Model for generate prompt\n",
        "Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF"
      ],
      "metadata": {
        "id": "u6v6g3pXAjMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi\n",
        "# !pip install crewai\n",
        "# !pip install numpy==1.24.4\n",
        "!pip install llama-cpp-python==v0.2.90 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "# !pip install llama-cpp-python==v0.3.0 --upgrade --force-reinstall --no-cache-dir --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "\n",
        "# from huggingface_hub import login\n",
        "# login(token='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')  # Replace with your actual token\n",
        "\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/prompt_style_positive.txt?download=true', 'prompt_style_positive.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/prompt_style.txt?download=true', 'prompt_style.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/lora.txt?download=true', 'lora.txt', '/content')\n",
        "download('https://huggingface.co/spaces/kamran-r123/SD-Prompt-Generator/resolve/main/lora_prompt.txt?download=true', 'lora_prompt.txt', '/content')\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Hnx8jVY6ChsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "class PromptGenerator:\n",
        "    chat_history = []\n",
        "\n",
        "    class Item:\n",
        "        prompt: str\n",
        "        temperature: float = 1.2\n",
        "        max_new_tokens: int = 1024\n",
        "        seed : int = 43\n",
        "\n",
        "    def __init__(self, n_ctx, lora_list, basemodel):\n",
        "        self.system_prompt = read_file('/content/prompt_style_positive.txt')\n",
        "        self.system_lora_prompt = read_file('/content/lora_prompt.txt')\n",
        "        self.lora_list = self._get_lora_list(lora_list, basemodel) if basemodel else []\n",
        "        self.len_chat_history = 0\n",
        "        self.chat_history = []\n",
        "\n",
        "        # model_id = \"failspy/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF\"\n",
        "        # filename=\"*-v3_q6.gguf\"\n",
        "        model_id = \"mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF\"\n",
        "        # filename=\"*Q6_K.gguf\"\n",
        "        filename=\"*Q8_0.gguf\"\n",
        "        model_id = \"mlabonne/Hermes-3-Llama-3.1-8B-lorablated-GGUF\"\n",
        "        self.model = Llama.from_pretrained(repo_id=model_id, filename=filename, n_gpu_layers=-1, n_ctx=n_ctx, verbose=False)\n",
        "\n",
        "    def _get_lora_list(self, l_list, basemodel):\n",
        "        lora_list = []\n",
        "        for it in l_list:\n",
        "            if it[\"baseModel\"] == basemodel:\n",
        "                item = {\n",
        "                    \"id\": it[\"id\"],\n",
        "                    \"name\": it[\"name\"],\n",
        "                    \"tags\": it[\"tags\"],\n",
        "                    \"weights\": it[\"weights\"]\n",
        "                }\n",
        "                try:\n",
        "                    item[\"trainedWords\"] = it[\"trainedWords\"]\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                lora_list.append(item)\n",
        "        return json.dumps(lora_list)\n",
        "\n",
        "\n",
        "    def list_json_extractor_from_text(self, text):\n",
        "        text = text.replace(\" '\", ' \"').replace(\"' \", '\" ').replace(\"{'\", '{\"').replace(\"'}\", '\"}').replace(\"':\", '\":')\n",
        "        text = text.replace(\"',\", '\",')\n",
        "        start_index = text.find('[')\n",
        "        end_index = text.rfind(']')\n",
        "        if end_index == -1:  # If no closing '}' is found\n",
        "            text += '\"]'  # Add missing closing brace\n",
        "            end_index = len(text)   # Set end_index to the new last character\n",
        "\n",
        "        # Step 3: Extract the JSON part from the start index to the end index\n",
        "        json_string = text[start_index:end_index + 1].strip()\n",
        "\n",
        "        try:\n",
        "            # Parse the JSON string\n",
        "            return json.loads(json_string)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"error in json_extractor_from_text: {e}, try another way\")\n",
        "            pattern = re.compile(r'\\{\"id\":\\s*(\\d+),\\s*\"weights\":\\s*([0-9.]+)\\}')\n",
        "            matches = pattern.findall(json_string)\n",
        "\n",
        "            # Convert matches to list of dictionaries\n",
        "            valid_items = [{\"id\": int(match[0]), \"weights\": float(match[1])} for match in matches]\n",
        "            return valid_items if len(valid_items) > 0 else None\n",
        "\n",
        "    def truncate_list_and_append(self, new_string):\n",
        "        \"\"\"Truncate strings in the list such that their total length does not exceed 4096 characters,\n",
        "        and append `new_string` to the list while removing the first element if necessary.\n",
        "        \"\"\"\n",
        "        ln = len(''.join(new_string))\n",
        "        max_sum = 1024 * 4\n",
        "        if len(self.chat_history) == 0:\n",
        "            self.len_chat_history = ln\n",
        "            self.chat_history.append(new_string)\n",
        "            return\n",
        "        if ln > max_sum:\n",
        "            self.len_chat_history = ln\n",
        "            self.chat_history.clear()\n",
        "            self.chat_history.append(new_string)\n",
        "            return\n",
        "\n",
        "        while len(self.chat_history) > 0 and ln + self.len_chat_history > max_sum:\n",
        "            self.len_chat_history -= len(''.join(self.chat_history.pop(1)))\n",
        "            print('removing from chat_history!')\n",
        "        self.chat_history.append(new_string)\n",
        "        self.len_chat_history += ln\n",
        "\n",
        "    def free_memory(self):\n",
        "        self.model.reset()\n",
        "        self.model.set_cache(None)\n",
        "        del self.model\n",
        "        self.model = None\n",
        "\n",
        "    def format_prompt(self, item: Item, system_prompt, chat_history):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "        ]\n",
        "        for it in chat_history:\n",
        "            messages.append({\"role\" : \"user\", \"content\": it[0]})\n",
        "            messages.append({\"role\" : \"assistant\", \"content\": it[1]})\n",
        "        messages.append({\"role\" : \"user\", \"content\": item.prompt})\n",
        "        return messages\n",
        "\n",
        "    def generate_prompt(self, prompt, seed=4, use_system_prompt=True):\n",
        "        item = PromptGenerator.Item()\n",
        "        item.seed=seed\n",
        "        item.prompt = prompt\n",
        "\n",
        "        formatted_prompt = self.format_prompt(item, self.system_prompt if use_system_prompt else 'You are prompt creator', self.chat_history)\n",
        "        output = self.model.create_chat_completion(messages=formatted_prompt, seed=item.seed, temperature=item.temperature,\n",
        "                                              max_tokens=item.max_new_tokens)\n",
        "\n",
        "\n",
        "        answer = output['choices'][0]['message']['content']\n",
        "        if answer:\n",
        "            self.truncate_list_and_append([str(item.prompt), str(answer)])\n",
        "        return answer, output\n",
        "\n",
        "    def generate_lora_list(self, prompt, seed=4):\n",
        "        if len(self.lora_list) ==0:\n",
        "            print('no base model provided !!!')\n",
        "            return None\n",
        "\n",
        "        item = PromptGenerator.Item()\n",
        "        item.seed=seed\n",
        "        item.prompt = prompt\n",
        "\n",
        "        chat_history = [\n",
        "            ['Please provide me a list of loras', str(self.lora_list)],\n",
        "            ['Please go ahead and give me the prompt in the specified JSON format.', str(json.dumps(prompt))],\n",
        "        ]\n",
        "        formatted_prompt = self.format_prompt(item, self.system_lora_prompt, chat_history)\n",
        "        output = self.model.create_chat_completion(messages=formatted_prompt, seed=item.seed, temperature=item.temperature,\n",
        "                                              max_tokens=item.max_new_tokens)\n",
        "\n",
        "\n",
        "        out = output['choices'][0]['message']['content']\n",
        "        answer = self.list_json_extractor_from_text(str(out))\n",
        "        return answer, out\n",
        "\n",
        "    def clear_history(self):\n",
        "        self.chat_history.clear()\n",
        "\n",
        "TEST_AI = True\n",
        "if TEST_AI:\n",
        "    try:\n",
        "        if promptGenerator:\n",
        "            promptGenerator.free_memory()\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    # lora_list = json.loads(read_file('/content/lora.txt'))\n",
        "    # promptGenerator = PromptGenerator(lora_list, basemodel='SDXL 1.0')\n",
        "\n",
        "    print('Start loading Prompt Generator Ai')\n",
        "    t1 = time.time()\n",
        "\n",
        "    base_model = None\n",
        "    if model_type == \"SDXL\":\n",
        "        base_model = 'SDXL 1.0'\n",
        "    elif model_type == \"SD15\":\n",
        "        base_model = 'SD 1.5'\n",
        "\n",
        "    n_ctx = 4 * 1024\n",
        "    promptGenerator = PromptGenerator(n_ctx=n_ctx, lora_list=None, basemodel=None)\n",
        "    print(f'Prompt Generator Ai loaded in {str(round(time.time() - t1, 1))} second.')"
      ],
      "metadata": {
        "id": "_oSVT4RRAtxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mass Prompt Generator"
      ],
      "metadata": {
        "id": "StghNPhX1mbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### definition class"
      ],
      "metadata": {
        "id": "0lUh9isl1yEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Callable, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "class AIPromptGenerator:\n",
        "    def __init__(self, generate_prompt_fn: Callable):\n",
        "        \"\"\"\n",
        "        Initialize the prompt generator with a function to access local AI.\n",
        "\n",
        "        Args:\n",
        "            generate_prompt_fn: Function that takes (prompt, seed) and returns AI-generated prompt\n",
        "        \"\"\"\n",
        "        self.generate_prompt_fn = generate_prompt_fn\n",
        "        # Expanded keyword sets with weights, incorporating keywords from provided documents\n",
        "        # Improvements: Split large categories like 'sexual' into sub-categories for better granularity:\n",
        "        # - 'nudity': Keywords related to exposure and nakedness.\n",
        "        # - 'sex_acts': Keywords for specific sexual positions and actions.\n",
        "        # - 'bodily_effects': Keywords for fluids, orgasms, and physical reactions.\n",
        "        # - 'sexual_descriptors': General sensual/sexual terms.\n",
        "        # Split 'quality' into 'base_quality' (fixed multi-select for terms like 'masterpiece, highest quality')\n",
        "        # and 'enhanced_quality' (random single select for additional qualifiers).\n",
        "        # Added 'base_quality' as a new category that always selects multiple fixed terms.\n",
        "        # Normalized weights across all sets.\n",
        "        self.keyword_sets = {\n",
        "            'color': [\n",
        "                (\"red\", 0.05), (\"black\", 0.05), (\"purple\", 0.05), (\"yellow\", 0.05), (\"pink\", 0.05),\n",
        "                (\"green\", 0.05), (\"blue\", 0.05), (\"silver\", 0.05), (\"gold\", 0.05), (\"gray\", 0.05),\n",
        "                (\"white\", 0.05), (\"brown\", 0.05), (\"orange\", 0.05), (\"violet\", 0.05), (\"indigo\", 0.05),\n",
        "                (\"teal\", 0.05), (\"lavender\", 0.05), (\"magenta\", 0.05), (\"cyan\", 0.05), (\"emerald\", 0.05),\n",
        "                (\"vibrant color\", 0.05), (\"muted colors\", 0.05), (\"dim colors\", 0.05), (\"soothing tones\", 0.05)\n",
        "            ],\n",
        "            'hair_style': [\n",
        "                (\"ponytail\", 0.05), (\"messy\", 0.05), (\"bob cut\", 0.05), (\"braid ponytail\", 0.05),\n",
        "                (\"long\", 0.05), (\"short\", 0.05), (\"wavy\", 0.05), (\"straight\", 0.05), (\"curly\", 0.05),\n",
        "                (\"spiky\", 0.05), (\"bun\", 0.05), (\"twin tails\", 0.05), (\"princess curls\", 0.05),\n",
        "                (\"afro\", 0.05), (\"pixie cut\", 0.05), (\"dreadlocks\", 0.05), (\"updo\", 0.05),\n",
        "                (\"side swept\", 0.05), (\"layered\", 0.05), (\"feathered\", 0.05), (\"very short hair\", 0.05),\n",
        "                (\"double ponytails\", 0.05), (\"red hair in a messy bun\", 0.05), (\"Curly perm with shiny long blond hair\", 0.05),\n",
        "                (\"extremely_detailed_glossy_hair\", 0.05), (\"natural_flowing_hair\", 0.05)\n",
        "            ],\n",
        "            'erotic': [\n",
        "                (\"seductive pose\", 0.07), (\"provocative\", 0.07), (\"alluring\", 0.07), (\"suggestive\", 0.07),\n",
        "                (\"cleavage\", 0.07), (\"erotic\", 0.07), (\"spread legs\", 0.07), (\"open legs\", 0.07),\n",
        "                (\"teasing\", 0.07), (\"inviting\", 0.07), (\"sensual gaze\", 0.07), (\"playful tease\", 0.07),\n",
        "                (\"beguiling\", 0.07), (\"enticing\", 0.07), (\"flirtatious\", 0.07), (\"dynamic sexy pose\", 0.07)\n",
        "            ],\n",
        "            'nipples': [\n",
        "                (\"visible nipples\", 0.1), (\"puffy nipples\", 0.1), (\"covered nipples\", 0.1),\n",
        "                (\"hard nipples\", 0.1), (\"nipple slip\", 0.1), (\"perky nipples\", 0.1), (\"erect nipples\", 0.1),\n",
        "                (\"outlined nipples\", 0.1), (\"subtle nipples\", 0.1), (\"outstanding nipples\", 0.1),\n",
        "                (\"nipple piercing\", 0.1)\n",
        "            ],\n",
        "            'nudity': [  # Split from 'sexual'\n",
        "                (\"nude\", 0.1), (\"half nude\", 0.1), (\"bare breasts\", 0.1), (\"exposed\", 0.1),\n",
        "                (\"genitals visible\", 0.1), (\"topless\", 0.1), (\"bottomless\", 0.1), (\"sheer nudity\", 0.1),\n",
        "                (\"naked\", 0.1), (\"transparency dress\", 0.1)\n",
        "            ],\n",
        "            'sex_acts': [  # Split from 'sexual'\n",
        "                (\"doggy style\", 0.05), (\"butterfly sex\", 0.05), (\"reversecowgirl\", 0.05), (\"reverse gang bang\", 0.05),\n",
        "                (\"self stroking\", 0.05), (\"riding cowgirl\", 0.05), (\"undressing\", 0.05), (\"sidefuck\", 0.1),\n",
        "                (\"penis penetration\", 0.05), (\"sexual intercourse\", 0.05), (\"Doggystyle sex\", 0.05),\n",
        "                (\"Doggystyle position\", 0.05), (\"getting fucked\", 0.05), (\"vaginal penetration\", 0.1),\n",
        "                (\"hard vaginal sex\", 0.05), (\"oral penetrated\", 0.05), (\"deep throath\", 0.05),\n",
        "                (\"double penetrating\", 0.05), (\"harcore sex\", 0.05), (\"sex from behind\", 0.05),\n",
        "                (\"pussy penetration\", 0.1), (\"vaginal insertion\", 0.1), (\"missionary sex position\", 0.05),\n",
        "                (\"thigh sex\", 0.05), (\"grinding\", 0.05), (\"girl on top\", 0.05), (\"breast grab\", 0.05),\n",
        "                (\"Reverse Cowgirl\", 0.05), (\"man grabbing girl's 1 breast\", 0.1), (\"huge dick\", 0.05),\n",
        "                (\"dick deep in vagina\", 0.1), (\"grab her ass\", 0.05), (\"rape\", 0.1)\n",
        "            ],\n",
        "            'bodily_effects': [  # Split from 'sexual'\n",
        "                (\"cum\", 0.1), (\"cumshot\", 0.1), (\"cum dripping\", 0.1), (\"squirting girl\", 0.1),\n",
        "                (\"massive squirting\", 0.2), (\"cum leaking from pussy\", 0.1), (\"pussy dripping cum\", 0.1),\n",
        "                (\"penis dripping cum\", 0.1), (\"having an orgasm\", 0.1), (\"orgasm\", 0.1),\n",
        "                (\"facial orgasm\", 0.1), (\"edge orgasm\", 0.2), (\"wet pussy\", 0.1), (\"oiled skin\", 0.1),\n",
        "                (\"wet skin\", 0.1), (\"wet shiny skin\", 0.1), (\"soaking wet\", 0.1), (\"screem\", 0.2),\n",
        "                (\"pleasure\", 0.2), (\"bouncing breasts\", 0.1), (\"cum pussy\", 0.1)\n",
        "            ],\n",
        "            'sexual_descriptors': [  # Split from 'sexual'\n",
        "                (\"NSFW\", 0.05), (\"sensual\", 0.05), (\"sexy\", 0.05), (\"pussy\", 0.05), (\"perfect pussy\", 0.05),\n",
        "                (\"hairless pussy\", 0.05), (\"ready to fuck\", 0.05), (\"dick\", 0.05), (\"thick veiny penis\", 0.05),\n",
        "                (\"hetero\", 0.05), (\"pained expression\", 0.05), (\"trembling\", 0.05), (\"breasts pressed\", 0.1),\n",
        "                (\"Penis between thighs\", 0.05), (\"leaning back\", 0.05), (\"worried look\", 0.05),\n",
        "                (\"shocked look\", 0.05), (\"struggling\", 0.05), (\"blush\", 0.05), (\"glossy lips\", 0.05),\n",
        "                (\"nose piercing\", 0.05), (\"teardrop breast\", 0.05), (\"skindentation\", 0.05),\n",
        "                (\"limp body\", 0.05), (\"tears\", 0.05), (\"tearing up\", 0.05), (\"eyes rolled back\", 0.05),\n",
        "                (\"moaning\", 0.1), (\"girl facing viewer\", 0.05), (\"gymnast body\", 0.05)\n",
        "            ],\n",
        "            'sensual': [\n",
        "                (\"pleasure\", 0.1), (\"ecstasy\", 0.1), (\"arousal\", 0.1), (\"desire\", 0.1),\n",
        "                (\"lust\", 0.1), (\"moaning\", 0.2), (\"heavy breathing\", 0.1), (\"bliss\", 0.1),\n",
        "                (\"whimpering\", 0.1), (\"squirming\", 0.1), (\"shivering\", 0.1), (\"trembling\", 0.1)\n",
        "            ],\n",
        "            'sex_position': [\n",
        "                (\"missionary position\", 0.05), (\"cowgirl position\", 0.05), (\"doggy style position\", 0.05), (\"spooning sex position\", 0.05),\n",
        "                (\"reverse cowgirl\", 0.05), (\"lotus sex position\", 0.05), (\"standing sex position\", 0.05), (\"69 sex position\", 0.05),\n",
        "                (\"against wall sex position\", 0.05), (\"butterfly sex position\", 0.05), (\"scissors sex position\", 0.05), (\"face sitting sex position\", 0.05),\n",
        "                (\"Anvil sex position\", 0.05), (\"Flatiron sex position\", 0.05), (\"Corkscrew sex position\", 0.05), (\"Leapfrog sex position\", 0.05),\n",
        "                (\"Taking a knee sex position\", 0.05), (\"lying on the back sex position\", 0.05)\n",
        "            ],\n",
        "            'action': [\n",
        "                (\"kissing\", 0.05), (\"fondling\", 0.05), (\"licking\", 0.05), (\"stroking\", 0.05),\n",
        "                (\"grinding\", 0.05), (\"embracing\", 0.05), (\"thrusting\", 0.05), (\"biting\", 0.05),\n",
        "                (\"touching self\", 0.05), (\"fucking\", 0.05), (\"inserting\", 0.05), (\"sucking\", 0.05),\n",
        "                (\"rubbing\", 0.05), (\"caressing\", 0.05), (\"nibbling\", 0.05), (\"spanking\", 0.05),\n",
        "                (\"kneeling\", 0.05), (\"rape\", 0.05)\n",
        "            ],\n",
        "            'pose': [\n",
        "                # Standing Poses\n",
        "                (\"standing straight\", 0.03), (\"relaxed standing\", 0.03), (\"arms crossed\", 0.03),\n",
        "                (\"hands in pockets\", 0.03), (\"leaning against a wall\", 0.03), (\"hands on hips\", 0.03),\n",
        "                (\"hands above head\", 0.03), (\"bending forward\", 0.03), (\"standing on one leg\", 0.03),\n",
        "                # Sitting Poses\n",
        "                (\"sitting on a chair\", 0.03), (\"sitting cross-legged\", 0.03), (\"sitting on knees\", 0.03),\n",
        "                (\"slouched on a chair\", 0.03), (\"sitting on the edge of a chair\", 0.03),\n",
        "                (\"sitting with knees to the side\", 0.03), (\"sitting with legs stretched\", 0.03),\n",
        "                (\"sitting with legs crossed\", 0.03), (\"sitting hugging knees\", 0.03), (\"sitting lotus\", 0.03),\n",
        "                # Lying Poses\n",
        "                (\"lying on the back\", 0.03), (\"lying on the stomach\", 0.03), (\"lying on the side\", 0.03),\n",
        "                (\"curled up\", 0.03), (\"reclining\", 0.03), (\"sprawled out\", 0.03), (\"propped on elbows\", 0.03),\n",
        "                # Action/Movement Poses\n",
        "                (\"walking\", 0.03), (\"running\", 0.03), (\"jumping\", 0.03), (\"pulling something\", 0.03),\n",
        "                (\"pushing something\", 0.03), (\"climbing\", 0.03), (\"falling\", 0.03), (\"dancing\", 0.03),\n",
        "                (\"twirling\", 0.03), (\"spinning\", 0.03),\n",
        "                # Hand & Body Gestures\n",
        "                (\"arms raised\", 0.03), (\"hands on face\", 0.03), (\"on all fours\", 0.03), (\"hugging knees\", 0.03),\n",
        "                (\"pointing\", 0.03), (\"hands clasped together\", 0.03), (\"waving\", 0.03),\n",
        "                (\"thumbs up\", 0.03), (\"clapping\", 0.03), (\"fist pump\", 0.03),\n",
        "                # Emotional/Expressive Poses\n",
        "                (\"bent over with hands on knees\", 0.03), (\"kneeling on the ground\", 0.03),\n",
        "                (\"leaning to the side\", 0.03), (\"balancing\", 0.03), (\"fighting stance\", 0.03),\n",
        "                (\"praying hands\", 0.03), (\"covering mouth\", 0.03), (\"head tilt\", 0.03),\n",
        "                (\"sitting on bed\", 0.03), (\"All-fours\", 0.03), (\"Taking a knee\", 0.03), (\"lying on the back\", 0.03),\n",
        "                (\"point toward you\", 0.03), (\"knee bent\", 0.03)\n",
        "            ],\n",
        "            'body': [\n",
        "                (\"curvy\", 0.05), (\"voluptuous\", 0.05), (\"athletic\", 0.05), (\"petite\", 0.05),\n",
        "                (\"slim\", 0.05), (\"hourglass figure\", 0.05), (\"muscular\", 0.05), (\"chubby\", 0.05),\n",
        "                (\"toned\", 0.05), (\"slender\", 0.05), (\"busty\", 0.05), (\"plump\", 0.05),\n",
        "                (\"fit\", 0.05), (\"lean\", 0.05), (\"full body\", 0.05), (\"skinny\", 0.05),\n",
        "                (\"perky breasts\", 0.05), (\"perfect legs\", 0.05), (\"perfect breasts\", 0.05),\n",
        "                (\"broad shoulders\", 0.05), (\"Small breast\", 0.05), (\"small breast\", 0.05),\n",
        "                (\"perfect perky breasts\", 0.05), (\"Her skin is flawless\", 0.05), (\"white pale skin\", 0.05),\n",
        "                (\"Pale skin\", 0.05), (\"natrual skin textures\", 0.05)\n",
        "            ],\n",
        "            'dress': [\n",
        "                (\"lingerie\", 0.04), (\"bikini\", 0.04), (\"maid outfit\", 0.04), (\"school uniform\", 0.04),\n",
        "                (\"kimono\", 0.04), (\"stockings\", 0.04), (\"leotard\", 0.04), (\"transparent clothes\", 0.04),\n",
        "                (\"naked\", 0.04), (\"half naked\", 0.04), (\"ripped clothes\", 0.04), (\"panties\", 0.04),\n",
        "                (\"corset\", 0.04), (\"gown\", 0.04), (\"swimsuit\", 0.04), (\"yukata\", 0.04),\n",
        "                (\"fishnet\", 0.04), (\"thong\", 0.04), (\"topless dress\", 0.04), (\"bare shoulder\", 0.04),\n",
        "                (\"wearing a crop top\", 0.04), (\"no bra\", 0.04), (\"mini skirt\", 0.04),\n",
        "                (\"tight spandex shirt\", 0.04), (\"leggings\", 0.04), (\"blue loose-fitting\", 0.04),\n",
        "                (\"off-the-shoulder blouse\", 0.04), (\"skinny jeans\", 0.04), (\"underpants\", 0.04),\n",
        "                (\"large neckline solo\", 0.04), (\"transparency dress\", 0.04)\n",
        "            ],\n",
        "            'camera': [\n",
        "                (\"front view\", 0.1), (\"side view\", 0.1), (\"POV\", 0.1), (\"close-up\", 0.1),\n",
        "                (\"medium shot\", 0.1), (\"wide shot\", 0.1), (\"aerial view\", 0.1), (\"over the shoulder\", 0.1),\n",
        "                (\"low angle\", 0.1), (\"high angle\", 0.1), (\"three-quarter view\", 0.1), (\"from side\", 0.1),\n",
        "                (\"dutch angle\", 0.1)\n",
        "            ],\n",
        "            'age': [\n",
        "                (\"young woman\", 0.15), (\"teen\", 0.15), (\"20s\", 0.15), (\"30s\", 0.15), (\"young adult\", 0.15),\n",
        "                (\"mature woman\", 0.1), (\"40s\", 0.1), (\"adolescent\", 0.05), (\"middle-aged\", 0.05), (\"girl\", 0.05),\n",
        "                (\"Adult\", 0.05)\n",
        "            ],\n",
        "            'race': [\n",
        "                (\"human\", 0.1), (\"elf\", 0.1), (\"demon\", 0.1), (\"angel\", 0.1), (\"catgirl\", 0.1),\n",
        "                (\"bunny girl\", 0.1), (\"mermaid\", 0.1), (\"vampire\", 0.1), (\"succubus\", 0.1),\n",
        "                (\"fairy\", 0.1), (\"dragon girl\", 0.1), (\"kitsune\", 0.1), (\"orc\", 0.1),\n",
        "                (\"cyborg\", 0.1), (\"alien\", 0.1), (\"Caucasian\", 0.1), (\"European face\", 0.1),\n",
        "                (\"a beautiful italian model\", 0.1)\n",
        "            ],\n",
        "            'lighting': [\n",
        "                (\"soft light\", 0.03), (\"moonlight\", 0.03), (\"sunlight\", 0.03), (\"candlelight\", 0.03),\n",
        "                (\"neon lights\", 0.03), (\"dim lighting\", 0.03), (\"backlight\", 0.03), (\"rim light\", 0.03),\n",
        "                (\"golden hour\", 0.03), (\"harsh shadows\", 0.03), (\"diffused light\", 0.03),\n",
        "                (\"perfect lighting\", 0.03), (\"Soft lighting\", 0.03), (\"night photography\", 0.03),\n",
        "                (\"nocturnal beauty\", 0.03), (\"city lights\", 0.03), (\"starry skies\", 0.03),\n",
        "                (\"celestial wonders\", 0.03), (\"moonlit landscapes\", 0.03), (\"urban glow\", 0.03),\n",
        "                (\"capturing the essence of darkness\", 0.03), (\"ethereal atmosphere\", 0.03),\n",
        "                (\"dramatic shadows\", 0.03), (\"magical ambiance\", 0.03), (\"long exposure techniques\", 0.03),\n",
        "                (\"expert use of light sources\", 0.03), (\"cinematic lighting\", 0.03), (\"ambient lighting\", 0.03),\n",
        "                (\"sidelighting\", 0.03), (\"Warm tone\", 0.03), (\"Bright and intense\", 0.03), (\"godrays\", 0.03)\n",
        "            ],\n",
        "            'expression': [\n",
        "                (\"seductive\", 0.05), (\"confident\", 0.05), (\"shy\", 0.05), (\"lust\", 0.05),\n",
        "                (\"desire\", 0.05), (\"submissive\", 0.05), (\"embarrassed\", 0.05), (\"smirking\", 0.05),\n",
        "                (\"winking\", 0.05), (\"pouting\", 0.05), (\"grinning\", 0.05), (\"surprised\", 0.05),\n",
        "                (\"ecstatic\", 0.05), (\"angry\", 0.05), (\"half smile\", 0.05), (\"blushing\", 0.05),\n",
        "                (\"friendly smile\", 0.05), (\"serene expression\", 0.05), (\"a look of surprise\", 0.05),\n",
        "                (\"pained expression\", 0.05), (\"worried look\", 0.05), (\"shocked look\", 0.05),\n",
        "                (\"struggling\", 0.05)\n",
        "            ],\n",
        "            'accessories': [\n",
        "                (\"choker\", 0.05), (\"high heels\", 0.05), (\"stockings\", 0.05), (\"gloves\", 0.05),\n",
        "                (\"ribbon\", 0.05), (\"piercings\", 0.05), (\"collar\", 0.05), (\"leash\", 0.05),\n",
        "                (\"earrings\", 0.05), (\"necklace\", 0.05), (\"bracelet\", 0.05), (\"anklet\", 0.05),\n",
        "                (\"tiara\", 0.05), (\"belt\", 0.05), (\"jewellery\", 0.05), (\"handbags\", 0.05),\n",
        "                (\"hats\", 0.05), (\"scarves\", 0.05), (\"watches\", 0.05), (\"sunglasses\", 0.05),\n",
        "                (\"pins\", 0.05), (\"bow ties\", 0.05), (\"leggings\", 0.05), (\"ties\", 0.05),\n",
        "                (\"suspenders\", 0.05), (\"tights\", 0.05), (\"Rayben Sunglasses\", 0.05)\n",
        "            ],\n",
        "            'environment': [\n",
        "                (\"bedroom\", 0.05), (\"beach\", 0.05), (\"forest\", 0.05), (\"shower\", 0.05),\n",
        "                (\"castle\", 0.05), (\"school\", 0.05), (\"dungeon\", 0.05), (\"pool\", 0.05),\n",
        "                (\"hospital\", 0.05), (\"office\", 0.05), (\"mountain\", 0.05), (\"desert\", 0.05),\n",
        "                (\"river\", 0.05), (\"cave\", 0.05), (\"jungle\", 0.05), (\"lake\", 0.05),\n",
        "                (\"kitchen\", 0.05), (\"car\", 0.05), (\"running trail\", 0.05), (\"walking on a trail\", 0.05)\n",
        "            ],\n",
        "            'mood': [\n",
        "                (\"romantic\", 0.1), (\"mysterious\", 0.1), (\"intimate\", 0.1), (\"playful\", 0.1),\n",
        "                (\"dark\", 0.1), (\"dreamy\", 0.1), (\"passionate\", 0.1), (\"eerie\", 0.1),\n",
        "                (\"serene\", 0.1), (\"tense\", 0.1), (\"joyful\", 0.1), (\"melancholic\", 0.1)\n",
        "            ],\n",
        "            'texture': [\n",
        "                (\"silky\", 0.1), (\"velvet\", 0.1), (\"lace\", 0.1), (\"satin\", 0.1),\n",
        "                (\"leather\", 0.1), (\"sheer\", 0.1), (\"soft\", 0.1), (\"furry\", 0.1),\n",
        "                (\"metallic\", 0.1), (\"sequined\", 0.1), (\"knitted\", 0.1), (\"denim\", 0.1),\n",
        "                (\"Exquisite details and textures\", 0.1)\n",
        "            ],\n",
        "            'background_details': [\n",
        "                (\"candles\", 0.1), (\"flowers\", 0.1), (\"mirrors\", 0.1), (\"curtains\", 0.1),\n",
        "                (\"fog\", 0.1), (\"stars\", 0.1), (\"petals\", 0.1), (\"vines\", 0.1),\n",
        "                (\"bookshelves\", 0.1), (\"artwork\", 0.1), (\"fireplace\", 0.1), (\"windows\", 0.1)\n",
        "            ],\n",
        "            'art_style': [\n",
        "                (\"anime\", 0.04), (\"realistic\", 0.04), (\"fantasy art\", 0.04), (\"cyberpunk\", 0.04),\n",
        "                (\"watercolor\", 0.04), (\"oil painting\", 0.04), (\"sketch\", 0.04), (\"3D render\", 0.04),\n",
        "                (\"surreal\", 0.04), (\"pixel art\", 0.04), (\"impressionist\", 0.04), (\"steampunk\", 0.04),\n",
        "                (\"baroque\", 0.04), (\"minimalist\", 0.04), (\"illustration\", 0.04), (\"3d\", 0.04),\n",
        "                (\"cartoon\", 0.04), (\"anime\", 0.04), (\"sketch\", 0.04), (\"black and white\", 0.04),\n",
        "                (\"muscular\", 0.04), (\"monochrome\", 0.04), (\"illustration\", 0.04), (\"sepia\", 0.04),\n",
        "                (\"painting\", 0.04), (\"cartoons\", 0.04), (\"multiple pictures\", 0.04), (\"ultra realistic illustration\", 0.04),\n",
        "                (\"by xm887\", 0.04), (\"Art by [any artist name]\", 0.04)\n",
        "            ],\n",
        "            'time_of_day': [\n",
        "                (\"daytime\", 0.1), (\"night\", 0.1), (\"sunset\", 0.1), (\"dawn\", 0.1),\n",
        "                (\"twilight\", 0.1), (\"midnight\", 0.1), (\"morning\", 0.1), (\"afternoon\", 0.1),\n",
        "                (\"evening\", 0.1), (\"golden hour\", 0.1)\n",
        "            ],\n",
        "            'weather': [\n",
        "                (\"clear sky\", 0.1), (\"rainy\", 0.1), (\"foggy\", 0.1), (\"stormy\", 0.1),\n",
        "                (\"snowy\", 0.1), (\"cloudy\", 0.1), (\"windy\", 0.1), (\"sunny\", 0.1),\n",
        "                (\"overcast\", 0.1), (\"misty\", 0.1), (\"thunderstorm\", 0.1)\n",
        "            ],\n",
        "            'emotion': [\n",
        "                (\"joyful\", 0.1), (\"melancholic\", 0.13), (\"confident\", 0.1), (\"vulnerable\", 0.13),\n",
        "                (\"introspective\", 0.1), (\"playful\", 0.1), (\"mysterious\", 0.3), (\"angry\", 0.07),\n",
        "                (\"serene\", 0.1), (\"anxious\", 0.1), (\"excited\", 0.13), (\"content\", 0.1),\n",
        "                (\"fearful\", 0.1), (\"hopeful\", 0.1)\n",
        "            ],\n",
        "            'props': [\n",
        "                (\"book\", 0.05), (\"mirror\", 0.05), (\"sword\", 0.05), (\"flowers\", 0.05),\n",
        "                (\"wine glass\", 0.05), (\"candle\", 0.05), (\"umbrella\", 0.05), (\"fan\", 0.05),\n",
        "                (\"jewelry box\", 0.05), (\"musical instrument\", 0.05), (\"lantern\", 0.05),\n",
        "                (\"scroll\", 0.05), (\"mask\", 0.05), (\"hat\", 0.05), (\"scarf\", 0.05),\n",
        "                (\"glasses\", 0.1), (\"leather shoes\", 0.05)\n",
        "            ],\n",
        "            'facial_features': [\n",
        "                (\"freckles\", 0.03), (\"sharp cheekbones\", 0.03), (\"soft lips\", 0.03), (\"piercing eyes\", 0.03),\n",
        "                (\"long eyelashes\", 0.03), (\"scar\", 0.03), (\"tattoo on face\", 0.03), (\"blushing cheeks\", 0.03),\n",
        "                (\"dimples\", 0.03), (\"mole\", 0.03), (\"high forehead\", 0.03), (\"arched eyebrows\", 0.03),\n",
        "                (\"full lips\", 0.03), (\"narrow eyes\", 0.03), (\"earrings\", 0.03), (\"forehead\", 0.03),\n",
        "                (\"freckles\", 0.03), (\"hair\", 0.03), (\"jewelry\", 0.03), (\"looking down\", 0.03),\n",
        "                (\"pointy nose\", 0.03), (\"red lips glossy\", 0.03), (\"shadow\", 0.03), (\"thick eyebrows\", 0.03),\n",
        "                (\"thick eyelashes\", 0.03), (\"full lips\", 0.03), (\"big clear eyes\", 0.03), (\"light grey eyes\", 0.03),\n",
        "                (\"blond hair\", 0.03), (\"extremely detailed face\", 0.03), (\"expressive eyes\", 0.03),\n",
        "                (\"perfect face\", 0.03), (\"seductive eyes\", 0.03), (\"symmetric eyes\", 0.03),\n",
        "                (\"blue eyes\", 0.03), (\"glowing eyes\", 0.03), (\"Blonde\", 0.03), (\"large almond-shaped eyes\", 0.03),\n",
        "                (\"mesmerizing blue\", 0.03), (\"dark eyelashes\", 0.03), (\"highly detailed beautiful expressive eyes\", 0.03),\n",
        "                (\"detailed eyes\", 0.03), (\"icy eyeshadow\", 0.03)\n",
        "            ],\n",
        "            'character': [\n",
        "                (\"Priscilla Barielle\", 0.05), (\"Emilia\", 0.05), (\"Mitsuri Kanroji\", 0.05), (\"Hinata Hyuga\", 0.05),\n",
        "                (\"Makima\", 0.05), (\"Darkness from KonoSuba\", 0.05), (\"Hestia\", 0.05), (\"Hayase Nagatoro\", 0.05),\n",
        "                (\"Haruno Sakura\", 0.05), (\"Kohaku\", 0.05), (\"Echidna\", 0.05), (\"Minerva\", 0.05),\n",
        "                (\"Kurumi Tokisaki\", 0.05), (\"Albedo\", 0.05), (\"Chika Fujiwara\", 0.05), (\"Rem\", 0.05),\n",
        "                (\"Ram\", 0.05), (\"Zero Two\", 0.05), (\"Asuna\", 0.05), (\"Mikasa\", 0.05)\n",
        "            ],\n",
        "            'medium': [\n",
        "                (\"illustration\", 0.1), (\"3D rendering\", 0.1), (\"photography\", 0.1),\n",
        "                (\"photorealistic\", 0.1), (\"high definition RAW color photo\", 0.1), (\"photo grain\", 0.1),\n",
        "                (\"Technicolor\", 0.1), (\"Panavision\", 0.1), (\"cinemascope\", 0.1), (\"cinematic shot\", 0.1)\n",
        "            ],\n",
        "            'style': [\n",
        "                (\"impressionist\", 0.1), (\"surrealist\", 0.1), (\"pop art\", 0.1), (\"realism\", 0.1),\n",
        "                (\"realistic\", 0.1), (\"ultra realistic illustration\", 0.1), (\"siena natural ratio\", 0.1)\n",
        "            ],\n",
        "            'resolution': [\n",
        "                (\"highly detailed\", 0.05), (\"sharp focus\", 0.05), (\"highest quality\", 0.05), (\"1024k UHD wallpaper\", 0.05),\n",
        "                (\"ultra-high resolution\", 0.05), (\"best quality\", 0.05), (\"8k\", 0.05), (\"HDR\", 0.05),\n",
        "                (\"fine details\", 0.05), (\"Exquisite details and textures\", 0.05), (\"masterpiece\", 0.05)\n",
        "            ],\n",
        "            'additional_details': [\n",
        "                (\"sci-fi\", 0.1), (\"dystopian\", 0.1), (\"athletic\", 0.1), (\"75mmg\", 0.1),\n",
        "                (\"high contrast\", 0.1), (\"portrait\", 0.1), (\"wide shot\", 0.1), (\"highly detailed hands\", 0.1),\n",
        "                (\"highly detailed fingers\", 0.1), (\"head to thigh portrait\", 0.1), (\"full length\", 0.1),\n",
        "                (\"Top to mid-chest\", 0.1), (\"upper body\", 0.1)\n",
        "            ],\n",
        "            'base_quality': [  # New category for fixed multi-select terms that should be used together\n",
        "                (\"masterpiece\", 1.0), (\"highest quality\", 1.0), (\"best quality\", 1.0)  # Weights don't matter as we select multiple\n",
        "            ],\n",
        "            'enhanced_quality': [  # Split from 'quality' for additional random qualifiers\n",
        "                (\"soft tones\", 0.02), (\"photorealistic\", 0.02), (\"1024k UHD wallpaper\", 0.02),\n",
        "                (\"ultra-high resolution\", 0.02), (\"perfect lighting\", 0.02), (\"athletic\", 0.02),\n",
        "                (\"running trail\", 0.02), (\"high definition RAW color photo\", 0.02), (\"photo grain\", 0.02),\n",
        "                (\"75mmg\", 0.02), (\"Technicolor\", 0.02), (\"Panavision\", 0.02), (\"cinemascope\", 0.02),\n",
        "                (\"sharp focus\", 0.02), (\"fine details\", 0.02), (\"8k\", 0.02), (\"HDR\", 0.02), (\"realism\", 0.02),\n",
        "                (\"realistic\", 0.02), (\"Soft lighting\", 0.02), (\"dutch angle\", 0.02), (\"night photography\", 0.02),\n",
        "                (\"nocturnal beauty\", 0.02), (\"city lights\", 0.02), (\"starry skies\", 0.02), (\"celestial wonders\", 0.02),\n",
        "                (\"moonlit landscapes\", 0.02), (\"urban glow\", 0.02), (\"capturing the essence of darkness\", 0.02),\n",
        "                (\"ethereal atmosphere\", 0.02), (\"dramatic shadows\", 0.02), (\"magical ambiance\", 0.02),\n",
        "                (\"long exposure techniques\", 0.02), (\"expert use of light sources\", 0.02), (\"portrait\", 0.02),\n",
        "                (\"high contrast\", 0.02), (\"vibrant color\", 0.02), (\"muted colors\", 0.02), (\"dim colors\", 0.02),\n",
        "                (\"soothing tones\", 0.02), (\"cinematic lighting\", 0.02), (\"ambient lighting\", 0.02), (\"sidelighting\", 0.02),\n",
        "                (\"Exquisite details and textures\", 0.02), (\"cinematic shot\", 0.02), (\"Warm tone\", 0.02),\n",
        "                (\"Bright and intense\", 0.02), (\"wide shot\", 0.02), (\"by xm887\", 0.02), (\"ultra realistic illustration\", 0.02),\n",
        "                (\"siena natural ratio\", 0.02), (\"godrays\", 0.02), (\"sunlight\", 0.02)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Negative keyword sets from documents (unweighted, as we sample randomly)\n",
        "        self.negative_keyword_sets = {\n",
        "            'general': [\n",
        "                \"low quality\", \"watermark\", \"signature\", \"artist name\", \"twitter username\", \"low detail\",\n",
        "                \"no detail\", \"error\", \"blurry\", \"poor anatomy\", \"worst quality\", \"malformed\", \"cropped\",\n",
        "                \"low resolution\", \"trademark\", \"title\", \"Reference sheet\", \"overexposed\", \"logo\",\n",
        "                \"jpeg artifacts\", \"duplicate\", \"mutilated\", \"out of frame\", \"3d\", \"cartoon\", \"anime\",\n",
        "                \"sketch\", \"black and white\", \"muscular\", \"monochrome\", \"illustration\", \"sepia\", \"painting\",\n",
        "                \"cartoons\", \"multiple pictures\", \"text\", \"humans\", \"SFW\"\n",
        "            ],\n",
        "            'human': [\n",
        "                \"extra hand\", \"extra leg\", \"extra arm\", \"extra head\", \"extra fingers\", \"extra body parts\",\n",
        "                \"bad anatomy\", \"distorted face\", \"extra limbs\", \"gross proportions\", \"malformed limbs\",\n",
        "                \"missing arms\", \"missing legs\", \"mutated hands\", \"fused fingers\", \"too many fingers\",\n",
        "                \"long neck\", \"extra head\", \"cloned head\", \"extra body\", \"cloned body\", \"curvy\", \"plump\",\n",
        "                \"fat\", \"fused bodies\", \"ugly\", \"unnatural hands\", \"unnatural fingers\", \"unnatural legs\",\n",
        "                \"unnatural breart\", \"unnatural eyes\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Normalize all positive keyword sets\n",
        "        for category in self.keyword_sets:\n",
        "            keywords = self.keyword_sets[category]\n",
        "            total_weight = sum(w for _, w in keywords)\n",
        "            if abs(total_weight - 1.0) > 0.01:\n",
        "                keywords = [(k, w / total_weight) for k, w in keywords]\n",
        "            self.keyword_sets[category] = keywords\n",
        "\n",
        "        # Expanded incompatible pairs, incorporating document insights (e.g., avoid mixing SFW/NSFW, human anatomy issues, etc.)\n",
        "        # Improvements: Updated incompatible pairs to account for new split categories (e.g., nudity vs. dress).\n",
        "        self.incompatible_pairs = [\n",
        "            (['naked', 'half naked', 'nude', 'topless', 'bare breasts', 'NSFW', 'transparency dress', 'erotic', 'sensual', 'sexy', 'pussy'],\n",
        "             ['lingerie', 'bikini', 'maid outfit', 'school uniform', 'kimono', 'leotard', 'corset', 'gown', 'swimsuit', 'yukata', 'fishnet', 'thong', 'SFW']),\n",
        "            (['slim', 'athletic', 'petite', 'toned', 'slender', 'fit', 'lean', 'skinny'], ['chubby', 'voluptuous', 'plump', 'busty', 'curvy', 'fat']),\n",
        "            (['shy', 'embarrassed', 'submissive'], ['confident', 'angry']),\n",
        "            (['naked', 'nude', 'NSFW'], ['accessories', 'stockings', 'high heels', 'gloves', 'earrings', 'necklace', 'bracelet', 'anklet', 'tiara', 'belt', 'SFW']),\n",
        "            (['fucking', 'inserting', 'thrusting', 'orgasming', 'orgasm', 'rape'], ['teen', 'adolescent']),\n",
        "            (['missionary', 'cowgirl', 'doggy style', 'reverse cowgirl', 'kissing', 'fondling', 'licking', 'stroking', 'grinding', 'sucking', 'rubbing', 'caressing', 'nibbling'],\n",
        "             ['standing straight', 'relaxed standing', 'arms crossed', 'hands in pockets', 'leaning against a wall',\n",
        "              'hands on hips', 'hands above head', 'standing on one leg', 'walking', 'running', 'jumping']),\n",
        "            (['pleasure', 'ecstasy', 'bliss'], ['pained expression', 'worried look', 'shocked look', 'struggling']),\n",
        "            (['teen', 'adolescent'], ['mature woman', 'middle-aged', '40s']),\n",
        "            (['sitting on a chair', 'sitting cross-legged', 'sitting on knees', 'slouched on a chair',\n",
        "              'sitting on the edge of a chair', 'sitting with knees to the side', 'sitting with legs stretched',\n",
        "              'sitting with legs crossed', 'sitting hugging knees', 'sitting lotus'],\n",
        "             ['lying on the back', 'lying on the stomach', 'lying on the side', 'curled up', 'reclining', 'sprawled out', 'propped on elbows']),\n",
        "            (['lying on the back', 'lying on the stomach', 'lying on the side', 'curled up', 'reclining', 'sprawled out', 'propped on elbows'],\n",
        "             ['walking', 'running', 'jumping', 'climbing', 'fighting stance', 'twirling', 'spinning']),\n",
        "            (['night', 'midnight'], ['sunlight', 'daytime', 'sunny']),\n",
        "            (['daytime', 'sunset', 'dawn'], ['moonlight', 'neon lights', 'night photography']),\n",
        "            (['rainy', 'stormy', 'snowy', 'foggy', 'thunderstorm'], ['bedroom', 'hospital', 'office', 'kitchen', 'car']),\n",
        "            (['joyful', 'playful', 'serene', 'excited', 'content', 'hopeful'], ['melancholic', 'angry', 'anxious', 'fearful']),\n",
        "            (['sword', 'musical instrument', 'lantern', 'scroll', 'mask'], ['naked', 'half naked', 'nude']),\n",
        "            (['book', 'wine glass', 'fan', 'jewelry box', 'umbrella', 'hat', 'scarf', 'glasses'], ['running', 'jumping', 'fighting stance', 'twirling', 'spinning']),\n",
        "            (['muscular', 'muscle man'], ['petite', 'slim', 'skinny']),\n",
        "            (['realistic', 'photorealistic', 'realism'], ['anime', 'cartoon', 'illustration', 'sketch', 'pixel art']),\n",
        "            (['highest quality', 'best quality', 'ultra-high resolution'], ['low quality', 'low resolution', 'blurry'])\n",
        "        ]\n",
        "\n",
        "        self.main_keywords = \"ultra detailed, intricate\"\n",
        "        self.max_prompt_length = 150  # StableDiffusion token limit\n",
        "\n",
        "    def add_keyword_set(self, category: str, keywords: List[Tuple[str, float]]) -> None:\n",
        "        total_weight = sum(weight for _, weight in keywords)\n",
        "        if abs(total_weight - 1.0) > 0.01:\n",
        "            print(f\"Keyword weights for {category} do not sum to 1.0, normalizing...\")\n",
        "            keywords = [(kw, w / total_weight) for kw, w in keywords]\n",
        "\n",
        "        if category in self.keyword_sets:\n",
        "            self.keyword_sets[category].extend(keywords)\n",
        "        else:\n",
        "            self.keyword_sets[category] = keywords\n",
        "        print(f\"Added/updated keyword set for category: {category}\")\n",
        "\n",
        "    def get_random_keyword(self, category: str, exclude: List[str] = None) -> str:\n",
        "        if category not in self.keyword_sets:\n",
        "            print(f\"Category {category} not found\")\n",
        "            return \"\"\n",
        "\n",
        "        keywords = self.keyword_sets[category]\n",
        "        if exclude:\n",
        "            keywords = [(kw, w) for kw, w in keywords if kw not in exclude]\n",
        "        if not keywords:\n",
        "            print(f\"No valid keywords in {category} after exclusions\")\n",
        "            return \"\"\n",
        "\n",
        "        kws, weights = zip(*keywords)\n",
        "        return random.choices(kws, weights=weights, k=1)[0]\n",
        "\n",
        "    def get_multiple_keywords(self, category: str, num: int = 2, exclude: List[str] = None) -> List[str]:\n",
        "        if category not in self.keyword_sets:\n",
        "            print(f\"Category {category} not found\")\n",
        "            return []\n",
        "\n",
        "        keywords = self.keyword_sets[category]\n",
        "        if exclude:\n",
        "            keywords = [(kw, w) for kw, w in keywords if kw not in exclude]\n",
        "        if not keywords:\n",
        "            print(f\"No valid keywords in {category} after exclusions\")\n",
        "            return []\n",
        "\n",
        "        kws, weights = zip(*keywords)\n",
        "        return random.choices(kws, weights=weights, k=num)\n",
        "\n",
        "    def check_compatibility(self, selected_keywords: Dict[str, str]) -> Dict[str, str]:\n",
        "        # Improvement: Limit retries to avoid infinite loops, and handle multi-keyword categories.\n",
        "        for _ in range(10):  # Retry up to 10 times to resolve conflicts\n",
        "            changed = False\n",
        "            for group1, group2 in self.incompatible_pairs:\n",
        "                for cat, kw in list(selected_keywords.items()):\n",
        "                    if isinstance(kw, list):  # Handle multi-keyword\n",
        "                        for single_kw in kw:\n",
        "                            if single_kw in group1:\n",
        "                                for cat2, kw2 in list(selected_keywords.items()):\n",
        "                                    if cat2 != cat:\n",
        "                                        if isinstance(kw2, list):\n",
        "                                            if any(k in group2 for k in kw2):\n",
        "                                                new_kws = self.get_multiple_keywords(cat2, len(kw2), exclude=group2)\n",
        "                                                if new_kws:\n",
        "                                                    selected_keywords[cat2] = new_kws\n",
        "                                                    changed = True\n",
        "                                                    print(f\"Replaced incompatible keywords {kw2} in {cat2} with {new_kws}\")\n",
        "                                        else:\n",
        "                                            if kw2 in group2:\n",
        "                                                new_kw = self.get_random_keyword(cat2, exclude=group2)\n",
        "                                                if new_kw:\n",
        "                                                    selected_keywords[cat2] = new_kw\n",
        "                                                    changed = True\n",
        "                                                    print(f\"Replaced incompatible keyword {kw2} in {cat2} with {new_kw}\")\n",
        "                            elif single_kw in group2:\n",
        "                                # Similar logic for group2\n",
        "                                for cat2, kw2 in list(selected_keywords.items()):\n",
        "                                    if cat2 != cat:\n",
        "                                        if isinstance(kw2, list):\n",
        "                                            if any(k in group1 for k in kw2):\n",
        "                                                new_kws = self.get_multiple_keywords(cat2, len(kw2), exclude=group1)\n",
        "                                                if new_kws:\n",
        "                                                    selected_keywords[cat2] = new_kws\n",
        "                                                    changed = True\n",
        "                                                    print(f\"Replaced incompatible keywords {kw2} in {cat2} with {new_kws}\")\n",
        "                                        else:\n",
        "                                            if kw2 in group1:\n",
        "                                                new_kw = self.get_random_keyword(cat2, exclude=group1)\n",
        "                                                if new_kw:\n",
        "                                                    selected_keywords[cat2] = new_kw\n",
        "                                                    changed = True\n",
        "                                                    print(f\"Replaced incompatible keyword {kw2} in {cat2} with {new_kw}\")\n",
        "                    else:\n",
        "                        if kw in group1:\n",
        "                            for cat2, kw2 in list(selected_keywords.items()):\n",
        "                                if cat2 != cat:\n",
        "                                    if isinstance(kw2, list):\n",
        "                                        if any(k in group2 for k in kw2):\n",
        "                                            new_kws = self.get_multiple_keywords(cat2, len(kw2), exclude=group2)\n",
        "                                            if new_kws:\n",
        "                                                selected_keywords[cat2] = new_kws\n",
        "                                                changed = True\n",
        "                                                print(f\"Replaced incompatible keywords {kw2} in {cat2} with {new_kws}\")\n",
        "                                    else:\n",
        "                                        if kw2 in group2:\n",
        "                                            new_kw = self.get_random_keyword(cat2, exclude=group2)\n",
        "                                            if new_kw:\n",
        "                                                selected_keywords[cat2] = new_kw\n",
        "                                                changed = True\n",
        "                                                print(f\"Replaced incompatible keyword {kw2} in {cat2} with {new_kw}\")\n",
        "                        elif kw in group2:\n",
        "                            for cat2, kw2 in list(selected_keywords.items()):\n",
        "                                if cat2 != cat:\n",
        "                                    if isinstance(kw2, list):\n",
        "                                        if any(k in group1 for k in kw2):\n",
        "                                            new_kws = self.get_multiple_keywords(cat2, len(kw2), exclude=group1)\n",
        "                                            if new_kws:\n",
        "                                                selected_keywords[cat2] = new_kws\n",
        "                                                changed = True\n",
        "                                                print(f\"Replaced incompatible keywords {kw2} in {cat2} with {new_kws}\")\n",
        "                                    else:\n",
        "                                        if kw2 in group1:\n",
        "                                            new_kw = self.get_random_keyword(cat2, exclude=group1)\n",
        "                                            if new_kw:\n",
        "                                                selected_keywords[cat2] = new_kw\n",
        "                                                changed = True\n",
        "                                                print(f\"Replaced incompatible keyword {kw2} in {cat2} with {new_kw}\")\n",
        "            if not changed:\n",
        "                break\n",
        "        return selected_keywords\n",
        "\n",
        "    def generate_keyword_combination(self, forced_categories: Optional[List[str]] = None) -> str:\n",
        "        selected_keywords = {}\n",
        "\n",
        "        # Align with anatomy of good prompt: Subject, Medium, Style, Resolution, Additional details, Color, Lighting\n",
        "        # Improvements: Updated core_categories to include new splits (e.g., 'nudity', 'sex_acts' instead of 'sexual').\n",
        "        # Always include 'base_quality' and select multiple terms from it.\n",
        "        # 'enhanced_quality' is now optional/random.\n",
        "        core_categories = ['medium', 'base_quality', 'enhanced_quality', 'expression', 'resolution', 'additional_details', 'color', 'lighting',\n",
        "                           'age', 'race', 'body', 'pose', 'dress', 'environment', 'emotion', 'mood', 'camera', 'time_of_day'] # , 'style', 'art_style']\n",
        "\n",
        "        for category in core_categories:\n",
        "            if category == 'base_quality':\n",
        "                # Select multiple (e.g., 2-3) from base_quality to use together\n",
        "                num_select = random.randint(2, 3)\n",
        "                selected_keywords[category] = self.get_multiple_keywords(category, num=num_select)\n",
        "            else:\n",
        "                selected_keywords[category] = self.get_random_keyword(category)\n",
        "\n",
        "        # Conditional additions based on documents\n",
        "        outdoor_envs = ['beach', 'forest', 'pool', 'mountain', 'desert', 'river', 'cave', 'jungle', 'lake']\n",
        "        if selected_keywords['environment'] in outdoor_envs:\n",
        "            if random.random() > 0.5 or 'weather' in forced_categories:\n",
        "                selected_keywords['weather'] = self.get_random_keyword('weather')\n",
        "\n",
        "        if 'human' in selected_keywords['race'] or 'girl' in selected_keywords['age']:\n",
        "            if random.random() > 0.25 or 'facial_features' in forced_categories:\n",
        "                selected_keywords['facial_features'] = self.get_random_keyword('facial_features')\n",
        "            if random.random() > 0.3 or 'hair_style' in forced_categories:\n",
        "                selected_keywords['hair_style'] = self.get_random_keyword('hair_style')\n",
        "            if random.random() > 0.3 or 'accessories' in forced_categories:\n",
        "                selected_keywords['accessories'] = self.get_random_keyword('accessories')\n",
        "\n",
        "        sitting_lying_poses = ['sitting on a chair', 'sitting cross-legged', 'sitting on knees', 'slouched on a chair',\n",
        "                               'sitting on the edge of a chair', 'sitting with knees to the side', 'sitting with legs stretched',\n",
        "                               'sitting with legs crossed', 'sitting hugging knees', 'sitting lotus', 'lying on the back',\n",
        "                               'lying on the stomach', 'lying on the side', 'curled up', 'reclining', 'sprawled out', 'propped on elbows']\n",
        "        if selected_keywords['pose'] in sitting_lying_poses:\n",
        "            if random.random() > 0.4 or 'props' in forced_categories:\n",
        "                selected_keywords['props'] = self.get_random_keyword('props')\n",
        "\n",
        "        if selected_keywords['dress'] not in ['naked', 'half naked', 'nude', 'topless']:\n",
        "            if random.random() > 0.3 or 'texture' in forced_categories:\n",
        "                selected_keywords['texture'] = self.get_random_keyword('texture')\n",
        "        else:\n",
        "            if random.random() > 0.4 or 'nipples' in forced_categories:\n",
        "                selected_keywords['nipples'] = self.get_random_keyword('nipples')\n",
        "            if random.random() > 0.3 or 'nudity' in forced_categories:\n",
        "                selected_keywords['nudity'] = self.get_random_keyword('nudity')\n",
        "\n",
        "        if random.random() > 0.3 or 'erotic' in forced_categories:\n",
        "            selected_keywords['erotic'] = self.get_random_keyword('erotic')\n",
        "        if random.random() > 0.35 and 'nudity' in selected_keywords or 'sensual' in forced_categories:\n",
        "            selected_keywords['sensual'] = self.get_random_keyword('sensual')\n",
        "        if random.random() > 0.3 and 'nudity' in selected_keywords or 'sex_position' in forced_categories:\n",
        "            selected_keywords['sex_position'] = self.get_random_keyword('sex_position')\n",
        "        if random.random() > 0.3 and 'erotic' in selected_keywords or 'action' in forced_categories:\n",
        "            selected_keywords['action'] = self.get_random_keyword('action')\n",
        "        if random.random() > 0.3 or 'sex_acts' in forced_categories:\n",
        "            selected_keywords['sex_acts'] = self.get_random_keyword('sex_acts')\n",
        "        if random.random() > 0.3 or 'bodily_effects' in forced_categories:\n",
        "            selected_keywords['bodily_effects'] = self.get_random_keyword('bodily_effects')\n",
        "        if random.random() > 0.3 or 'sexual_descriptors' in forced_categories:\n",
        "            selected_keywords['sexual_descriptors'] = self.get_random_keyword('sexual_descriptors')\n",
        "\n",
        "        if random.random() > 0.3 or 'background_details' in forced_categories:\n",
        "            selected_keywords['background_details'] = self.get_random_keyword('background_details')\n",
        "\n",
        "        # Improvement: If forced_categories provided, explicitly add/override them if not already selected.\n",
        "        if forced_categories:\n",
        "            for category in forced_categories:\n",
        "                if category in self.keyword_sets:\n",
        "                    if category == 'base_quality':\n",
        "                        num_select = random.randint(2, 3)\n",
        "                        selected_keywords[category] = self.get_multiple_keywords(category, num=num_select)\n",
        "                    else:\n",
        "                        selected_keywords[category] = self.get_random_keyword(category)\n",
        "                else:\n",
        "                    print(f\"Forced category {category} not found, skipping.\")\n",
        "\n",
        "        selected_keywords = self.check_compatibility(selected_keywords)\n",
        "\n",
        "        # Structure prompt as per user request: medium, quality, expression, resolution at start; camera, time_of_day, art_style at end\n",
        "        # Improvement: Handle multi-keyword categories by joining them with commas.\n",
        "        prompt_parts = [\n",
        "            self.main_keywords,\n",
        "            selected_keywords['medium'] if isinstance(selected_keywords['medium'], str) else \", \".join(selected_keywords['medium']),\n",
        "            \", \".join(selected_keywords['base_quality']) if 'base_quality' in selected_keywords else \"\",\n",
        "            selected_keywords.get('enhanced_quality', \"\")\n",
        "        ]\n",
        "\n",
        "        # Middle part: subject, additional_details, color, lighting, age, race, body, pose, dress, environment, emotion, mood\n",
        "        middle_parts = []\n",
        "        if random.random() > 0.6:\n",
        "            character = self.get_random_keyword('character')\n",
        "            middle_parts.append(f\"{character}, {selected_keywords['age']}, {selected_keywords['race']}\")\n",
        "        else:\n",
        "            race = selected_keywords['race']\n",
        "            hair_color = self.get_random_keyword('color')\n",
        "            eye_color = self.get_random_keyword('color')\n",
        "            middle_parts.append(f\"{selected_keywords['age']} {race} {'' if 'girl' in race else 'girl'}, \"\n",
        "                                f\"{hair_color} hair, {eye_color} eyes, {selected_keywords.get('hair_style', '')}, \"\n",
        "                                f\"{selected_keywords.get('facial_features', '')}, {selected_keywords['body']}\")\n",
        "\n",
        "        middle_parts.extend([\n",
        "            f\"{selected_keywords['expression']}, {selected_keywords['pose']}\"\n",
        "        ])\n",
        "\n",
        "        # Add conditional categories to middle\n",
        "        for category in ['erotic', 'nipples', 'nudity', 'sensual', 'sex_position', 'action', 'accessories', 'texture', 'background_details', 'props', 'sex_acts', 'bodily_effects', 'sexual_descriptors']:\n",
        "            if category in selected_keywords:\n",
        "                kw = selected_keywords[category]\n",
        "                middle_parts.append(kw if isinstance(kw, str) else \", \".join(kw))\n",
        "\n",
        "        middle_parts.extend([\n",
        "            f\"{selected_keywords['dress']}, {selected_keywords['emotion']}, {selected_keywords['mood']}\",\n",
        "            f\"{selected_keywords['environment']}, {selected_keywords.get('weather', '')}\",\n",
        "            f\"{selected_keywords['additional_details']}, {selected_keywords['lighting']}\",\n",
        "        ])\n",
        "\n",
        "        # End part: camera, time_of_day, art_style\n",
        "        end_parts = [\n",
        "            f\"{selected_keywords['camera']}, {selected_keywords['time_of_day']}\" # , {selected_keywords['art_style']}\"\n",
        "        ]\n",
        "\n",
        "        # Combine all parts\n",
        "        prompt_parts.extend(middle_parts)\n",
        "        prompt_parts.extend(end_parts)\n",
        "\n",
        "        prompt = \", \".join(filter(None, prompt_parts)).replace('  ', ' ').strip()\n",
        "\n",
        "        words = prompt.split()\n",
        "        if len(words) > self.max_prompt_length:\n",
        "            prompt = \" \".join(words[:self.max_prompt_length])\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def generate_negative_prompt(self) -> str:\n",
        "        # Select a random subset of negative keywords as per documents (simple words, no 'no', 10-20 items)\n",
        "        num_general = random.randint(5, 10)\n",
        "        num_human = random.randint(5, 10)\n",
        "        general_neg = random.sample(self.negative_keyword_sets['general'], min(num_general, len(self.negative_keyword_sets['general'])))\n",
        "        human_neg = random.sample(self.negative_keyword_sets['human'], min(num_human, len(self.negative_keyword_sets['human'])))\n",
        "        negative_prompt = \", \".join(general_neg + human_neg)\n",
        "        return negative_prompt\n",
        "\n",
        "    def clean_ai_output(self, text: str) -> str:\n",
        "        text = re.sub(r'^(here is your prompt:|generated prompt:|prompt:|here you go:|here\\'s the prompt:)\\s*', '', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'(i hope|let me know|enjoy|please note).*$', '', text, flags=re.IGNORECASE)\n",
        "        text = text.strip('\"\\'` \\n').replace('\\n', ' ')\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        words = text.split()\n",
        "        if len(words) > self.max_prompt_length:\n",
        "            text = ' '.join(words[:self.max_prompt_length])\n",
        "        return text\n",
        "\n",
        "    def generate_prompts(\n",
        "            self,\n",
        "            base_prompt: str = 'Generate highly detailed NSFW prompt for StableDiffusion image generation',\n",
        "            num_prompts: int = 10,\n",
        "            save_path: Optional[str] = None,\n",
        "            batch_size: int = 10,\n",
        "            forced_categories: Optional[List[str]] = None\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        print(f'Starting to generate {num_prompts} prompts...')\n",
        "        start_time = time.time()\n",
        "        prompts = []\n",
        "\n",
        "        general_prompt = \"\"\"\n",
        "        {base}. Follow these rules:\n",
        "        1. Use only provided keywords\n",
        "        2. Output only the prompt, no extra commentary\n",
        "        3. Select one option randomly from lists separated by '|'\n",
        "        4. Keep prompt to one line, max {max_words} words\n",
        "        5. Ensure coherence and compatibility with StableDiffusion\n",
        "        Keywords: {keywords}\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        while len(prompts) < num_prompts:\n",
        "            try:\n",
        "                keywords = self.generate_keyword_combination(forced_categories)\n",
        "                full_prompt = general_prompt.format(\n",
        "                    base=base_prompt,\n",
        "                    keywords=keywords,\n",
        "                    max_words=self.max_prompt_length\n",
        "                )\n",
        "\n",
        "                ai_seed = random.randint(0, 2**32 - 1)\n",
        "                raw_output = self.generate_prompt_fn(prompt=full_prompt, seed=ai_seed)\n",
        "\n",
        "                if raw_output:\n",
        "                    clean_positive = self.clean_ai_output(raw_output)\n",
        "                    negative = self.generate_negative_prompt()  # Fixed: Generate negative here\n",
        "                    if clean_positive and len(clean_positive.split()) <= self.max_prompt_length:\n",
        "                        prompt_pair = {\"positive\": clean_positive, \"negative\": negative}\n",
        "                        prompts.append(prompt_pair)\n",
        "                        print(f\"Generated prompt pair {len(prompts)}/{num_prompts}: Positive - {clean_positive} | Negative - {negative}\")\n",
        "\n",
        "                        if save_path and len(prompts) % batch_size == 0:\n",
        "                            self.save_prompts(base_prompt, prompts, save_path, timestamp)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating prompt: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if save_path:\n",
        "            self.save_prompts(base_prompt, prompts, save_path, timestamp)\n",
        "\n",
        "        elapsed = round(time.time() - start_time, 1)\n",
        "        print(f'Finished generating {len(prompts)} prompt pairs in {elapsed} seconds.')\n",
        "        return prompts\n",
        "\n",
        "    def generate_raw_prompts(\n",
        "            self,\n",
        "            base_prompt: str = 'Generate highly detailed NSFW prompt for StableDiffusion image generation',\n",
        "            forced_categories: Optional[List[str]] = None\n",
        "    ) -> Dict[str, str]:\n",
        "        keywords = self.generate_keyword_combination(forced_categories)\n",
        "        raw_positive = f\"{base_prompt}, {keywords}\" if base_prompt and len(base_prompt) > 0 else keywords\n",
        "        return self.clean_ai_output(raw_positive)\n",
        "\n",
        "    def save_prompts(self, base_prompt: str, prompts: List[Dict[str, str]], directory: str, timestamp: str) -> None:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        filename = os.path.join(directory, f\"prompts_{timestamp}.json\")\n",
        "\n",
        "        data = {\n",
        "            \"metadata\": {\n",
        "                \"generated_at\": timestamp,\n",
        "                \"num_prompts\": len(prompts),\n",
        "                \"base_prompt\": base_prompt,\n",
        "                \"keyword_categories\": list(self.keyword_sets.keys())\n",
        "            },\n",
        "            \"prompts\": prompts\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(filename, 'w') as f:\n",
        "                json.dump(data, f, indent=2)\n",
        "            print(f\"Saved {len(prompts)} prompt pairs to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving prompts: {str(e)}\")"
      ],
      "metadata": {
        "id": "0Bwk6sBK1rbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator"
      ],
      "metadata": {
        "id": "0UDR4sOW14v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(prompt, seed=1267):\n",
        "    promptGenerator.clear_history()\n",
        "    prompt, out = promptGenerator.generate_prompt(prompt=prompt, seed=seed, use_system_prompt=False)\n",
        "    return prompt\n",
        "\n",
        "generator = AIPromptGenerator(generate_prompt)\n",
        "\n",
        "base_prompt = 'Generate prompt for girl that getting fucked in sexual positions, highest possible erotic themes, sensual pleasure coursing through their bodies'\n",
        "# base_prompt = 'Generate prompt for beauty girl with high-quality sensual themes and sexual positions, optimized for StableDiffusion'\n",
        "# prompts = generator.generate_prompts(base_prompt=base_prompt, num_prompts=100, save_path=\"/content/drive/MyDrive/AI/KHidden.mail_Generated\")\n",
        "# for pt in prompts:\n",
        "#     print(pt)"
      ],
      "metadata": {
        "id": "9sMxJrIB1wYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(AIPromptGenerator(None).generate_raw_prompts(base_prompt='', forced_categories=['sexual', 'nipples']))"
      ],
      "metadata": {
        "id": "-PUPmdduNBwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_prompt(prompt='suggest me image prompt with explitic sexual content, including sex , ... . not mild themes, highest possible erotic themes ', seed=1267))"
      ],
      "metadata": {
        "id": "NcnnfG0-TQQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nodes"
      ],
      "metadata": {
        "id": "imVQcYXHvVeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models as Enum"
      ],
      "metadata": {
        "id": "p50s1XPcng-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "# https://huggingface.co/stabilityai/control-lora\n",
        "class Controlnet(Enum):\n",
        "    pass\n",
        "\n",
        "class ControlnetLoRa_SDXL(Controlnet):\n",
        "    Canny = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors', 'control-lora-canny-rank256.safetensors']\n",
        "    Depth = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors', 'control-lora-depth-rank256.safetensors']\n",
        "    Recolor = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors', 'control-lora-recolor-rank256.safetensors']\n",
        "    Sketch = ['https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors', 'control-lora-sketch-rank256.safetensors']\n",
        "    OpenPoseXL2 = ['https://huggingface.co/thibaud/controlnet-openpose-sdxl-1.0/resolve/main/control-lora-openposeXL2-rank256.safetensors', 'control-lora-openposeXL2-rank256.safetensors']\n",
        "\n",
        "class ControlnetModel_SD15(Controlnet):\n",
        "    Canny = ['https://huggingface.co/lllyasviel/control_v11p_sd15_canny/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_canny.fp16.safetensors']\n",
        "    Depth = ['https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11f1p_sd15_depth.fp16.safetensors']\n",
        "    SoftEdge = ['https://huggingface.co/lllyasviel/control_v11p_sd15_softedge/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_softedge.fp16.safetensors']\n",
        "    Inpaint = ['https://huggingface.co/lllyasviel/control_v11p_sd15_inpaint/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_inpaint.fp16.safetensors']\n",
        "    OpenPose = ['https://huggingface.co/lllyasviel/control_v11p_sd15_openpose/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_openpose.fp16.safetensors']\n",
        "    Scribble = ['https://huggingface.co/lllyasviel/control_v11p_sd15_scribble/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_scribble.fp16.safetensors']\n",
        "    LineArt  = ['https://huggingface.co/lllyasviel/control_v11p_sd15_lineart/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'control_v11p_sd15_lineart.fp16.safetensors']\n",
        "\n",
        "class ControlnetModel_XL(Controlnet):\n",
        "    Canny = ['https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'controlnet-canny-sdxl-1.0.fp16.safetensors']\n",
        "    Depth = ['https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors', 'controlnet-depth-sdxl-1.0.fp16.safetensors']\n",
        "\n",
        "class HyperLoRa(Enum):\n",
        "    HyperSD_15_1_step = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-1step-lora.safetensors', 'Hyper-SD15-1step-lora.safetensors']\n",
        "    HyperSD_15_2_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-2steps-lora.safetensors', 'Hyper-SD15-2steps-lora.safetensors']\n",
        "    HyperSD_15_4_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-4steps-lora.safetensors', 'Hyper-SD15-4steps-lora.safetensors']\n",
        "    HyperSD_15_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SD15-8steps-lora.safetensors', 'Hyper-SD15-8steps-lora.safetensors']\n",
        "    HyperSD_XL_1_step = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-1step-lora.safetensors', 'Hyper-SDXL-1step-lora.safetensors']\n",
        "    HyperSD_XL_2_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-2steps-lora.safetensors', 'Hyper-SDXL-2steps-lora.safetensors']\n",
        "    HyperSD_XL_4_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-4steps-lora.safetensors', 'Hyper-SDXL-4steps-lora.safetensors']\n",
        "    HyperSD_XL_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-8steps-lora.safetensors', 'Hyper-SDXL-8steps-lora.safetensors']\n",
        "    Hyper_Flux_DEV_8_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-FLUX.1-dev-8steps-lora.safetensors', 'Hyper-FLUX.1-dev-8steps-lora.safetensors']\n",
        "    Hyper_Flux_DEV_16_steps = ['https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-FLUX.1-dev-16steps-lora.safetensors', 'Hyper-FLUX.1-dev-16steps-lora.safetensors']\n",
        "\n",
        "class UpscalerModel(Enum):\n",
        "    RealESRGAN_x2 = ['https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth', 'RealESRGAN_x2.pth']\n",
        "    UltraSharp_4x = ['https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x-UltraSharp.pth', '4x-UltraSharp.pth']\n",
        "\n",
        "class Scheduler(Enum):\n",
        "    SIMPLE = 'simple'\n",
        "    NORMAL = 'normal'\n",
        "    KARRAS = 'karras'\n",
        "    EXPONENTIAL = 'exponential'\n",
        "    SGM_UNIFORM = 'sgm_uniform'\n",
        "\n",
        "\n",
        "class Sampler(Enum):\n",
        "    DDIM = 'ddim'\n",
        "    Euler = 'euler'\n",
        "    Euler_a = 'euler_ancestral'\n",
        "    DDPM = 'ddpm'\n",
        "    DPM_PP_2M = 'dpmpp_2m'\n",
        "    DPM_PP_2M_SDE = 'dpmpp_2m_sde'\n",
        "    DPM_PP_SDE = 'dpmpp_sde'\n",
        "    DPM2 = 'dpm_2'\n",
        "    DPM2_a = 'dpm_2_ancestral'\n",
        "    Heun = 'heun'\n",
        "    LMS = 'lms'\n",
        "    DEIS = 'deis'\n",
        "    UniPC = 'uni_pc'\n",
        "    LCM = 'lcm'\n"
      ],
      "metadata": {
        "id": "lh8oeyhWnruO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes to method"
      ],
      "metadata": {
        "id": "u6xXtx6glPfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# %cd /content/TotoroUI\n",
        "# from TotoroUI.nodes import NODE_CLASS_MAPPINGS as T_NODE_CLASS_MAPPINGS\n",
        "# from TotoroUI.totoro import model_management as T_model_management\n",
        "# from TotoroUI.totoro_extras import nodes_custom_sampler as T_nodes_custom_sampler\n",
        "# from TotoroUI.totoro_extras import nodes_custom_sampler as T_nodes_custom_sampler\n",
        "# from TotoroUI.custom_nodes.totoro_GGUF.nodes import NODE_CLASS_MAPPINGS as T_NODE_CLASS_MAPPINGS_GGUF\n",
        "\n",
        "%cd /content/KMUI\n",
        "import nodes\n",
        "from KMUI.nodes import NODE_CLASS_MAPPINGS\n",
        "from KMUI.kmui_extras import nodes_custom_sampler\n",
        "from KMUI.kmui import model_management\n",
        "from KMUI.custom_nodes.KMUI_GGUF.nodes import NODE_CLASS_MAPPINGS as NODE_CLASS_MAPPINGS_GGUF\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "def scale_by_model(pixels, upscale_model:UpscalerModel, scale:float=1, upscale_method=\"nearest-exact\"): # return upscaled pixels\n",
        "    from KMUI.kmui_extras import nodes_upscale_model\n",
        "    # upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n",
        "    if not os.path.exists(modelpaths.upscale + '/' + upscale_model.value[1]):\n",
        "        download(upscale_model.value[0], upscale_model.value[1], modelpaths.upscale)\n",
        "        if not os.path.exists(modelpaths.upscale + '/' + upscale_model.value[1]):\n",
        "            raise Exception(f'download {upscale_model.value[1]} failed!')\n",
        "\n",
        "    UpscaleModelLoader = nodes_upscale_model.NODE_CLASS_MAPPINGS[\"UpscaleModelLoader\"]()\n",
        "    ImageUpscaleWithModel = nodes_upscale_model.NODE_CLASS_MAPPINGS[\"ImageUpscaleWithModel\"]()\n",
        "    ImageScaleBy = NODE_CLASS_MAPPINGS[\"ImageScaleBy\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        model = UpscaleModelLoader.load_model(model_name=upscale_model.value[1])[0]\n",
        "        image = pixels\n",
        "        if model:\n",
        "            image = ImageUpscaleWithModel.upscale(model, pixels)[0]\n",
        "\n",
        "        if scale != 1:\n",
        "            image = ImageScaleBy.upscale(image, upscale_method, scale)[0]\n",
        "\n",
        "        return image\n",
        "\n",
        "def apply_controlnet(conditioning, control_net, image, strength): # cn = [(lora name, strength), ...]\n",
        "    ControlNetApply = NODE_CLASS_MAPPINGS[\"ControlNetApply\"]()\n",
        "    with torch.inference_mode():\n",
        "        cond = ControlNetApply.apply_controlnet(conditioning, control_net, image, strength)[0]\n",
        "    return cond\n",
        "\n",
        "def apply_lora(unet, lora=[], clip=None, apply_to_clip=True): # lora = [(lora name, strength), ...]\n",
        "    LoraLoaderModelOnly = NODE_CLASS_MAPPINGS[\"LoraLoaderModelOnly\"]()\n",
        "    LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        if apply_to_clip:\n",
        "            final_model = (unet, clip)\n",
        "            for it in lora:\n",
        "                final_model = LoraLoader.load_lora(model=final_model[0], clip=final_model[1], lora_name=it[0], strength_model=it[1], strength_clip=it[1])\n",
        "        else:\n",
        "            final_model = unet\n",
        "            for it in lora:\n",
        "                final_model = LoraLoaderModelOnly.load_lora_model_only(final_model, it[0], it[1])[0]\n",
        "            final_model = (final_model, clip)\n",
        "        return final_model\n",
        "\n",
        "def apply_hyper_lora(unet, clip, lora:HyperLoRa):\n",
        "    if not os.path.exists(modelpaths.lora + '/' + lora.value[1]):\n",
        "        download(lora.value[0], lora.value[1], modelpaths.lora)\n",
        "        if not os.path.exists(modelpaths.lora + '/' + lora.value[1]):\n",
        "            raise Exception(f'download {lora.value[1]} failed!')\n",
        "\n",
        "    return apply_lora(unet=unet, lora=[[lora.value[1], 1.0],], clip=clip)\n",
        "    # LoraLoaderModelOnly = NODE_CLASS_MAPPINGS[\"LoraLoaderModelOnly\"]()\n",
        "    # final_model = unet\n",
        "    # with torch.inference_mode():\n",
        "    #     return LoraLoaderModelOnly.load_lora_model_only(final_model, lora.value[1], 1.0)[0]\n",
        "\n",
        "def load_vae(file_name=None):\n",
        "    if file_name is None:\n",
        "        for item in os.listdir(modelpaths.vae):\n",
        "            if item.endswith('safetensors') or item.endswith('pt'):\n",
        "                file_name = item\n",
        "                break\n",
        "        if not file_name:\n",
        "            raise Exception(\"no model found.\")\n",
        "        else:\n",
        "            print(f\"VAE {file_name} loaded.\")\n",
        "\n",
        "    VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "    with torch.inference_mode():\n",
        "        vae = VAELoader.load_vae(file_name)[0]\n",
        "    return vae, file_name\n",
        "\n",
        "def load_checkpoint(ckpt_name: str=None):\n",
        "    if Flux_mode:\n",
        "        schnell = 'schnell' in model_type.lower()\n",
        "        dn = False\n",
        "        if schnell:\n",
        "            # https://huggingface.co/city96/FLUX.1-schnell-gguf/tree/main\n",
        "            name = 'flux1-schnell-Q6_K.gguf'\n",
        "            name = 'flux1-schnell-Q5_K_S.gguf'\n",
        "            if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "                dn = True\n",
        "                download(f'https://huggingface.co/city96/FLUX.1-schnell-gguf/resolve/main/{name}',name , modelpaths.unet)\n",
        "        else:\n",
        "            # https://huggingface.co/city96/FLUX.1-dev-gguf/tree/main\n",
        "            # name = 'flux1-dev-Q6_K.gguf'\n",
        "            name = 'flux1-dev-Q5_K_S.gguf'\n",
        "            if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "                dn = True\n",
        "                download(f'https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/{name}',name , modelpaths.unet)\n",
        "                download(f'https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha/resolve/main/diffusion_pytorch_model.safetensors','FLUX.1-Turbo-Alpha.safetensors' , modelpaths.lora)\n",
        "        if dn:\n",
        "            download('https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft', 'ae.sft', modelpaths.vae)\n",
        "            download('https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors', 'clip_l.safetensors', modelpaths.clip)\n",
        "            download('https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q5_K_M.gguf', 't5-v1_1-xxl-encoder-Q6_K.gguf', modelpaths.clip)\n",
        "\n",
        "\n",
        "        DualCLIPLoaderGGUF = NODE_CLASS_MAPPINGS_GGUF[\"DualCLIPLoaderGGUF\"]()\n",
        "        UnetLoaderGGUF = NODE_CLASS_MAPPINGS_GGUF[\"UnetLoaderGGUF\"]()\n",
        "        VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            clip = DualCLIPLoaderGGUF.load_clip(\"t5-v1_1-xxl-encoder-Q6_K.gguf\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "            unet = UnetLoaderGGUF.load_unet(name)[0]\n",
        "            if not schnell:\n",
        "                unet, clip = apply_lora(unet=unet, lora=[['FLUX.1-Turbo-Alpha.safetensors', 1.0]], clip=clip)\n",
        "            vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "            return unet, clip, vae, name\n",
        "    elif model_type==\"SD3.5\":\n",
        "        name = 'sd3.5_large_fp8_scaled.safetensors'\n",
        "        if not os.path.exists(modelpaths.unet + '/' + name):\n",
        "            download(f'https://huggingface.co/Comfy-Org/stable-diffusion-3.5-fp8/resolve/main/{name}',name , modelpaths.model)\n",
        "\n",
        "        CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "        with torch.inference_mode():\n",
        "            checkpoint_loader_simple = CheckpointLoaderSimple.load_checkpoint(ckpt_name) # it return (model_patcher, clip, vae, clipvision)\n",
        "            clip = checkpoint_loader_simple[1]\n",
        "            unet = checkpoint_loader_simple[0]\n",
        "            vae = checkpoint_loader_simple[2]\n",
        "            return unet, clip, vae, ckpt_name\n",
        "    else:\n",
        "        if ckpt_name is None:\n",
        "            for item in os.listdir(modelpaths.model):\n",
        "                if item.endswith('safetensors'):\n",
        "                    ckpt_name = item\n",
        "                    break\n",
        "            if not ckpt_name:\n",
        "                raise Exception(\"no model found.\")\n",
        "            else:\n",
        "                print(f\"model {ckpt_name} loaded.\")\n",
        "        CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "        with torch.inference_mode():\n",
        "            checkpoint_loader_simple = CheckpointLoaderSimple.load_checkpoint(ckpt_name) # it return (model_patcher, clip, vae, clipvision)\n",
        "            clip = checkpoint_loader_simple[1]\n",
        "            unet = checkpoint_loader_simple[0]\n",
        "            vae = checkpoint_loader_simple[2]\n",
        "            return unet, clip, vae, ckpt_name\n",
        "\n",
        "def encode_prompt(clip, prompt):\n",
        "    with torch.inference_mode():\n",
        "        cond, pooled = clip.encode_from_tokens(clip.tokenize(prompt), return_pooled=True)\n",
        "        return [[cond, {\"pooled_output\": pooled}]]\n",
        "\n",
        "def load_controlnet(control_net):\n",
        "    if not os.path.exists(modelpaths.controlnet + '/' + control_net.value[1]):\n",
        "        download(control_net.value[0], control_net.value[1], modelpaths.controlnet)\n",
        "        if not os.path.exists(modelpaths.controlnet + '/' + control_net.value[1]):\n",
        "            raise Exception(f'download {control_net.value[1]} failed!')\n",
        "\n",
        "    CNLoader = NODE_CLASS_MAPPINGS[\"ControlNetLoader\"]()\n",
        "    with torch.inference_mode():\n",
        "        cn = CNLoader.load_vae(control_net.value[1])[0]\n",
        "    return cn\n",
        "\n",
        "def create_empty_latent(width, height, batch_size=1):\n",
        "    EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16), batch_size=batch_size)[0]\n",
        "\n",
        "def ksampler(model, positive, negative, latent, seed=0, steps=20, cfg=1.0,\n",
        "             sampler: Sampler=Sampler.Euler, scheduler: Scheduler=Scheduler.NORMAL,\n",
        "             denoise=1.0,start_step=None, last_step=None, add_noise=True, force_full_denoise=False):\n",
        "    RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "    BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "    CFGGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"CFGGuider\"]()\n",
        "    KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "    BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "    SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "\n",
        "    disable_noise = not add_noise\n",
        "    if Flux_mode:\n",
        "        if 'schnell' in model_type.lower():\n",
        "            sampler = Sampler.Euler\n",
        "            scheduler = Scheduler.SIMPLE\n",
        "            steps = 4\n",
        "            cfg = 0.9\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                noise = RandomNoise.get_noise(seed)[0]\n",
        "                guider = BasicGuider.get_guider(model, positive)[0]\n",
        "                guider.set_cfg(cfg)\n",
        "\n",
        "                sampler = KSamplerSelect.get_sampler(sampler.value)[0]\n",
        "                sigmas = BasicScheduler.get_sigmas(model, scheduler.value, steps, denoise)[0]\n",
        "                sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent)\n",
        "                model_management.soft_empty_cache(True)\n",
        "                return sample\n",
        "        else:\n",
        "            sampler = Sampler.Euler\n",
        "            scheduler = Scheduler.SIMPLE\n",
        "            steps = 8\n",
        "            cfg = 1.0\n",
        "\n",
        "            return nodes.common_ksampler(model=model, seed=seed, steps=steps, cfg=cfg, sampler_name=sampler.value,\n",
        "                                        scheduler=scheduler.value, positive=positive, negative=negative,\n",
        "                                        latent=latent, denoise=denoise, start_step=start_step, last_step=last_step,\n",
        "                                         disable_noise=disable_noise, force_full_denoise=force_full_denoise)[0]\n",
        "    else:\n",
        "        with torch.inference_mode():\n",
        "            # noise = RandomNoise.get_noise(seed)[0]\n",
        "            # guider = CFGGuider.get_guider(model, positive, negative, cfg)[0]\n",
        "            # sampler = KSamplerSelect.get_sampler(sampler.value)[0]\n",
        "            # sigmas = BasicScheduler.get_sigmas(model, scheduler.value, steps, denoise)[0]\n",
        "            # sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent)\n",
        "            # model_management.soft_empty_cache()\n",
        "            # return sample\n",
        "            return nodes.common_ksampler(model=model, seed=seed, steps=steps, cfg=cfg, sampler_name=sampler.value,\n",
        "                                        scheduler=scheduler.value, positive=positive, negative=negative,\n",
        "                                        latent=latent, denoise=denoise,start_step=start_step, last_step=last_step,\n",
        "                                         disable_noise=disable_noise,force_full_denoise=force_full_denoise)[0]\n",
        "\n",
        "def vae_decode(vae, latent): # return image (float[0-1])\n",
        "    VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return VAEDecode.decode(vae, latent)[0].detach()\n",
        "\n",
        "def vae_encode(vae, pixels): # pixels (float[0-1])\n",
        "    VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        return VAEEncode.encode(vae, pixels)[0]\n",
        "\n",
        "def load_image(image_path): # RETURN_TYPES = (\"IMAGE\", \"MASK\")\n",
        "    LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "    return LoadImage.load_image(image_path)[0]\n",
        "\n",
        "def get_printable_image(image, index=0): # image in float format\n",
        "    return Image.fromarray(np.array(image*255, dtype=np.uint8)[index])\n",
        "\n",
        "def saveJPEG(image, index=0, path='/content/KMUI/output', name='image', quality=94, exif=None): # image in float format\n",
        "    img = Image.fromarray(np.array(image*255, dtype=np.uint8)[index])\n",
        "    if exif:\n",
        "        img.convert('RGB').save(f'{path}/{name}.jpg', optimize=True, quality=quality, exif=exif)\n",
        "    else:\n",
        "        img.convert('RGB').save(f'{path}/{name}.jpg', optimize=True, quality=quality)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "PrC4_OZuEHNs",
        "outputId": "d790df5b-b646-473a-98d9-b1abc5e5feca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KMUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## custom nodes"
      ],
      "metadata": {
        "id": "9DuIoxttIxBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceRestorModel(Enum):\n",
        "    GFPGANv14 = 'GFPGANv1.4.pth'\n",
        "    codeformer = 'codeformer-v0.1.0.pth'\n",
        "    GPEN_BFR_512 = 'GPEN-BFR-512.onnx'\n",
        "    GPEN_BFR_1024 = 'GPEN-BFR-1024.onnx'\n",
        "    GPEN_BFR_2048 = 'GPEN-BFR-2048.onnx'\n",
        "\n",
        "class ReActorFaceSwap:\n",
        "    facedetection_model = [\"retinaface_resnet50\", \"retinaface_mobile0.25\", \"YOLOv5l\", \"YOLOv5n\"]\n",
        "    fr_urls = \"https://huggingface.co/datasets/Gourieff/ReActor/resolve/main/models/facerestore_models/\"\n",
        "    reactor = None\n",
        "    swap_model = 'inswapper_128.onnx'\n",
        "    face_restore_model = FaceRestorModel.GFPGANv14\n",
        "\n",
        "    def __init__(self, face_restore_model=FaceRestorModel.GFPGANv14):\n",
        "        try:\n",
        "            %cd /content/KMUI/custom_nodes/KMUI_reactor_node\n",
        "            from KMUI_reactor_node.nodes import NODE_CLASS_MAPPINGS as RA_NODE_CLASS_MAPPINGS\n",
        "        except Exception as e:\n",
        "            %cd /content/KMUI/custom_nodes\n",
        "            from KMUI_reactor_node.nodes import NODE_CLASS_MAPPINGS as RA_NODE_CLASS_MAPPINGS\n",
        "\n",
        "        self.face_restore_model=face_restore_model\n",
        "        if not os.path.exists(f'{modelpaths.base_path}/facerestore_models'):\n",
        "            os.makedirs(f'{modelpaths.base_path}/facerestore_models')\n",
        "\n",
        "        if not os.path.exists(f'{modelpaths.base_path}/facerestore_models/{self.face_restore_model.value}'):\n",
        "            download(self.fr_urls + self.face_restore_model.value, self.face_restore_model.value, f'{modelpaths.base_path}/facerestore_models')\n",
        "\n",
        "        self.reactor = RA_NODE_CLASS_MAPPINGS[\"ReActorFaceSwap\"]()\n",
        "\n",
        "    def swap(self, input_image, source_image, input_faces_index='0', source_faces_index='0'):\n",
        "        result ,face_model_to_provide = self.reactor.execute(enabled=True, input_image=input_image, swap_model=self.swap_model, detect_gender_source='no',\n",
        "                             detect_gender_input='no', source_faces_index=source_faces_index, input_faces_index=input_faces_index,\n",
        "                             console_log_level=1, face_restore_model=self.face_restore_model.value, face_restore_visibility=1,\n",
        "                             codeformer_weight=1, facedetection=self.facedetection_model[0], source_image=source_image,\n",
        "                             face_model=None, faces_order=None, face_boost=None)\n",
        "        return result\n",
        "\n",
        "# reActorFaceSwap = None\n",
        "# if ReactorNode:\n",
        "#     reActorFaceSwap = ReActorFaceSwap()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lhjEW5-RIwHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference data"
      ],
      "metadata": {
        "id": "F3pLYafjlXZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_prompt = '''\n",
        "A masterfully crafted, ultra-detailed, 8K masterpiece, beauty girl with captivating eyes,\n",
        "curvy, bent, seductive body shape, one hand grab breast, scream of orgasm, vibrand intense color, RED, GREEN, Yellow, purple, black, white, gold,\n",
        "her voluptuous figure alluring in the soft moonlight. Carefully rendered in high resolution,\n",
        "every curl of her luscious tresses, her bare skin aglow in the deep shadows of this erotic scene,\n",
        "'''\n",
        "# positive_prompt = '''\n",
        "# highly detailed realistic (full_body:1.3) photo of girl with vibrant red hair styled in an intricate braid that falls over her shoulder.\n",
        "# her bare skin aglow in the deep shadows of this erotic scene, She has large, expressive golden-brown eyes with delicate eyeliner and a touch of red eyeshadow.\n",
        "# Her lips are full and painted a bold red, slightly parted to reveal a hint of sharp. She wears elegant,\n",
        "# dangling earrings featuring heart-shaped red gemstones framed in gold, paired with a matching red cord necklace. Her skin is smooth and luminous,\n",
        "# with a soft blush on her cheeks. She is dressed in a flowing white garment with gentle folds, illuminated by a warm, ethereal light against a dark,\n",
        "# starry background with tiny sparkling particles. The overall style should be realistic with a fantasy aesthetic, emphasizing rich colors and fine details.\n",
        "# '''\n",
        "\n",
        "# positive_prompt = '''\n",
        "# Create a highly detailed realistic (full body) photo of girl with vibrant red hair styled in an intricate braid.\n",
        "# Her hair is glossy and voluminous, with soft strands framing her face, catching the light with a subtle glow.\n",
        "# her bare white skin aglow in the deep shadows of this erotic scene, She has large, expressive golden-brown eyes with delicate eyeliner and a touch of red eyeshadow,\n",
        "# giving her a striking and elegant look. Her lips are full and painted a bold red, slightly parted to reveal a hint of sharp.\n",
        "# her bare skin aglow in the deep shadows of this erotic scene, curvy, bent, seductive body shape,\n",
        "# She wears elegant, dangling earrings featuring heart-shaped red gemstones framed in gold, paired with a matching red cord necklace.\n",
        "# Her skin is smooth and luminous, with a soft blush on her cheeks. She is illuminated by a warm,\n",
        "# ethereal light against a dark, starry background with tiny sparkling particles. The overall style should be a fantasy aesthetic, emphasizing rich colors and fine details.\n",
        "# '''\n",
        "\n",
        "negative_prompt = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "lora_prompt = ''\n",
        "width = 640 # int(832)\n",
        "height = 1144 # int(1216)\n",
        "seed = 0\n",
        "steps = 25\n",
        "cfg = 5\n",
        "sampler = Sampler.DPM_PP_2M\n",
        "scheduler = Scheduler.KARRAS\n",
        "# print(positive_prompt)\n",
        "# print(negative_prompt)\n",
        "empty_latent = create_empty_latent(width,height)\n",
        "if seed ==0:\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "print(f'seed={seed}')"
      ],
      "metadata": {
        "id": "LopCusy3SNzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "GbPYUikl_Udj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet, clip, vae, chp_name = load_checkpoint()\n",
        "# vae, vae_name = load_vae()"
      ],
      "metadata": {
        "id": "sCYSnmdx_ZJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet2, clip2 = apply_hyper_lora(unet=unet, clip=clip, lora=HyperLoRa.HyperSD_XL_8_steps)"
      ],
      "metadata": {
        "id": "9RlwQR67chuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple text to image"
      ],
      "metadata": {
        "id": "NS8f_7E5lseA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed = random.randint(0, 18446744073709551615)\n",
        "# unet2 = apply_hyper_lora(unet, clip, HyperLoRa.HyperSD_XL_8_steps)\n",
        "default_lora_list=[\n",
        "    ['AddMoreDetails-v1.safetensors', 1.5],\n",
        "    ['upright_front_above_50.safetensors', 0.75],\n",
        "    ['seductiveorgasm.safetensors', 0.85],\n",
        "    # ['BetterEyesFaceSkin-v1.safetensors', 1],\n",
        "    # ['3DMM_V12.safetensors', 1],\n",
        "]\n",
        "lora_prompt = ', (1boy:1.1), sex, (hetero:1.3), (upright straddle), pussy juice, leg lock, from behind, seductiveorgasm'\n",
        "\n",
        "# default_lora_list=[\n",
        "#     ['Expressive_H-000001.safetensors', 0.8],\n",
        "#     ['PerfectEyesXL.safetensors', 0.9],\n",
        "#     ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "#     ['Urban_Fusion_IL.safetensors', 0.3],\n",
        "#     ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "#     ['cfg_scale_boost.safetensors', 0.3],\n",
        "#     # ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "# ]\n",
        "\n",
        "# lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "unet3, clip3 = apply_lora(unet=unet, lora=default_lora_list, clip=clip, apply_to_clip=True)\n"
      ],
      "metadata": {
        "id": "TgGY5TgwQYqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "for i in range(100):\n",
        "    generator = AIPromptGenerator(generate_prompt_fn=None)\n",
        "\n",
        "    positive_prompt = f'''\n",
        "    A masterfully crafted, ultra-detailed, 8K masterpiece, (1boy:1.1), sex, (hetero:1.3), (upright straddle), leg lock, from behind, beauty girl with captivating eyes,\n",
        "    {generator.get_random_keyword('expression')}, {generator.get_random_keyword('body')}, {generator.get_random_keyword('sensual')}, {generator.get_random_keyword('erotic')},\n",
        "    {generator.get_random_keyword('pose')}, {generator.get_random_keyword('lighting')}, {generator.get_random_keyword('nipples')}, {generator.get_random_keyword('sexual')},\n",
        "    in {generator.get_random_keyword('environment')}, scream of orgasm, one hand grab breast,vibrand intense {generator.get_random_keyword('color')} hair,\n",
        "    {generator.get_random_keyword('hair_style')} hair style, her voluptuous figure alluring in the soft moonlight. Carefully rendered in high resolution,\n",
        "    wear {generator.get_random_keyword('accessories')},  every curl of her luscious tresses, her bare skin aglow in the deep shadows of this erotic scene,\n",
        "    {generator.get_random_keyword('age')}, {generator.get_random_keyword('camera')}, seductiveorgasm\n",
        "    '''\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "    # seed = 1366\n",
        "    latent = ksampler(model=unet3, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                    positive=encode_prompt(clip3, positive_prompt),\n",
        "                    negative=encode_prompt(clip3, negative_prompt),\n",
        "                    latent=empty_latent)\n",
        "\n",
        "    image = vae_decode(vae, latent)\n",
        "\n",
        "    print(f'seed={seed}, time: {str(time.time()-t1)} sec')\n",
        "\n",
        "    img = get_printable_image(image)\n",
        "    # clear_output()\n",
        "    saveJPEG(image)\n",
        "    caption = (\n",
        "        TelegramTextBuilder()\n",
        "        .plain(f\"seed={seed}, cfg={cfg}, step={steps}, w={width}, h={height}\")\n",
        "        .new_line()\n",
        "        .quote(positive_prompt, True, True)\n",
        "        .new_line()\n",
        "        .build()\n",
        "    )\n",
        "    await broadcast_image_to_telegram_bot('/content/KMUI/output/image.jpg', caption=caption)\n",
        "    # img"
      ],
      "metadata": {
        "id": "qBGb7iU970Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "source_image = load_image('/content/negin.jpg')\n",
        "swapped_img = ReActorFaceSwap().swap(input_image=image, source_image=source_image)\n",
        "print(f'time: {str(time.time()-t1)} sec')\n",
        "swp_img = get_printable_image(swapped_img)\n",
        "swp_img"
      ],
      "metadata": {
        "id": "-cm6tLb_ShMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple text to image Flux.1"
      ],
      "metadata": {
        "id": "VbVrHjyy1QOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['vaginalsexlora.safetensors', '0.8'],\n",
        "]\n",
        "unet3, clip3 = apply_lora(unet=unet2, lora=default_lora_list, clip=clip2)"
      ],
      "metadata": {
        "id": "OO0d3yVMVO5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "prompt = '''\n",
        "A strikingly beautiful girl with a detailed, angelic soft face lies on a luxurious, red satin bed, her expression a mix of passion and vulnerability. The room is dimly lit, with soft, golden light casting warm shadows across her smooth skin. The composition focuses on the interplay of light and shadow, emphasizing the curves and contours of their bodies, creating a visually captivating and sensual image.'''\n",
        "\n",
        "# prompt = 'tangled embrace, beautiful faces locked in deep intense gaze, nipples hard and straining, nipples pert and erect, aching need written all over their nice faces, hands roaming and caressing, stroking every curve, tongue darting out to lick and taste, fingers teasing and toying with sensitive nipples, making them even harder, driving them both wild with desire, rubbing together in the slick heat, pelvic grinding, pumping faster and faster, slamming together in deep penetrating thrusts, desperate for more of that incredible pleasure, breathless screams torn from throat, body tensing and quivering on the brink, falling off the edge into oblivion'\n",
        "t1 = time.time()\n",
        "seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "width = int(512 * 1.5)\n",
        "height = int(768 * 1.5)\n",
        "empty_latent = create_empty_latent(width, height)\n",
        "\n",
        "latent = ksampler(model=unet, seed=seed, positive=encode_prompt(clip, prompt), negative=encode_prompt(clip, \"bad quality\"), latent=empty_latent)\n",
        "image = vae_decode(vae, latent)\n",
        "print(f'seed={seed}, time: {str(time.time()-t1)} sec')\n",
        "img = get_printable_image(image)\n",
        "img\n",
        "\n",
        "saveJPEG(image, name=f'lunar-{str(datetime.now().strftime(\"%H%M%S\"))}')\n"
      ],
      "metadata": {
        "id": "xcFxnUUm1Q9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "source_image = load_image('/content/negar.jpg')\n",
        "swapped_img = ReActorFaceSwap().swap(input_image=image, source_image=source_image)\n",
        "print(f'time: {str(time.time()-t1)} sec')\n",
        "swp_img = get_printable_image(swapped_img)\n",
        "swp_img"
      ],
      "metadata": {
        "id": "gVle9H8T0-Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_management.unload_all_models()"
      ],
      "metadata": {
        "id": "obVI5mIEpuY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "yAYDIF9exOYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple image to image"
      ],
      "metadata": {
        "id": "qYRTxq85lwyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if seed == 0:\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "print(f'seed={seed}')\n",
        "\n",
        "pixels = load_image('example.png')\n",
        "latent = vae_encode(vae, pixels)\n",
        "latent = ksampler(unet, seed, steps, cfg, sampler, scheduler,\n",
        "                  encode_prompt(clip, positive_prompt), encode_prompt(clip, negative_prompt),\n",
        "                  latent, denoise=0.8)\n",
        "image = vae_decode(vae, latent)\n",
        "img = get_printable_image(image)\n",
        "img"
      ],
      "metadata": {
        "id": "eHbGqwBVcrkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UpScale Image"
      ],
      "metadata": {
        "id": "OaYV1yCpKOlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_nX = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=1)\n",
        "latent = vae_encode(vae, image_nX)\n",
        "latent = ksampler(unet2, seed, steps, cfg, sampler, scheduler,\n",
        "                  encode_prompt(clip, positive_prompt), encode_prompt(clip, negative_prompt),\n",
        "                  latent, denoise=0.4)\n",
        "image_nX = vae_decode(vae, latent)\n",
        "img = get_printable_image(image_nX)\n",
        "img"
      ],
      "metadata": {
        "id": "o7GfOEAUGeyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Batch Image Generator"
      ],
      "metadata": {
        "id": "QKxVHBIfvfyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import piexif\n",
        "from datetime import datetime\n",
        "import time\n",
        "import json\n",
        "import gc\n",
        "import PIL.Image\n",
        "import random\n",
        "\n",
        "class BatchImageGeneratorWithAI:\n",
        "\n",
        "    def __init__(self, path='/content/output', image_perfix='km_'):\n",
        "        self.out_path = os.path.join(path, datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "        if not os.path.exists(self.out_path):\n",
        "            os.makedirs(self.out_path)\n",
        "\n",
        "        self.file_perfix=image_perfix\n",
        "        self.base_model=None\n",
        "        self.model = None\n",
        "        self.base_clip=None\n",
        "        self.ckpt_name = None\n",
        "        self.promptGenerator = None\n",
        "        try:\n",
        "            self.lora_list = json.loads(read_file('/content/lora.txt'))\n",
        "        except Exception as e:\n",
        "            self.lora_list = []\n",
        "\n",
        "        self.disable_lora = False\n",
        "        self.default_lora_list = []\n",
        "        self.pre_prompt = ''\n",
        "\n",
        "    def add_vae(self, vae_file_name=None):\n",
        "        self.vae, name = load_vae(vae_file_name)\n",
        "\n",
        "    def apply_lora(self, lora_list=[]):\n",
        "        flist = []\n",
        "        flist.extend(self.default_lora_list)\n",
        "        flist.extend(lora_list)\n",
        "\n",
        "        if self.base_model:\n",
        "            self.model, self.clip = apply_lora(self.base_model, lora=flist, clip=self.base_clip, apply_to_clip=True)\n",
        "        else:\n",
        "            raise Expection('load model firt!')\n",
        "\n",
        "    def add_to_positive_prompt(self, pre_prompt=''):\n",
        "        self.pre_prompt=pre_prompt\n",
        "\n",
        "    def remove_lora(self):\n",
        "        self.default_lora_list = []\n",
        "        self.model = self.base_model\n",
        "\n",
        "    def load_image_generator_model(self, ckpt_name=None, hyper_lora:HyperLoRa=None):\n",
        "        print('Start loading Image Generator Ai')\n",
        "        self.ckpt_name = ckpt_name\n",
        "        t1 = time.time()\n",
        "        self.unet, self.base_clip, self.vae, self.model_name = load_checkpoint(ckpt_name)\n",
        "        self.clip = self.base_clip\n",
        "        if hyper_lora:\n",
        "            self.base_model = apply_hyper_lora(self.unet, hyper_lora)\n",
        "            self.model = self.base_model\n",
        "        else:\n",
        "            self.base_model = self.unet\n",
        "            self.model = self.base_model\n",
        "        print(f'Model {ckpt_name} loaded at {str(round(time.time() - t1, 1))} second.')\n",
        "\n",
        "    def generate_prompt_with_ai(self, general_prompt, following_prompt, keywords, number, path_to_save=None):\n",
        "        def get_lora_detailds(id):\n",
        "            for lora in self.lora_list:\n",
        "                if id == lora[\"id\"]:\n",
        "                    return lora\n",
        "\n",
        "        if self.promptGenerator is None:\n",
        "            print('Start loading Prompt Generator Ai')\n",
        "            t1 = time.time()\n",
        "\n",
        "            base_model = None\n",
        "            if model_type == \"SDXL\":\n",
        "                base_model = 'SDXL 1.0'\n",
        "            elif model_type == \"SD15\":\n",
        "                base_model = 'SD 1.5'\n",
        "\n",
        "            n_ctx = 4 * 1024 if self.disable_lora else 4*1024\n",
        "            try:\n",
        "                if promptGenerator:\n",
        "                    self.promptGenerator = promptGenerator\n",
        "            except Exception as e:\n",
        "                self.promptGenerator = PromptGenerator(n_ctx=n_ctx, lora_list=self.lora_list, basemodel=base_model)\n",
        "\n",
        "            print(f'Prompt Generator Ai loaded in {str(round(time.time() - t1, 1))} second.')\n",
        "        else:\n",
        "            self.promptGenerator.clear_history()\n",
        "\n",
        "        print('Start generating prompts ...')\n",
        "        t1 = time.time()\n",
        "        prompt_list = []\n",
        "\n",
        "        prompt_list_file_name = f'prompt_list {str(datetime.now().strftime(\"%H%M%S\"))}.txt'\n",
        "        while len(prompt_list) < number:\n",
        "            print()\n",
        "            print()\n",
        "            print(f\"++++  Start {len(prompt_list)} ---------------------------------------\")\n",
        "            print()\n",
        "            ai_seed=random.randint(0, 1844674124)\n",
        "            # ai_prompt, out = self.promptGenerator.generate_prompt(prompt=general_prompt if len(prompt_list) == 0 else following_prompt, seed=ai_seed)\n",
        "            self.promptGenerator.clear_history()\n",
        "            kws = keywords()\n",
        "            main_prompt = general_prompt.replace(\"RP_Keywords\", kws)\n",
        "            ai_prompt, out = self.promptGenerator.generate_prompt(prompt=main_prompt, seed=ai_seed, use_system_prompt=False)\n",
        "            if ai_prompt:\n",
        "                try:\n",
        "                    if len(ai_prompt) > 1000:\n",
        "                        ai_prompt = ai_prompt[:1000]\n",
        "                    ai_prompt = ai_prompt.split('\\n')\n",
        "                    if len(ai_prompt) > 1:\n",
        "                        if 'The prompt' in ai_prompt[0] or 'Here' in ai_prompt[0]:\n",
        "                            ai_prompt = ai_prompt[1] if len(ai_prompt[1]) > 10 else (ai_prompt[2] if len(ai_prompt[2]) > 10 else '')\n",
        "                        else:\n",
        "                            ai_prompt = ai_prompt[0]\n",
        "                    else:\n",
        "                        ai_prompt = ai_prompt[0]\n",
        "\n",
        "                    positive_prompt = ai_prompt\n",
        "                    print(f\"positive_prompt: {positive_prompt}\")\n",
        "\n",
        "                    if self.disable_lora:\n",
        "                         prompt_list.append((positive_prompt, '', None))\n",
        "                    else:\n",
        "                        def is_duplicate(item, llist):\n",
        "                            for it in llist:\n",
        "                                if it[\"id\"] == item[\"id\"]:\n",
        "                                    return True\n",
        "                            return False\n",
        "\n",
        "                        try:\n",
        "                            lora_prompt, out = self.promptGenerator.generate_lora_list(str(json.dumps(ai_prompt)), seed=ai_seed)\n",
        "                            llora = []\n",
        "                            pp = positive_prompt\n",
        "                            for it in lora_prompt:\n",
        "                                if is_duplicate(it, llora):\n",
        "                                    continue\n",
        "\n",
        "                                lora = get_lora_detailds(it[\"id\"])\n",
        "                                if lora:\n",
        "                                    pp = positive_prompt\n",
        "                                    if \"trainedWords\" in lora:\n",
        "                                        pp += f', {lora[\"trainedWords\"][0]}'\n",
        "\n",
        "                                    if \"weights\" in it:\n",
        "                                        lora[\"weights\"] = it[\"weights\"]\n",
        "                                        print(f\"    |- lora loaded: {lora['name']}\")\n",
        "                                        llora.append(lora)\n",
        "\n",
        "                            prompt_list.append((pp, '', llora))\n",
        "                        except Exception as e:\n",
        "                            print(f\"bad lora prompt: {out}\")\n",
        "                            prompt_list.append((positive_prompt, '', None))\n",
        "\n",
        "                except Exception as er:\n",
        "                    print(f\"bad prompt: {out['choices'][0]['message']['content']}\")\n",
        "\n",
        "            if path_to_save:\n",
        "                data = {\n",
        "                    \"general_prompt\": main_prompt,\n",
        "                    \"following_prompt\": following_prompt,\n",
        "                    \"prompt_list\": prompt_list\n",
        "                }\n",
        "                file_name = os.path.join(path_to_save, prompt_list_file_name)\n",
        "                with open(file_name, 'w') as file:\n",
        "                    file.write(json.dumps(data, indent=4))\n",
        "                    file.close()\n",
        "\n",
        "        if path_to_save:\n",
        "            print(f\"Prompts printed to {file_name}\")\n",
        "        print(f'Prompt Generated at {str(round(time.time() - t1, 1))} second.')\n",
        "        return prompt_list\n",
        "\n",
        "    def load_prompts(self, file_name):\n",
        "        with open(file_name, 'r') as file:\n",
        "            contents = file.read()\n",
        "            file.close()\n",
        "        return json.loads(contents)['prompt_list']\n",
        "\n",
        "    def free_memory(self):\n",
        "        if self.promptGenerator:\n",
        "            self.promptGenerator.free_memory()\n",
        "            self.promptGenerator = None\n",
        "\n",
        "        if self.base_model:\n",
        "            self.base_model=None\n",
        "            self.model = None\n",
        "            self.clip = None\n",
        "            self.vae = None\n",
        "            model_management.soft_empty_cache(force=True)\n",
        "            model_management.unload_all_models()\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    def set_default_lora(self, default_lora_list=[]):\n",
        "        self.default_lora_list=default_lora_list\n",
        "\n",
        "    async def text_to_image(self, prompt_list, batch=6, upscale=None, width=512, height=768, steps=10, cfg=0.9, negative_prompt='', p_seed=None,\n",
        "                      sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM, denoise=0.35, save_log=False, split_sampler=False, lora_prompt=''):\n",
        "        print()\n",
        "        t1 = time.time()\n",
        "        empty_latent = create_empty_latent(width, height)\n",
        "        if self.disable_lora and len(self.default_lora_list) > 0:\n",
        "            self.apply_lora()\n",
        "\n",
        "        for i in range(len(prompt_list)):\n",
        "            positive_prompt = self.pre_prompt + prompt_list[i][0] + lora_prompt\n",
        "            llora = prompt_list[i][2]\n",
        "            list_of_lora_name = []\n",
        "            if not self.disable_lora:\n",
        "                if llora:\n",
        "                    for it in llora:\n",
        "                        try:\n",
        "                            it[\"filename\"] = it[\"filename\"].replace(\" \", \"_\").replace(\" \", \"_\")\n",
        "                            if not os.path.exists(os.path.join(modelpaths.lora, str(it[\"filename\"]))):\n",
        "                                # download lora\n",
        "                                download(f'https://civitai.com/api/download/models/{it[\"id\"]}', str(it[\"filename\"]), modelpaths.lora)\n",
        "                            if os.path.exists(os.path.join(modelpaths.lora, str(it[\"filename\"]))):\n",
        "                                list_of_lora_name.append([str(it[\"filename\"]), float(it[\"weights\"])])\n",
        "                        except Exception as e:\n",
        "                            print(f\"bad lora prompt: {e}\")\n",
        "                    self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "            # generate\n",
        "            for j in range(batch):\n",
        "                print(f'Start batch: {i}, image number: {j}')\n",
        "\n",
        "                seed = p_seed if p_seed is not None else random.randint(0, 18446744073709551615)\n",
        "                # seed = 125\n",
        "                if not split_sampler:\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                        positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                        latent=empty_latent)\n",
        "                else:\n",
        "                    stp = steps//3\n",
        "\n",
        "                    start_step = 0\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt),negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=empty_latent, start_step=start_step, last_step=last_step, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                    start_step = last_step\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=latent, start_step=start_step, last_step=last_step, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                    start_step = last_step\n",
        "                    last_step = start_step + stp\n",
        "                    latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                    positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                    latent=latent, start_step=start_step, last_step=steps, add_noise=True,force_full_denoise=True)\n",
        "\n",
        "                image = vae_decode(self.vae, latent)\n",
        "\n",
        "                # upscale\n",
        "                if upscale:\n",
        "                    # self.default_lora_list.append(['Hyper-SD15-8steps-lora.safetensors', 1.0])\n",
        "                    # self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "                    upscale = float(upscale)\n",
        "                    if upscale > 0.2 and upscale <= 4:\n",
        "                        if upscale <= 2:\n",
        "                            image = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=upscale * 0.5)\n",
        "                        elif upscale > 2:\n",
        "                            image = scale_by_model(image, UpscalerModel.UltraSharp_4x, scale=upscale * 0.25)\n",
        "                        latent = vae_encode(self.vae, image)\n",
        "                        latent = ksampler(model=self.model, seed=seed, steps=8, cfg=0.95, sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM,\n",
        "                                        positive=encode_prompt(self.clip, positive_prompt), negative=encode_prompt(self.clip, negative_prompt),\n",
        "                                        latent=latent, denoise=denoise)\n",
        "                        image = vae_decode(self.vae, latent)\n",
        "\n",
        "                    # self.default_lora_list.pop()\n",
        "                    # self.apply_lora(lora_list=list_of_lora_name)\n",
        "\n",
        "                await self.save_image(self.file_perfix, image, positive_prompt, negative_prompt, width, height,\n",
        "                                seed, steps, cfg, sampler, scheduler, upscale, denoise, list_of_lora_name, save_log=save_log)\n",
        "\n",
        "        if self.disable_lora and len(self.default_lora_list) > 0:\n",
        "            self.remove_lora()\n",
        "\n",
        "        print(f\"finish generating {len(prompt_list) * batch} images in {str(time.time() - t1)} second.\")\n",
        "\n",
        "    async def image_upscale(self, img_file, prompts, upscale=None, seed=0, steps=8, cfg=0.85,\n",
        "                      sampler=Sampler.DDIM, scheduler=Scheduler.NORMAL, denoise=0.4, save_log=False):\n",
        "\n",
        "        if type(img_file) == str:\n",
        "            image = load_image(img_file)\n",
        "            file_name = os.path.splitext(os.path.basename(img_file))[0]\n",
        "        else:\n",
        "            raise Exception('this methos is only for image files.')\n",
        "\n",
        "        if upscale:\n",
        "            print()\n",
        "            t1 = time.time()\n",
        "            print(f'Start upscale image: {file_name} to {upscale}')\n",
        "\n",
        "            upscale = float(upscale)\n",
        "            if seed < 1:\n",
        "                seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "            if upscale > 0.2 and upscale <= 4:\n",
        "                if upscale <= 2:\n",
        "                    image = scale_by_model(image, UpscalerModel.RealESRGAN_x2, scale=upscale * 0.5)\n",
        "                elif upscale > 2:\n",
        "                    image = scale_by_model(image, UpscalerModel.UltraSharp_4x, scale=upscale * 0.25)\n",
        "                latent = vae_encode(self.vae, image)\n",
        "                latent = ksampler(model=self.model, seed=seed, steps=steps, cfg=cfg, sampler=sampler, scheduler=scheduler,\n",
        "                                positive=encode_prompt(self.clip, self.pre_prompt + prompts[0]), negative=encode_prompt(self.clip, prompts[1]),\n",
        "                                latent=latent, denoise=denoise)\n",
        "                image = vae_decode(self.vae, latent)\n",
        "            await self.save_image(file_name, image, self.pre_prompt + prompts[0], prompts[1], image.shape[2], image.shape[1],\n",
        "                                seed, steps, cfg, sampler, scheduler, upscale, denoise, lora_list=[], save_log=save_log)\n",
        "            print(f\"Finish generating images in {str(time.time() - t1)} second.\")\n",
        "\n",
        "    async def save_image(self, file_name, image, p_prompt, n_prompt, width=512, height=768, seed=0, steps=10, cfg=0.95,\n",
        "                         sampler=Sampler.DDPM, scheduler=Scheduler.SGM_UNIFORM, upscale=None, denoise=0.4, lora_list=[],\n",
        "                         save_log=False, broadcast_image=True):\n",
        "\n",
        "        flist = []\n",
        "        flist.extend(self.default_lora_list)\n",
        "        flist.extend(lora_list)\n",
        "\n",
        "        zeroth_ifd = {\n",
        "            \"positive_prompt\": p_prompt,\n",
        "            \"negative_prompt\": n_prompt,\n",
        "            \"width\": str(width),\n",
        "            \"height\": str(height),\n",
        "            \"seed\": str(seed),\n",
        "            \"steps\": str(steps),\n",
        "            \"cfg\": str(cfg),\n",
        "            \"sampler\": str(sampler.value),\n",
        "            \"scheduler\": str(scheduler.value),\n",
        "            \"upscale\": str(upscale),\n",
        "            \"denoise\": str(denoise),\n",
        "            \"model_name\": str(self.model_name),\n",
        "            \"lora\": flist,\n",
        "        }\n",
        "\n",
        "        metadata_string = json.dumps(zeroth_ifd)\n",
        "        exif_dict = {\n",
        "            '0th': {\n",
        "                piexif.ImageIFD.ImageDescription: metadata_string,  # Store the serialized dictionary\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Convert the EXIF dictionary to bytes\n",
        "        exif_bytes = piexif.dump(exif_dict)\n",
        "        if file_name and len(file_name) and self.file_perfix in file_name:\n",
        "            name =  file_name + str(datetime.now().strftime(\"%H%M%S\"))\n",
        "        else:\n",
        "            name =  self.file_perfix + '_' + str(datetime.now().strftime(\"%H%M%S\"))\n",
        "\n",
        "        if save_log:\n",
        "            file_name = os.path.join(self.out_path, f\"{name}.log\")\n",
        "            with open(file_name, 'w') as file:\n",
        "                file.write(json.dumps(zeroth_ifd))\n",
        "                file.close()\n",
        "\n",
        "        saveJPEG(image=image, path=self.out_path, name=f'{name}', quality=90, exif=exif_bytes)\n",
        "\n",
        "        if broadcast_image:\n",
        "            text = f\"seed={seed}, cfg={cfg}, step={steps}, w={width}, h={height}, prompt={p_prompt}, checkpoint={self.ckpt_name}, lora={self.default_lora_list}\"\n",
        "            caption = (\n",
        "                TelegramTextBuilder()\n",
        "                .quote(text, True, True)\n",
        "                .new_line()\n",
        "                .build()\n",
        "            )\n",
        "            await broadcast_image_to_telegram_bot(f'{self.out_path}/{name}.jpg', caption=caption)\n",
        "\n",
        "def get_prompts_in_all_categories(categorized_prompts_file, required_categories):\n",
        "    \"\"\"\n",
        "    Find prompts that exist in ALL of the specified category lists.\n",
        "\n",
        "    Args:\n",
        "        categorized_prompts_file (str): Path to categorized prompts JSON\n",
        "        required_categories (list): Categories the prompt must appear in\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of matching prompts, output file path)\n",
        "    \"\"\"\n",
        "    with open(categorized_prompts_file, 'r', encoding='utf-8') as f:\n",
        "        categorized_prompts = json.load(f)\n",
        "\n",
        "    # Verify all required categories exist\n",
        "    missing_categories = [cat for cat in required_categories if cat not in categorized_prompts]\n",
        "    if missing_categories:\n",
        "        raise ValueError(f\"Categories not found: {missing_categories}\")\n",
        "\n",
        "    # Get sets of prompts for each required category\n",
        "    prompt_sets = [set(categorized_prompts[cat]) for cat in required_categories]\n",
        "\n",
        "    # Find intersection (prompts present in all sets)\n",
        "    common_prompts = set(prompt_sets[0])\n",
        "    for prompt_set in prompt_sets[1:]:\n",
        "        common_prompts.intersection_update(prompt_set)\n",
        "\n",
        "    matching_prompts = list(common_prompts)\n",
        "\n",
        "    return matching_prompts"
      ],
      "metadata": {
        "id": "ePf2bUCHvfSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/result')\n",
        "# gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True"
      ],
      "metadata": {
        "id": "rzwEBzv-Z-gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen.free_memory()"
      ],
      "metadata": {
        "id": "XQAG1gv2g-2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen.load_image_generator_model(ckpt_name='aniverse_v50Pruned.safetensors', hyper_lora=None)\n",
        "# gen.load_image_generator_model(ckpt_name=None, hyper_lora=None)\n",
        "# gen.add_vae()"
      ],
      "metadata": {
        "id": "ruWM7mcR1et4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 182046.txt')\n",
        "required = [\"pose\", \"action\", \"sex_position\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    # ['Upright_front_above_2-000012.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    # ['xl_more_art-full-v1.safetensors', 0.8],\n",
        "    # ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    # ['Rendered_Face_Detailer_v1.0.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    # ['skin_texture_style_v4.safetensors', 1],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    # ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_list=[\n",
        "    ['POVMissionary.safetensors', 0.8],\n",
        "    # ['MissionaryVaginal-v2.safetensors', 0.7],\n",
        "    # ['upright_front_above_50.safetensors', 0.7],\n",
        "    # ['upright_straddle_20.safetensors', 0.7],\n",
        "    # ['EkuneSideDoggy.safetensors', 0.7],\n",
        "]\n",
        "lora_prompt = ''\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, 3DMM' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='score_9, score_8_up, score_7_up, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "# gen.text_to_image(prompt_list=prompt_list[2:4], batch=1, upscale=None, width=832, height=1216, steps=8, p_seed=145, cfg=0.98,\n",
        "#                   negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)\n",
        "gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=20, cfg=6, denoise=0.2, p_seed=145, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)\n",
        "\n",
        "# for item in lora_list:\n",
        "#     nlist = default_lora_list.copy()\n",
        "#     nlist.append(item)\n",
        "#     gen.set_default_lora(default_lora_list=nlist)\n",
        "#     # gen.text_to_image(prompt_list=prompt_list[0:10], batch=1, upscale=None, width=640, height=960)\n",
        "#     gen.text_to_image(prompt_list=prompt_list[0:1], batch=1, upscale=1.4, steps=25, cfg=7, sampler=Sampler.DPM_PP_2M_SDE,\n",
        "#                       scheduler=Scheduler.KARRAS)"
      ],
      "metadata": {
        "id": "kXAVthHzo70t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"pose\", \"sex_position\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "print(len(prompts))"
      ],
      "metadata": {
        "id": "YMXxtCb53BCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['xl_more_art-full-v1.safetensors', 0.9],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 2.5],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.6],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "lora_prompt = ', 3DMM, perfecteyes'\n",
        "# gen.remove_lora()\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.apply_lora()\n",
        "\n",
        "for item in os.listdir(gen.out_path)[:4]:\n",
        "    if item.endswith(\".log\"):\n",
        "        sItem = os.path.join(gen.out_path, item)\n",
        "        data = json.loads(read_file(sItem))\n",
        "        gen.image_upscale(img_file=sItem.replace(\".log\", \".jpg\"), prompts=[data['positive_prompt']+lora_prompt, data['negative_prompt']],\n",
        "                          cfg=1, upscale=1.6, seed=int(data['seed']), steps=8, denoise=0.35)\n",
        "        # os.remove(sItem)\n",
        "        # os.remove(sItem.replace(\".log\", \".jpg\"))\n",
        "gen.remove_lora()"
      ],
      "metadata": {
        "id": "BJJbt7jeiTBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 1 (Fucktastic 2.5D Checkpoint)"
      ],
      "metadata": {
        "id": "nk0ahcge7L7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='fucktastic25DCheckpointPony_v20.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "BuHSOYIA7qFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "prompt_list = []\n",
        "for i in range(10):\n",
        "    prompt_list.append((AIPromptGenerator(None).generate_raw_prompts('Seductive'), '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['xl_more_art-full-v1.safetensors', 0.8],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['Rendered_Face_Detailer_v1.0.safetensors', 0.9],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', perfecteyes, Expressiveh, 7-cgifaces'\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "NbH_RtFG7r_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "\n",
        "prompt_list = []\n",
        "for i in range(10):\n",
        "    prompt_list.append((AIPromptGenerator(None).generate_raw_prompts('Seductive'), '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "9S-R0tgs9-F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slow"
      ],
      "metadata": {
        "id": "xtaIVWuxBIqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_list = gen.load_prompts('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompt_list 163120.txt')\n",
        "prompt_list = []\n",
        "for i in range(10):\n",
        "    prompt_list.append((AIPromptGenerator(None).generate_raw_prompts('Seductive'), '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.7],\n",
        "    # ['Insertion_Slider_alpha1.safetensors', 5],\n",
        "    ['DetailTweaker-XL-V1.safetensors', 1],\n",
        "]\n",
        "\n",
        "lora_prompt = ''\n",
        "pre_prompt='realystic, 3D, CG Girl, detailed eyes, ginger face, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=24, cfg=7, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.SIMPLE, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "-7JQdCBtAYj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 2 (waiNSFWIllustrious_v150)"
      ],
      "metadata": {
        "id": "f27WiESiDLoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='waiNSFWIllustrious_v150.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "XAU96zr2DLoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(3):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='detailed face, realistic',\n",
        "               forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "M8FRWtM2dV7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8], #Expressiveh\n",
        "    ['Eye_Enhancer.safetensors', 1],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3], # aesthetic\n",
        "    ['Dramatic_Lighting_Slider.safetensors', 3.5],\n",
        "    ['Face_Enhancer_Illustrious.safetensors', 1],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', detailed eyes, Expressiveh, aesthetic'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "if ['Hyper-SDXL-8steps-lora.safetensors', 1.0] in default_lora_list:\n",
        "    await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=10, cfg=1, denoise=0.2, p_seed=None, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DDPM, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)\n",
        "else:\n",
        "    await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=21, cfg=5, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "tD0GVMQEDLoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 3 (prefectPonyXL_v3)"
      ],
      "metadata": {
        "id": "EGZv4mdi-PdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='prefectPonyXL_v3.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "b3ro5DOT-PdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "# prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for i in range(100):\n",
        "    p_prompt, n_prompt = AIPromptGenerator(None).generate_raw_prompts('')\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.7],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.6],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "OeYx6zlx-PdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 4 (realcartoonXL_v7)"
      ],
      "metadata": {
        "id": "2gOEbnAFCZgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='realcartoonXL_v7.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "VYAbOniyCZgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.3],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.3],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list[:2], batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "WzMsY9OtCZgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 5 (aniversePonyXL_v50)"
      ],
      "metadata": {
        "id": "iGaE319xH6AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='aniversePonyXL_v50.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "8RStVU8NH6AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required = [\"erotic\", \"sensual\"]\n",
        "\n",
        "# prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "\n",
        "# with open('/content/drive/MyDrive/AI/KHidden.mail_Generated/prompts_20250826_182405.json', 'r', encoding='utf-8') as f:\n",
        "#         prompts = json.load(f)['prompts']\n",
        "\n",
        "prompt_list = []\n",
        "for p_prompt in range(10):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='', forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['NsfwPovAllInOneLoraSdxl-000009.safetensors', 0.5],\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.4],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.4],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.3],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=648, height=1152, steps=21, cfg=6, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "B8KOO2yUH6AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 6 (iniverseMixSFWNSFW_ponyRealGuofengV50C) # realistic photo"
      ],
      "metadata": {
        "id": "pKdi1__RPckq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='iniverseMixSFWNSFW_ponyRealGuofengV50C.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "_7qpOW-iPcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required = [\"dress\", \"sensual\"]\n",
        "\n",
        "prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['Hyper-SDXL-8steps-lora.safetensors', 1.0],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='3D, CG model, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=832, height=1216, steps=8, cfg=0.98,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL)"
      ],
      "metadata": {
        "id": "4M0_CKzbPcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 7 (fucktastic25DCheckpointPony_v20)"
      ],
      "metadata": {
        "id": "wl0ZDMQbe8WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='fucktastic25DCheckpointPony_v20.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "DuGsNFl9e8WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required = [\"expression\", \"action\", \"sensual\"]\n",
        "\n",
        "# prompts = get_prompts_in_all_categories(categorized_prompts_file=\"/content/drive/MyDrive/AI/KHidden.mail_Generated/categorized_prompts.json\", required_categories=required)\n",
        "\n",
        "with open('/content/drive/MyDrive/AI/prompts_20250825_171021.json', 'r', encoding='utf-8') as f:\n",
        "        prompts = json.load(f)['prompts']\n",
        "\n",
        "prompt_list = []\n",
        "for p in prompts:\n",
        "    prompt_list.append((p, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''\n",
        "\n",
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.9],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['PerfectEyesXL.safetensors', 0.9],\n",
        "    ['detailed_notrigger.safetensors', 0.8],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.5],\n",
        "    ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.6],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, 3DMM' # ', 3DMM, perfecteyes, Expressiveh, 7-cgifaces, realistic skin'\n",
        "pre_prompt='score_9, score_8_up, score_7_up, detailed eyes, highly detailed body, natural skin,'\n",
        "gen.add_to_positive_prompt(pre_prompt=pre_prompt)\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=768, height=1152, steps=20, cfg=6, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                  negative_prompt=negative_prompt_sd15, sampler=Sampler.Euler_a, scheduler=Scheduler.NORMAL, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "XX7KkUnKe8WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 8 (prefectiousXLNSFW_v10)"
      ],
      "metadata": {
        "id": "kMX3xbqV8vb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='prefectiousXLNSFW_v10.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "ZAvefF-l8vb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(3):\n",
        "    p_prompt = AIPromptGenerator('detailed face').generate_raw_prompts(base_prompt='', forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "u-HM78cKNQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.7],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.3],\n",
        "    # ['CreateConcept_Illustrious_v2.safetensors', 0.4],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3],\n",
        "    ['3DMM_XL_V13.safetensors', 1],\n",
        "    ['Dramatic_Lighting_Slider.safetensors', 3.5],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, aesthetic, 3DMM'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=21, cfg=5, denoise=0.2, lora_prompt=lora_prompt, p_seed=1365,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "JFg6gt5l8vb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 9 (realvisxlV50_v50LightningBakedvae)"
      ],
      "metadata": {
        "id": "8HXK3AuTQOcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='realvisxlV50_v50LightningBakedvae.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "CsyFGX_3QOcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(20):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='detailed face',\n",
        "               forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "LQCqbSHgQOcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['PerfectEyesXL.safetensors', 0.7],\n",
        "    ['AddMicroDetails_Illustrious_v3.safetensors', 0.3], # addmicrodetails\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.4], # createconcept\n",
        "    # ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3], # aesthetic\n",
        "    ['Dramatic_Lighting_Slider.safetensors', 0.5],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, addmicrodetails, perfecteyes, Expressiveh, aesthetic'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=6, cfg=1.5, denoise=0.2, lora_prompt=lora_prompt, p_seed=1365,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_SDE, scheduler=Scheduler.KARRAS, split_sampler=False, save_log=False)"
      ],
      "metadata": {
        "id": "td-Ran4XQOcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 10 (perfectdeliberate_il)"
      ],
      "metadata": {
        "id": "04RfxROnkhQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='perfectdeliberate_il.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "id": "1TgcKo7GkhQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(100):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='detailed face',\n",
        "               forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "_-PLU8KQkhQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    # ['Expressive_H-000001.safetensors', 0.8],\n",
        "    ['Eye_Enhancer.safetensors', 1],\n",
        "    # ['AddMicroDetails_Illustrious_v3.safetensors', 0.3], # addmicrodetails\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.4], # createconcept\n",
        "    # ['Urban_Fusion_IL.safetensors', 0.5],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3], # aesthetic\n",
        "    ['Dramatic_Lighting_Slider.safetensors', 1.5],\n",
        "    ['Face_Enhancer_Illustrious.safetensors', 1],\n",
        "    # ['Detail_enhancer_IL_v2.safetensors', 0.8],\n",
        "]\n",
        "\n",
        "lora_prompt = ', createconcept, detailed eyes, aesthetic'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=21, cfg=5, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "Te42u5yWkhQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 11 (prefectIllustriousXL_v3)"
      ],
      "metadata": {
        "id": "P5ZrW6SuStWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='prefectIllustriousXL_v3.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "outputId": "7924155b-1596-4d6e-bf26-9051cbf69f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEa0tfXnStWV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start loading Image Generator Ai\n",
            "Model prefectIllustriousXL_v3.safetensors loaded at 28.9 second.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(150):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='detailed face, realistic',\n",
        "               forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "Pcu1EOfzStWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.8], #Expressiveh\n",
        "    ['Eye_Enhancer.safetensors', 1],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3], # aesthetic\n",
        "    ['Dramatic_Lighting_Slider.safetensors', 3.5],\n",
        "    ['Face_Enhancer_Illustrious.safetensors', 1],\n",
        "]\n",
        "\n",
        "lora_prompt = ', detailed eyes, Expressiveh, aesthetic'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=21, cfg=5, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "BG8ighCpStWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 12 (illustrijQuill_v1)"
      ],
      "metadata": {
        "id": "rBxzrZ_1cixb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = BatchImageGeneratorWithAI(path='/content/drive/MyDrive/AI/KHidden.mail_Generated')\n",
        "gen.disable_lora=True\n",
        "gen.load_image_generator_model(ckpt_name='illustrijQuill_v1.safetensors', hyper_lora=None)"
      ],
      "metadata": {
        "outputId": "7924155b-1596-4d6e-bf26-9051cbf69f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCfcwhtjcixd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start loading Image Generator Ai\n",
            "Model prefectIllustriousXL_v3.safetensors loaded at 28.9 second.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "for p_prompt in range(150):\n",
        "    p_prompt = AIPromptGenerator(None).generate_raw_prompts(base_prompt='detailed face, 3D',\n",
        "               forced_categories=['nipples', 'erotic', 'sex_acts', 'bodily_effects', 'sexual_descriptors', 'sex_position'])\n",
        "    prompt_list.append((p_prompt, '', ''))\n",
        "\n",
        "negative_prompt_sd15 = '''\n",
        "(low quality, worst quality), deformed limbs, bad anatomy, blury, poor quality, sketch, painting,\n",
        "busty, (large breasts:0.3),  mutated hands, low res, blurry face, pumped body, extra fingers, fused fingers, too many fingers\n",
        "'''"
      ],
      "metadata": {
        "id": "t-tfT1TNcixd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_lora_list=[\n",
        "    ['Expressive_H-000001.safetensors', 0.5], #Expressiveh\n",
        "    ['Eye_Enhancer.safetensors', 1],\n",
        "    ['cfg_scale_boost.safetensors', 0.4],\n",
        "    ['aesthetic.safetensors', 3], # aesthetic\n",
        "    ['CreateConcept_Illustrious_v2.safetensors', 0.4],\n",
        "    ['Face_Enhancer_Illustrious.safetensors', 1],\n",
        "    ['female-dominant_V1.safetensors', 0.6],\n",
        "]\n",
        "\n",
        "lora_prompt = ', detailed eyes, createconcept, Expressiveh, aesthetic, female-dominant_V1'\n",
        "gen.set_default_lora(default_lora_list=default_lora_list)\n",
        "\n",
        "await gen.text_to_image(prompt_list=prompt_list, batch=1, upscale=None, width=512, height=1120, steps=21, cfg=5, denoise=0.2, lora_prompt=lora_prompt,\n",
        "                negative_prompt=negative_prompt_sd15, sampler=Sampler.DPM_PP_2M, scheduler=Scheduler.KARRAS, split_sampler=True, save_log=False)"
      ],
      "metadata": {
        "id": "bwoXrA_0cixd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AyH4Jb5mNofH",
        "USPvp_jieoRL",
        "vUabsHbSTKF6",
        "Nb8G2WauywJu"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}